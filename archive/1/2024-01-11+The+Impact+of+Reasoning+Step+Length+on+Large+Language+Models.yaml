date: 2024-01-11 00:00
author: Mingyu Jin
title: The Impact of Reasoning Step Length on Large Language Models
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/33G4qvyyqfGsMGMYGXjIj.png
link: https://huggingface.co/papers/2401.04925
summary: Chain of Thought (CoT) is significant in improving the reasoning abilities of large language models (LLMs). However, the correlation between the effectiveness of CoT and the length of reasoning steps in prompts remains largely unknown. To shed light on this, we have conducted several empirical experiments to explore the relations. Specifically, we design experiments that expand and compress the rationale reasoning steps within CoT demonstrations, while keeping all other factors constant. We have...
opinion: placeholder
tags:
    - Deep Learning
    - Natural Language Processing
