date: "2024-01-18"
author: Nanye Ma
title: 'SiT: Exploring Flow and Diffusion-based Generative Models with Scalable Interpolant Transformers'
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/hdPDnPoXo91-ivR-5d52c.png
link: https://huggingface.co/papers/2401.08740
summary: This paper proposes Scalable Interpolant Transformers (SiT), a family of generative models that improves upon Diffusion Transformers (DiT). SiT allows for flexible connection of two distributions and explores various design choices impacting generative models, including discrete vs. continuous time learning, choice of objective, interpolant, and sampler. SiT outperforms DiT on the conditional ImageNet 256x256 benchmark and achieves an FID-50K score of 2.06 with tunable diffusion coefficients....
opinion: placeholder
tags:
    - Unsupervised Learning
    - Deep Learning
    - Generative Models
