date: "2024-01-18"
author: Trung Quoc Luong
title: 'ReFT: Reasoning with Reinforced Fine-Tuning'
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/bPp1x6IrywnkFJUhY7QLH.png
link: https://huggingface.co/papers/2401.08967
summary: ReFT is a proposed approach for enhancing the generalizability of learning Large Language Models (LLMs) for reasoning, specifically for math problem-solving. ReFT first uses Supervised Fine-Tuning (SFT) with Chain-of-Thought (CoT) annotations, then employs reinforcement learning with the PPO algorithm for further fine-tuning. An abundance of reasoning paths are automatically sampled given the question, and rewards are derived from the ground-truth answers. ReFT outperforms SFT on GSM8K, MathQA, ...
opinion: placeholder
tags:
    - Supervised Learning
    - Reinforcement Learning
    - Deep Learning
    - Natural Language Processing
