date: "2024-01-12"
author: Asma Ghandeharioun
title: 'Patchscope: A Unifying Framework for Inspecting Hidden Representations of Language Models'
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/eVgaUfR3krVVYKRzWbaA8.png
link: https://huggingface.co/papers/2401.06102
summary: Patchscope, a unifying framework for inspecting hidden representations of language models, uses the model itself to explain its internal representations in natural language to answer various research questions about its computation. Patchscopes can also unify prior interpretability methods and open new possibilities for self-correction in multi-hop reasoning....
opinion: placeholder
tags:
    - Explainable AI and Interpretability
    - Natural Language Processing
    - Deep Learning
