date: "2024-01-18"
author: Lianghui Zhu
title: 'Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model'
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/3CR9QVEIjbOr4I8mOvDy1.png
link: https://huggingface.co/papers/2401.09417
summary: This paper proposes a new generic vision backbone with bidirectional Mamba blocks (Vim) for efficient and generic visual representation learning. Vim uses bidirectional state space models to compress visual representation with position embeddings, achieving higher performance on ImageNet classification, COCO object detection, and ADE20k semantic segmentation tasks while being significantly more computation & memory efficient compared to well-established vision transformers like DeiT....
opinion: placeholder
tags:
    - Computer Vision
    - Deep Learning
    - Optimization and Learning Algorithms
