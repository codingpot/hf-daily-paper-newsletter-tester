author: Haoxin Chen
date: '2024-01-18'
link: https://huggingface.co/papers/2401.09047
opinion: placeholder
summary: The paper proposes a new method for training high-quality video diffusion
  models using low-quality videos and synthesized high-quality images, overcoming
  the limitations of relying on well-filtered, high-quality videos. The method involves
  finetuning spatial modules with high-quality images and analyzing the connection
  between spatial and temporal modules to shift the distribution to higher quality.
  The proposed method demonstrates superiority in picture quality, motion, and concept
  composition....
tags:
- Deep Learning
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/jgPqbzAZBFM7Anlxsjxpi.png
title: 'VideoCrafter2: Overcoming Data Limitations for High-Quality Video Diffusion
  Models'
translated_path:
  ko: ../translated-papers/2401.09047/paper.ko.html
