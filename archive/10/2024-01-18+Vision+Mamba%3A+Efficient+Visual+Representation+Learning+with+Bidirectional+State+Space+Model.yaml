date: "2024-01-18"
author: Lianghui Zhu
title: 'Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model'
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/3CR9QVEIjbOr4I8mOvDy1.png
link: https://huggingface.co/papers/2401.09417
summary: Vision Mamba (Vim) is a new generic vision backbone with bidirectional Mamba blocks that compresses visual representation with bidirectional state space models, achieving higher performance on ImageNet classification, COCO object detection, and ADE20k semantic segmentation tasks compared to DeiT, while demonstrating improved computation & memory efficiency. It overcomes computation & memory constraints for Transformer-style understanding of high-resolution images, making it a potential next-gene...
opinion: placeholder
tags:
    - Deep Learning
    - Computer Vision
