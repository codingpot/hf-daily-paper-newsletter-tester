date: 2024-01-12 00:00
author: Zhaowei Li
title: LEGO:Language Enhanced Multi-modal Grounding Model
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/RS19u0XvuZMiB3d0swKNN.png
link: https://huggingface.co/papers/2401.06071
summary: Multi-modal large language models have demonstrated impressive performance across various tasks in different modalities. However, existing multi-modal models primarily emphasize capturing global information within each modality while neglecting the importance of perceiving local information across modalities. Consequently, these models lack the ability to effectively understand the fine-grained details of input data, limiting their performance in tasks that require a more nuanced understanding. ...
opinion: placeholder
tags:
    - ML
