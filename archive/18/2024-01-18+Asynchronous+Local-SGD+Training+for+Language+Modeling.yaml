date: "2024-01-18"
author: Bo Liu
title: Asynchronous Local-SGD Training for Language Modeling
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/wV15FTUGHbZ62WNxqwYgF.png
link: https://huggingface.co/papers/2401.09135
summary: This paper presents an empirical study of asynchronous Local-SGD for training language models. The study examines the impacts of worker hardware heterogeneity, model size, number of workers, and optimizer on the learning performance. The authors identify momentum acceleration on stale gradients as a key challenge and propose a novel method to adjust the workers' local training steps based on their computation speed. The method matches the performance of synchronous Local-SGD in terms of perplexi...
opinion: placeholder
tags:
    - Supervised Learning
    - Deep Learning
    - Optimization and Learning Algorithms
    - Natural Language Processing
