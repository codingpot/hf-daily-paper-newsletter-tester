date: "2024-01-18"
author: Lianghui Zhu
title: 'Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model'
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/3CR9QVEIjbOr4I8mOvDy1.png
link: https://huggingface.co/papers/2401.09417
summary: The paper proposes a new vision backbone called Vision Mamba (Vim), which is purely based on State Space Models (SSMs) and can efficiently learn visual representations. Vim uses bidirectional Mamba blocks and position embeddings to compress visual representation and achieve higher performance on ImageNet, COCO, and ADE20k tasks with improved computation and memory efficiency compared to existing vision transformers like DeiT. Vim has the potential to become the next-generation backbone for visio...
opinion: placeholder
tags:
    - Computer Vision
    - Deep Learning
