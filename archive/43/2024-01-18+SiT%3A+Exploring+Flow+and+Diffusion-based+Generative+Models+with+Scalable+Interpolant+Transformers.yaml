date: "2024-01-18"
author: Nanye Ma
title: 'SiT: Exploring Flow and Diffusion-based Generative Models with Scalable Interpolant Transformers'
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/hdPDnPoXo91-ivR-5d52c.png
link: https://huggingface.co/papers/2401.08740
summary: The Scalable Interpolant Transformers (SiT) paper presents a family of generative models built on the backbone of Diffusion Transformers (DiT). SiT allows for a modular study of various design choices impacting generative models, including using discrete vs. continuous time learning, choosing the interpolant connecting the distributions, and deploying a deterministic or stochastic sampler. By introducing these key ingredients, SiT surpasses DiT on the conditional ImageNet 256x256 benchmark and a...
opinion: placeholder
tags:
    - Generative Models
    - Diffusion Models
    - Deep Learning
    - Natural Language Processing
    - Computer Vision
