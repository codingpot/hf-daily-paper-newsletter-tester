date: "2024-01-17"
author: Alaaeldin El-Nouby
title: Scalable Pre-training of Large Autoregressive Image Models
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/agQVTT_BcFBvRnhUcBL4R.png
link: https://huggingface.co/papers/2401.08541
summary: 'This paper introduces AIM, a pre-trained collection of vision models with scaling properties similar to Large Language Models. The paper highlights two key findings: the performance of the visual features scale with model capacity and quantity of data, and the value of the objective function correlates with the model''s performance on downstream tasks. The paper illustrates the practical implication by pre-training a 7 billion parameter AIM on 2 billion images, achieving 84.0% accuracy on ImageNe...'
opinion: placeholder
tags:
    - Supervised Learning
    - Deep Learning
    - Computer Vision
