date: "2024-01-17"
author: Yikai Zhang
title: Extending LLMs' Context Window with 100 Samples
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/Qkvd3tER1WtHEyZa69or6.png
link: https://huggingface.co/papers/2401.07004
summary: This paper presents a novel method for extending the context window of large language models (LLMs) using modified rotary position embedding. The method employs adjusting the base frequency of RoPE and scaling attention logits to maintain stability while adapt to a larger context window. The authors demonstrate the superiority of the method in fine-tuning performance and robustness across different context window sizes on various context-demanding tasks. They also explore the effect of data comp...
opinion: placeholder
tags:
    - Deep Learning
    - Natural Language Processing
