date: "2024-01-12"
author: Chaoyang Wang
title: Diffusion Priors for Dynamic View Synthesis from Monocular Videos
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/ha--2B5SzZn5_Y7poI_yS.png
link: https://huggingface.co/papers/2401.05583
summary: This paper proposes a method for dynamic novel view synthesis from monocular videos by finetuning a pretrained RGB-D diffusion model and distilling the knowledge to a 4D representation encompassing both dynamic and static NeRF components. The method preserves scene identity while maintaining geometric consistency, and is evaluated through thorough experiments. The results demonstrate the robustness and utility of the approach in challenging cases, further advancing dynamic novel view synthesis....
opinion: placeholder
tags:
    - Computer Vision
    - Deep Learning
