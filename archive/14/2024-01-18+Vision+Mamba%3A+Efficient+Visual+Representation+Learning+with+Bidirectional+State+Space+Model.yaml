date: "2024-01-18"
author: Lianghui Zhu
title: 'Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model'
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/3CR9QVEIjbOr4I8mOvDy1.png
link: https://huggingface.co/papers/2401.09417
summary: This paper proposes a new vision backbone called Vision Mamba (Vim) based on bidirectional state space models for efficient visual representation learning. Vim achieves higher performance than DeiT on ImageNet classification, COCO object detection, and ADE20k semantic segmentation tasks while being faster and more memory-efficient. The results demonstrate Vim's potential as a next-generation vision backbone for foundation models....
opinion: placeholder
tags:
    - Computer Vision
    - Deep Learning
