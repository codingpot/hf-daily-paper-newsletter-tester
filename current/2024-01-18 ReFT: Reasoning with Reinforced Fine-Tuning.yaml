author: Trung Quoc Luong
date: '2024-01-18'
link: https://huggingface.co/papers/2401.08967
opinion: placeholder
summary: This paper proposes a method called Reinforced Fine-Tuning (ReFT) to improve
  the reasoning capability of Large Language Models (LLMs) for math problem-solving.
  ReFT first uses Supervised Fine-Tuning (SFT) with Chain-of-Thought (CoT) annotations
  and then employs Reinforced Fine-Tuning with the Proximal Policy Optimization (PPO)
  algorithm to further fine-tune the model. ReFT samples a large number of reasoning
  paths for each question and uses the ground-truth answer as a reward signal. Experiments...
tags:
- Supervised Learning
- Reinforcement Learning
- Deep Learning
- Natural Language Processing
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/bPp1x6IrywnkFJUhY7QLH.png
title: 'ReFT: Reasoning with Reinforced Fine-Tuning'
translated_path:
  ko: ../translated-papers/2401.08967/paper.ko.html
