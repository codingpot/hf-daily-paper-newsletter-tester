author: Boyi Li
date: '2024-01-22'
link: https://huggingface.co/papers/2401.10889
opinion: placeholder
summary: 'This paper introduces a diffusion model-based framework for animating people
  from a single image, based on a target 3D motion sequence. The framework consists
  of two components: learning priors about invisible parts of the human body and clothing,
  and rendering novel body poses with proper clothing and texture. The authors use
  an in-filling diffusion model to hallucinate unseen parts of a person, and train
  it on texture map space for better efficiency. A diffusion-based rendering pipeline
  is als...'
tags:
- Computer Vision
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/U5nTq8nH2lRpYYR-dBknO.qt
title: Synthesizing Moving People with 3D Control
translated_paths:
  KR: https://raw.githack.com/codingpot/hf-daily-paper-newsletter-tester/main/translated-papers/2401.10889/paper.ko.html
