author: Zihan Liu
date: '2024-01-19'
link: https://huggingface.co/papers/2401.10225
opinion: placeholder
summary: This paper presents ChatQA, a conversational question answering (QA) model
  family that achieves GPT-4 level accuracy. ChatQA employs a two-stage instruction
  tuning method to improve conversational QA results from large language models (LLMs).
  For retrieval, ChatQA fine-tunes a dense retriever on a multi-turn QA dataset, which
  offers comparable performance as state-of-the-art query rewriting models while reducing
  deployment cost. ChatQA-70B outperforms GPT-4 on 10 conversational QA datasets witho...
tags:
- Natural Language Processing
- Deep Learning
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/UkABNPp5_cGu24Z_PYrnA.png
title: 'ChatQA: Building GPT-4 Level Conversational QA Models'
translated_paths:
  KR: https://raw.githack.com/codingpot/hf-daily-paper-newsletter-tester/main/translated-papers/2401.10225/paper.ko.html
