date: "2024-01-12"
author: Zhaowei Li
title: LEGO:Language Enhanced Multi-modal Grounding Model
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/RS19u0XvuZMiB3d0swKNN.png
link: https://huggingface.co/papers/2401.06071
summary: This paper proposes a new multi-modal grounding model called LEGO that excels at tasks requiring a detailed understanding of local information in inputs. Unlike existing models that primarily capture global information, LEGO is designed to precisely identify and localize specific regions in images or moments in videos. A diversified dataset construction pipeline is used for training the model, resulting in a multi-modal, multi-granularity dataset. The code, dataset, and demo can be found at the ...
opinion: placeholder
tags:
    - Computer Vision
