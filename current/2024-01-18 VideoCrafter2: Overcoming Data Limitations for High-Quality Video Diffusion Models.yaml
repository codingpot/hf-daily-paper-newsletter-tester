author: Haoxin Chen
date: '2024-01-18'
link: https://huggingface.co/papers/2401.09047
opinion: placeholder
summary: This research focuses on text-to-video generation, addressing the limitations
  of current models that rely on large-scale, high-quality videos not accessible to
  the community. The authors explore a training scheme extended from Stable Diffusion
  and investigate the feasibility of using low-quality videos and synthesized high-quality
  images to obtain a high-quality video model. They analyze the connection between
  spatial and temporal modules and observe that full training results in a stronger
  coup...
tags:
- Computer Vision
- Deep Learning
- Natural Language Processing
- Supervised Learning
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/jgPqbzAZBFM7Anlxsjxpi.png
title: 'VideoCrafter2: Overcoming Data Limitations for High-Quality Video Diffusion
  Models'
translated_path:
  ko: ../translated-papers/2401.09047/paper.ko.html
