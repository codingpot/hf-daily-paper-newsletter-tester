date: "2024-01-18"
author: Haoxin Chen
title: 'VideoCrafter2: Overcoming Data Limitations for High-Quality Video Diffusion Models'
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/jgPqbzAZBFM7Anlxsjxpi.png
link: https://huggingface.co/papers/2401.09047
summary: Text-to-video generation aims to produce a video based on a given prompt. Recently, several commercial video models have been able to generate plausible videos with minimal noise, excellent details, and high aesthetic scores. However, these models rely on large-scale, well-filtered, high-quality videos that are not accessible to the community. Many existing research works, which train models using the low-quality WebVid-10M dataset, struggle to generate high-quality videos because the models are...
opinion: placeholder
tags:
    - Computer Vision
