date: "2024-01-12"
author: Pratyush Maini
title: 'TOFU: A Task of Fictitious Unlearning for LLMs'
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/saRF-HF-97bCg64554hKJ.png
link: https://huggingface.co/papers/2401.06121
summary: This paper introduces TOFU, a benchmark for unlearning in large language models. The benchmark aims to evaluate the extent to which unlearning methods result in models equivalent to those that were not trained on the data to be forgotten. The authors present a dataset of synthetic author profiles and a suite of metrics to evaluate unlearning efficacy. The paper also provides baseline results from existing unlearning algorithms, highlighting the need for continued research in this area....
opinion: placeholder
tags:
    - Unsupervised Learning
    - Deep Learning
    - Natural Language Processing
