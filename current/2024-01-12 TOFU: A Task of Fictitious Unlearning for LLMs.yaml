date: 2024-01-12 00:00
author: Pratyush Maini
title: 'TOFU: A Task of Fictitious Unlearning for LLMs'
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/saRF-HF-97bCg64554hKJ.png
link: https://huggingface.co/papers/2401.06121
summary: Large language models trained on massive corpora of data from the web can memorize and reproduce sensitive or private data raising both legal and ethical concerns. Unlearning, or tuning models to forget information present in their training data, provides us with a way to protect private data after training. Although several methods exist for such unlearning, it is unclear to what extent they result in models equivalent to those where the data to be forgotten was never learned in the first place
opinion: placeholder
tags:
    - ML
