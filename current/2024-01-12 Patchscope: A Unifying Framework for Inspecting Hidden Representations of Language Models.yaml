date: "2024-01-12"
author: Asma Ghandeharioun
title: 'Patchscope: A Unifying Framework for Inspecting Hidden Representations of Language Models'
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/eVgaUfR3krVVYKRzWbaA8.png
link: https://huggingface.co/papers/2401.06102
summary: This paper presents Patchscopes, a framework for understanding hidden representations of language models by using the model itself to explain its internal representations in natural language. The framework unifies prior interpretability methods and opens up new possibilities such as using a more capable model to explain the representations of a smaller model. Patchscopes can be used to answer a wide range of research questions about an LLM's computation....
opinion: placeholder
tags:
    - Explainable AI and Interpretability
    - Natural Language Processing
    - Deep Learning
