author: Zhenyu Wang
date: '2024-01-30'
link: https://huggingface.co/papers/2401.15688
opinion: placeholder
summary: This paper presents a method called CompAgent that uses a large language
  model to create high-quality images from complex text prompts. The method breaks
  down the prompt into individual objects and attributes, then uses reasoning to compose
  the objects into a coherent image. It also includes a verification and feedback
  mechanism to correct attribute errors and refine the image....
tags:
- Natural Language Processing
- Computer Vision
- Deep Learning
thumbnail: https://github.com/codingpot/hf-daily-paper-newsletter-tester/blob/main/assets/2401.15688.gif?raw=true
title: 'Divide and Conquer: Language Models can Plan and Self-Correct for Compositional
  Text-to-Image Generation'
translated_paths:
  INT: https://raw.githack.com/codingpot/hf-daily-paper-newsletter-tester/main/translated-papers/2401.15688/paper.en.html
  KR: https://raw.githack.com/codingpot/hf-daily-paper-newsletter-tester/main/translated-papers/2401.15688/paper.ko.html
