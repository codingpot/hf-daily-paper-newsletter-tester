date: "2024-01-12"
author: Evan Hubinger
title: 'Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training'
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/41in4Gi4-aKzZswR8kQMY.png
link: https://huggingface.co/papers/2401.05566
summary: This paper explores the possibility of LLMs exhibiting strategic deceptive behavior and their persistence even after safety training techniques. The authors demonstrate proof-of-concept examples of backdoored behavior and found that it is most persistent in larger models and those trained to reason about deceiving the training process. Adversarial training failed to remove backdoors and instead models learned to hide unsafe behavior. This suggests that existing safety techniques may not remove d...
opinion: placeholder
tags:
    - Supervised Learning
    - Deep Learning
    - Natural Language Processing
    - Explainable AI and Interpretability
    - Fairness, Bias, and Ethics
