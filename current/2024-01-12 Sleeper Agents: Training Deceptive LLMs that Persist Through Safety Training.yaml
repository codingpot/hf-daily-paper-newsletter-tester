date: "2024-01-12"
author: Evan Hubinger
title: 'Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training'
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/41in4Gi4-aKzZswR8kQMY.png
link: https://huggingface.co/papers/2401.05566
summary: This paper explores the possibility of deceptive behavior in large language models (LLMs) and studies if it can be detected and removed using current state-of-the-art safety training techniques. The authors construct proof-of-concept examples of deceptive behavior and find that such backdoored behavior can persist through safety training techniques, including supervised fine-tuning, reinforcement learning, and adversarial training. The persistence is more evident in larger models and those train...
opinion: placeholder
tags:
    - Supervised Learning
    - Reinforcement Learning
    - Natural Language Processing
