date: "2024-01-18"
author: Nanye Ma
title: 'SiT: Exploring Flow and Diffusion-based Generative Models with Scalable Interpolant Transformers'
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/hdPDnPoXo91-ivR-5d52c.png
link: https://huggingface.co/papers/2401.08740
summary: Scalable Interpolant Transformers (SiT) are generative models built on the backbone of Diffusion Transformers (DiT). SiT allows for a more flexible connection between two distributions, enabling a modular study of various design choices impacting generative models. By introducing these ingredients, SiT surpasses DiT on the conditional ImageNet 256x256 benchmark, and achieves an FID-50K score of 2.06 by tuning diffusion coefficients....
opinion: placeholder
tags:
    - Unsupervised Learning
    - Deep Learning
    - Computer Vision
