author: Nanye Ma
date: '2024-01-18'
link: https://huggingface.co/papers/2401.08740
opinion: placeholder
summary: This paper introduces Scalable Interpolant Transformers (SiT), a family of
  generative models that builds upon Diffusion Transformers (DiT). SiT provides more
  flexibility in connecting two distributions than standard diffusion models. The
  authors conduct a modular study of various design choices that impact generative
  models built on dynamical transport, including the use of discrete vs. continuous
  time learning, choosing the objective, the interpolant, and the sampler. SiT outperforms
  DiT on the...
tags:
- Unsupervised Learning
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/hdPDnPoXo91-ivR-5d52c.png
title: 'SiT: Exploring Flow and Diffusion-based Generative Models with Scalable Interpolant
  Transformers'
translated_path:
  ko: ../translated-papers/2401.08740/paper.ko.html
