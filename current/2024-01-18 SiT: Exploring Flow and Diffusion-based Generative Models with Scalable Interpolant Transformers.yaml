author: Nanye Ma
date: '2024-01-18'
link: https://huggingface.co/papers/2401.08740
opinion: placeholder
summary: Scalable Interpolant Transformers (SiT) are generative models built on the
  backbone of Diffusion Transformers (DiT). SiT allows for a more flexible connection
  between two distributions, enabling a modular study of various design choices impacting
  generative models. By introducing these ingredients, SiT surpasses DiT on the conditional
  ImageNet 256x256 benchmark, and achieves an FID-50K score of 2.06 by tuning diffusion
  coefficients....
tags:
- Unsupervised Learning
- Deep Learning
- Computer Vision
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/hdPDnPoXo91-ivR-5d52c.png
title: 'SiT: Exploring Flow and Diffusion-based Generative Models with Scalable Interpolant
  Transformers'
translated_path:
  ko: ../translated-papers/2401.08740/paper.ko.html
