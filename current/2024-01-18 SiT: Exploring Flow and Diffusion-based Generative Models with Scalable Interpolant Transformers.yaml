date: "2024-01-18"
author: Nanye Ma
title: 'SiT: Exploring Flow and Diffusion-based Generative Models with Scalable Interpolant Transformers'
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/hdPDnPoXo91-ivR-5d52c.png
link: https://huggingface.co/papers/2401.08740
summary: This paper presents Scalable Interpolant Transformers (SiT), a family of generative models based on Diffusion Transformers (DiT). SiT allows for more flexible connections between distributions and explores various design choices such as discrete vs. continuous time learning, choice of objective, interpolant, and sampler. SiT outperforms DiT on the ImageNet 256x256 benchmark using the same backbone, parameters, and GFLOPs, and achieves an FID-50K score of 2.06 with varying diffusion coefficients....
opinion: placeholder
tags:
    - Unsupervised Learning
    - Deep Learning
    - Computer Vision
