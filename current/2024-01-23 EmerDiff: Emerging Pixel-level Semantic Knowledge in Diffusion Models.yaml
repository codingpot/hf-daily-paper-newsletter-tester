author: Koichi Namekata
date: '2024-01-23'
link: https://huggingface.co/papers/2401.11739
opinion: placeholder
summary: The paper proposes a framework to extract fine-grained segmentation maps
  from pre-trained diffusion models, by identifying semantic correspondences between
  image pixels and low-dimensional feature maps. This method does not require additional
  training and produces detailed and accurate segmentation maps, demonstrating the
  presence of pixel-level semantic knowledge in diffusion models....
tags:
- Deep Learning
- Computer Vision
- Unsupervised Learning
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/xyrEB9_HYQv8Rd2MkFtie.jpeg
title: 'EmerDiff: Emerging Pixel-level Semantic Knowledge in Diffusion Models'
translated_paths:
  INT: https://raw.githack.com/codingpot/hf-daily-paper-newsletter-tester/main/translated-papers/2401.11739/paper.en.html
  KR: https://raw.githack.com/codingpot/hf-daily-paper-newsletter-tester/main/translated-papers/2401.11739/paper.ko.html
