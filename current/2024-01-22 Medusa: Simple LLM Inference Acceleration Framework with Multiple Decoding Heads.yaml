date: "2024-01-22"
author: Tianle Cai
title: 'Medusa: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads'
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/gxvTu6T6sN1X8MJshLwux.gif
link: https://huggingface.co/papers/2401.10774
summary: This paper presents Medusa, an efficient method for LLM inference acceleration by adding extra decoding heads that predict multiple subsequent tokens in parallel using a tree-based attention mechanism. Medusa introduces minimal overhead and reduces the number of decoding steps required, achieving over 2.2x speedup without compromising generation quality. The paper proposes two levels of fine-tuning procedures, Medusa-1 and Medusa-2, and several extensions to improve or expand the utility of Medu...
opinion: placeholder
tags:
    - Deep Learning
    - Natural Language Processing
