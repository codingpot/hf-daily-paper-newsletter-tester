date: "2024-01-23"
author: Alexandre Ram√©
title: 'WARM: On the Benefits of Weight Averaged Reward Models'
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/T4eMvoGUt2g-EoLiQRDqP.png
link: https://huggingface.co/papers/2401.12187
summary: The paper proposes Weight Averaged Reward Models (WARM) as a solution to mitigate reward hacking in language models fine-tuned through reinforcement learning (RLHF). WARM fine-tunes multiple reward models and averages them in the weight space, improving efficiency and reliability under distribution shifts and robustness to preference inconsistencies. Experiments show that WARM improves the overall quality and alignment of LLM predictions....
opinion: placeholder
tags:
    - Reinforcement Learning
    - Natural Language Processing
