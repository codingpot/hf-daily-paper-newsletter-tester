author: "Alexandre Ram\xE9"
date: '2024-01-23'
link: https://huggingface.co/papers/2401.12187
opinion: placeholder
summary: The paper proposes Weight Averaged Reward Models (WARM) as a solution to
  mitigate reward hacking in language models fine-tuned through reinforcement learning
  (RLHF). WARM fine-tunes multiple reward models and averages them in the weight space,
  improving efficiency and reliability under distribution shifts and robustness to
  preference inconsistencies. Experiments show that WARM improves the overall quality
  and alignment of LLM predictions....
tags:
- Reinforcement Learning
- Natural Language Processing
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/T4eMvoGUt2g-EoLiQRDqP.png
title: 'WARM: On the Benefits of Weight Averaged Reward Models'
translated_paths:
  INT: https://raw.githack.com/codingpot/hf-daily-paper-newsletter-tester/main/translated-papers/2401.12187/paper.en.html
  KR: https://raw.githack.com/codingpot/hf-daily-paper-newsletter-tester/main/translated-papers/2401.12187/paper.ko.html
