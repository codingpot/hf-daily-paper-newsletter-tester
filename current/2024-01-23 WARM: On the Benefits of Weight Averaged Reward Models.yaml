date: "2024-01-23"
author: Alexandre Ram√©
title: 'WARM: On the Benefits of Weight Averaged Reward Models'
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/T4eMvoGUt2g-EoLiQRDqP.png
link: https://huggingface.co/papers/2401.12187
summary: This paper proposes an approach called Weight Averaged Reward Models (WARM) to align large language models with human preferences and mitigate reward hacking, a problem that arises when language models exploit failures in the reward model. WARM first fine-tunes multiple reward models and then averages them in the weight space, which improves efficiency and reliability under distribution shifts and preference inconsistencies. Experiments on summarization tasks show that WARM improves the overall ...
opinion: placeholder
tags:
    - Supervised Learning
    - Natural Language Processing
