date: "2024-01-18"
author: Lianghui Zhu
title: 'Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model'
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/3CR9QVEIjbOr4I8mOvDy1.png
link: https://huggingface.co/papers/2401.09417
summary: This paper proposes a new generic vision backbone called Vision Mamba (Vim) that uses bidirectional state space models for efficient visual representation learning. Vim improves computation and memory efficiency compared to vision transformers like DeiT while achieving higher performance on tasks such as ImageNet classification, COCO object detection, and ADE20k semantic segmentation. The results show that Vim has potential to become the next-generation backbone for vision foundation models....
opinion: placeholder
tags:
    - Computer Vision
    - Deep Learning
    - Optimization and Learning Algorithms
