date: "2024-01-18"
author: Lianghui Zhu
title: 'Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model'
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/3CR9QVEIjbOr4I8mOvDy1.png
link: https://huggingface.co/papers/2401.09417
summary: Vision Mamba proposes a new generic vision backbone with bidirectional Mamba blocks (Vim) that marks image sequences with position embeddings and compresses visual representation with bidirectional state space models. Vim achieves higher performance compared to well-established vision transformers while demonstrating significantly improved computation and memory efficiency. Vim has great potential to become the next-generation backbone for vision foundation models....
opinion: placeholder
tags:
    - Computer Vision
    - Deep Learning
