date: "2024-01-18"
author: Lianghui Zhu
title: 'Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model'
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/3CR9QVEIjbOr4I8mOvDy1.png
link: https://huggingface.co/papers/2401.09417
summary: This paper proposes a new generic vision backbone called Vision Mamba (Vim) for efficient visual representation learning using bidirectional state space models. Vim outperforms existing vision transformers like DeiT while being more computationally and memory-efficient, particularly for high-resolution images. The results suggest that Vim has the potential to become the next-generation backbone for vision foundation models....
opinion: placeholder
tags:
    - Computer Vision
    - Deep Learning
