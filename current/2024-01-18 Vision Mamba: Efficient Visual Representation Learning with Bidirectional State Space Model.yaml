date: "2024-01-18"
author: Lianghui Zhu
title: 'Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model'
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/3CR9QVEIjbOr4I8mOvDy1.png
link: https://huggingface.co/papers/2401.09417
summary: This paper proposes a generic vision backbone, Vision Mamba (Vim), with bidirectional Mamba blocks for efficient visual representation learning. Vim uses position embeddings and bidirectional state space models to compress visual representation. Vim outperforms DeiT and other vision transformers in computation and memory efficiency, making it a potential next-generation backbone for vision foundation models....
opinion: placeholder
tags:
    - Deep Learning
    - Computer Vision
    - Optimization and Learning Algorithms
