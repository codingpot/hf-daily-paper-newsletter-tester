date: "2024-01-18"
author: Lianghui Zhu
title: 'Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model'
thumbnail: https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/3CR9QVEIjbOr4I8mOvDy1.png
link: https://huggingface.co/papers/2401.09417
summary: This paper proposes a new generic vision backbone called Vim, which uses bidirectional state space models for efficient and generic visual representation learning. Vim is capable of achieving higher performance compared to well-established vision transformers like DeiT on ImageNet classification, COCO object detection, and ADE20k semantic segmentation tasks, while also demonstrating significantly improved computation and memory efficiency. It has the potential to become the next-generation backb...
opinion: placeholder
tags:
    - Deep Learning
    - Computer Vision
