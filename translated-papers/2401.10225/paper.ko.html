<!DOCTYPE html>
<html lang="en" data-lt-installed="true"><head>
  <meta charset="UTF-8">
  <title>Title</title>
  <script>
    const text = '' +
      'GPT-4 레벨 대화 QA 모델# ChatQA\n' +
      '\n' +
      'Zihan Liu\n' +
      '\n' +
      'Wei Ping\n' +
      '\n' +
      'Rajarshi Roy\n' +
      '\n' +
      'Peng Xu\n' +
      '\n' +
      'Mohammad Shoeybi\n' +
      '\n' +
      'Bryan Catanzaro\n' +
      '\n' +
      '###### Abstract\n' +
      '\n' +
      '본 연구에서는 GPT-4 수준 정확도를 얻는 대화형 질문 응답(QA) 모델 가족 ChatQA를 소개한다. 구체적으로 대형 언어 모델(LLM)에서 제로 샷 대화 QA 결과를 크게 개선할 수 있는 2단계 명령어 튜닝 방법을 제안한다. 대화 QA에서 검색을 처리하기 위해 다회전 QA 데이터셋에 조밀한 리트리버를 미세 조정했으며, 이는 배치 비용을 크게 감소시키면서 최첨단 쿼리 재작성 모델을 사용하는 것과 유사한 결과를 제공한다. 특히, 우리의 ChatQA-70B는 10개의 대화형 QA 데이터세트(54.14 대 53.90)에서 평균 점수 측면에서 GPT-4를 능가할 수 있다. 오픈AI GPT 모델의 합성 데이터에 의존하지 않고.\n' +
      '\n' +
      '기계 학습, ICML 기계 학습, ICML 기계 학습, ICML 기계 학습, ICML 머신 학습, ICML 기계 학습, ICML 기계 학습, ICML 컴퓨터 학습, ICML 기계 학습, ICML 기계 학습, ICML 기계 학습\n' +
      '\n' +
      '## 1 Introduction\n' +
      '\n' +
      '가장 최근에는 ChatGPT(오픈AI, 2022)와 후속 조치(오픈AI, 2023; 인류, 2023; 구글, 2023)가 생산 및 연구 커뮤니티에서 질문 답변(QA) 모델을 구축하는 패러다임의 전환을 이끌어냈으며, 특히 QA 모델의 다음과 같은 측면은 실제 응용 분야에서 선호되며, 이는 사용자가 대화 방식으로 QA 모델과 상호 작용할 수 있으므로 쉽게 후속 질문을 제기할 수 있다. _ 일반주의 모델은 미세 조정 전문가 모델의 정확성과 일치하면서 데이터 세트 특이적 미세 조정 없이 제로 샷 방식으로 답변을 생성할 수 있다. _ 일반주의적 모델은 미세 조정 전문가 모델의 정확성과 일치할 수 있다. QA 모델은 LLM(예: 인류, 2023; Xu et al., 2023b)의 컨텍스트 창보다 훨씬 긴 개방형 도메인 또는 긴 문서 설정 모두에서 검색된 증거 청크를 통합할 수 있다. 이를 위해 우리는 이 세 가지 측면을 다루는 대화 QA에 초점을 맞추고 있다.\n' +
      '\n' +
      '그러나 최첨단 블랙박스 모델, 즉 GPT-4(오픈AI, 2023)의 정확성과 일치할 수 있는 대화형 QA 모델을 구축하는 것은 여전히 연구 커뮤니티에 대한 큰 도전이다. 이 작업에서 GPT-4 레벨 정확도를 갖는 화이트박스 대화 QA 모델인 ChatQA-70B를 제안된 2단계 명령어 튜닝 레시피, 대화 QA에서 검색-증강 생성(RAG)에 대한 향상된 리트리버, 세심한 데이터 큐레이션 프로세스를 통해 소개한다.\n' +
      '\n' +
      '구체적으로 다음과 같은 기여를 합니다.\n' +
      '\n' +
      '1. 제로 샷 대화 QA 태스크에 대해 제공되거나 검색된 컨텍스트를 통합하는 LLM의 능력을 크게 향상시킬 수 있는 2단계 명령어 튜닝 방법 및 데이터세트 큐레이션 레시피를 제안한다. 우리는 우리의 방법이 정규 명령어 튜닝 또는 RLHF 기반 레시피(예: 라마-2-챗)를 상당히 능가한다는 것을 보여준다.\n' +
      '대화 QA의 RAG에서 2.2의 경우, 우리는 인간이 아닌 다중턴 QA 데이터셋에 대한 미세 조정 최첨단 단일턴 쿼리를 검색하고 최첨단 LLM 기반 질의 재작성 모델, 즉 GPT-3.5-투르보(오픈AI, 2022)를 활용한다는 것을 보여준다.\n' +
      '3. 우리는 Llama2-7B, Llama2-13B, Llama2-70B(Touvron et al., 2023) 및 사내 8B를 기반으로 ChatQA 모델 계열을 구축한다. 검색이 필요한 긴 서류가 있는 데이터세트 5개와 테이블이 있는 데이터세트 3개를 포함하여 10개의 대화 QA 데이터셋에 대한 포괄적인 연구를 수행한다. 평균 점수 측면에서 ChatQA-70B 모델(54.14)은 ChatGPT 모델의 합성 데이터를 사용하지 않고 GPT-3.5-turbo(50.37) 및 GPT-4(53.90)를 능가할 수 있다.\n' +
      '4. 우리는 원하는 답이 제공된 또는 검색된 컨텍스트에 포함되지 않는 "불허성" 시나리오를 연구하여 LLM이 쉽게 환각할 수 있다. 지시 튜닝에 적은 양의 "불답가능" 샘플을 추가하면 모델이 필요할 때 "답지 않을 수 있다" 출력을 생성할 수 있으므로 복장을 크게 줄일 수 있음을 보여준다. 우리의 ChatQA-70B는 이와 관련하여 GPT-3.5-turbo를 능가하는 반면, GPT-4(약 3.5%)에 비해 약간의 격차를 가지고 있다.\n' +
      '\n' +
      '나머지 논문을 다음과 같이 정리합니다. SS 2의 관련 작업을 논의합니다. SS 3의 ChatQA에 대한 2단계 명령 튜닝 방법을 소개하고 SS 4의 ChatQA에 대한 검색 불변 QA를 연구합니다. SS 5의 실험 설정을 SS 6의 결과와 SS 7의 논문을 결론짓는다.\n' +
      '\n' +
      '2개는 회사 관련.\n' +
      '\n' +
      '### Conversational QA\n' +
      '\n' +
      '대화 방식으로 답하는 질문은 추적 질문을 해결함으로써 자연스럽게 사용자 경험을 향상시킵니다. 모델은 또한 필요한 경우 사용자에게 명확한 질문을 제기할 수 있으며, 이는 환각 현상을 줄일 수 있다. 따라서 생산(예: OpenAI, 2022; 구글, 2023; 인류, 2023b)에 QA 모델을 배치하는 기본 형태가 된다.\n' +
      '\n' +
      '최근 몇 년 동안 많은 대화형 QA 데이터셋이 도입되었으며, 여기서 모델은 제공되는 컨텍스트 또는 문서를 기반으로 질문에 답하도록 요청된다. 다양한 영역(펑 et al., 2020; Anianha et al., 2021; 아시네자 et al., 2021; Adiannejadi et al., 2021; Adianha et al, 2019; Reddy et al., 2019; A와 et al., 2023; 우 et al., 2022; Deng et al., 2022; Guo et al.,2022; 최 et al., 2018; Campos & Liang, 2018; Campos & Liang, 2018; K.\n' +
      '\n' +
      '최신 LLM 기반 일반 솔루션(예: OpenAI, 2022)과 대조적으로 대부분의 이전 연구는 특정 도메인 또는 데이터셋(펑 et al., 2020; Izacard & Grave, 2021; Chen et al, 2022; Gao et al., 2022; 나카무라 et al., 2022; Adlakha et al, 2022; 우 et al., 2023)에 대한 미세 조정 전문가 모델에 초점을 맞추고 있다.\n' +
      '\n' +
      '멀티-턴 QA.\n' +
      '\n' +
      '대화 QA는 개방형 도메인 설정에서 검색-증강 생성(RAG) 또는 제공된 문서가 LLM의 컨텍스트 윈도우보다 긴 경우를 포함한다. 조밀한 검색기는 보통 단일 질문(예: 린 et al, 2023, 왕 et al, 2022, Izacard et al, 2022)을 통해 상위 기업(k\\) 관련 청크를 회수하도록 훈련된다. 대화 QA에서 후속 질문(예: 이전 대화에서 언급한 엔티티들을 지칭하는 프로운트와 함께)은 검색에 대한 정보가 충분하지 않을 수 있지만, 대화 이력과 함께 먹이는 것은 중복되어 최적이 아닌 결과로 이어질 수 있다.\n' +
      '\n' +
      '2.2.1/2.1 대화식 쿼리 재생기####.\n' +
      '\n' +
      '이전 솔루션의 대부분은 질의 재작성 방법입니다. 최신 질문 차례는 이전 대화 이력(Vakulenko et al., 2021; 예 et al., 2023; Mo et al., 2023)의 추가 정보 없이 독립형 쿼리로 다시 작성되기 때문에 관련 컨텍스트(Vakulenko et al, 2021; Mele et al, 2021; Raposo et al, 2022; Mo et al., 2023)를 회수하기 위해 검색 모델에 의해 직접 사용될 수 있다. 이 연구 라인을 용이하게 하기 위해 많은 데이터 세트를 수집했으며(엘고히리스 et al., 2019; 추 et al, 2020; Qu et al, 2020; Anantha et al, 2021; Brabant et al., 2022), 여러 가지 제안된 질의 재작성 방법(Ishii et al., 2022; 유 et al, 2020; 우 et al, 2022; 델 틴티치 등은 2022; Chen et al., 2022; Galimzhanova et al., 2022; Galimzhanova 등)과 함께 여러 가지 제안된 질의 재작성 방법(Ishii et al. 예를 들어, 우 et al(2022)와 Chen et al(2022)는 질의 재작성용 강화 학습 방법을 사용할 것을 제안했다. 유 등은 질의 재작성용 GPT-2와 같은 몇 가지 샷 생성 모델을 조사했다. 갈림자노바(2023)는 지시 튜닝된 GPT-3.5-투르보를 연구했으며 대화 질의 재작성에 대한 최첨단 결과를 달성했음을 보여주었다.\n' +
      '\n' +
      '멀티턴 QA/###### 2.2.2 Fine-tuning 리트리버 2.2 Fine-turn QA###\n' +
      '\n' +
      '일부 이전 작업은 도메인 내 대화 질의 및 컨텍스트 쌍(펑 et al., 2020; Gao et al., 2022; Adlakha et al., 2022; 우 et al., 2023)에 대해 단일 시간 쿼리를 재구성하여 대화 히스토리와 현재 쿼리의 연결을 입력으로 직접 취할 수 있다. 이 작품에서 우리는 제로샷 평가에 중점을 둔다. 고품질 멀티턴 데이터셋에 단일턴 쿼리를 재조정합니다. 그런 다음 5개의 벤치마크 데이터 세트에서 미세 도금 리트리버의 제로 샷 능력을 평가합니다. 놀랍게도, 이 간단한 접근법은 최첨단 쿼리 재작성 모델, 즉 GPT-3.5-투보로 유사한 제로샷 결과를 얻을 수 있다는 것을 발견했다.\n' +
      '\n' +
      '### Instruction Tuning\n' +
      '\n' +
      '지시 튜닝 목표는 LLM이 자연어 지시(위 et al., 2022; 산h et al., 2022; 이이어 et al., 2022; 이이어 et al., 2022; 이이어 et al., Du et al., 2022; Ouyang et al., 2022; 오양 et al., 2022; 왕 et al., 1986; 장 et al., 2023; Ghang et al; Gao et al;2022; Gao et al;2022; 청 등은 2022; 무니호프, 2022; 자오 et al. FLAN(충 et al, 2022), 자기강좌(왕 et al., 2022), 부자연적 지도(호모비치 et al., 2022), 돌리(콘오버 et al., 2023), 개방형(Kopf et al., 2023) 등 수준 높은 지시 튜닝 데이터셋 개발이 급증하고 있다.\n' +
      '\n' +
      '지시 튜닝에 대한 많은 연구가 수행되었지만, 몇 가지 작업은 QA에 대한 RAG 또는 컨텍스트 인식 생성을 개선하는 데 중점을 두었다. Lin et al.(2023)은 검색-증강 명령어 튜닝 방법을 도입했으며, 이는 상위-\\(k\\)가 LLM 미세 조정에 대해 청크를 검색했다. 왕 등은 검색-증강 전처리 후 지시 튜닝을 적용하였다(2023). 대조적으로, 우리는 재확인이 있거나 문맥이 제공되는 세대를 개선하기 위해 2단계 지시 튜닝 방법을 제안한다. 우리는 LLM 미세 조정용 톱\\(k\\) 검색 청크를 적용하는 것이 광범위한 대화 QA 과제(자세한 내용은 SS6.3 참조)에 도움이 되지 않는다는 것을 발견했다.\n' +
      '\n' +
      'ChatGPT(오픈AI, 2022) 출시 후 지시 튜닝은 다양한 작업으로 제로 샷 능력을 놀라운 최첨단 대화 에이전트를 구축하는 필수 불가결한 성분이 된다. 대화 QA 역량은 대화 에이전트에서 중요한 역할을 하지만 이러한 중요한 측면에 전념하는 연구는 제한적이었다.\n' +
      '\n' +
      '## 3 ChatQA\n' +
      '\n' +
      '본 절에서는 ChatQA에 대한 2단계 지시 튜닝 방법을 제안한다. 그림 1을 일러스트에 참조하세요. 우리의 방법은 전처리된 LLM 기반 모델로 시작한다. 단계-1에서 우리는 지도 제거 및 대화 데이터 세트의 혼합에 오양 등(2022)에서와 같이 감독된 미세 조정(SFT)을 적용한다. 그 후, 우리의 모델은 대화 에이전트로 지침을 따를 수 있는 좋은 능력을 나타낸다. 그러나 맥락화되거나 RAG 기반 QA에 대한 능력은 여전히 한정적이다. 따라서 대화 QA에서 컨텍스트 인식 또는 검색-증강 생성에 대한 모델의 능력을 향상시키기 위해 특별히 설계된 컨텍스트 강화 명령어 튜닝이라고 하는 후속 단계를 소개합니다.\n' +
      '\n' +
      '####. Stage-1을 검색했습니다.\n' +
      '\n' +
      '크고 포괄적인 감독 미세 조정(SFT) 데이터 세트를 구성하기 위해 Xu et al.(2023b); 왕 et al.(2023a) 및 고품질 명령어 튜닝 데이터세트로부터의 128K SFT 샘플들의 결합된 세트를 수집했다. 정씨(위 et ali et al, 2022), 정씨(LLM et al., 2022), LLM 합성 명령어 튜닝 데이터 세트: 셀프-구조(Wang et al., 2022b), 3) LLM 합성 명령어 튜닝 데이터 세트: 자기-구성 데이터 세트(김 et al., 2022b), 비자연적인 설명서(호모비치 et al.\n' +
      '\n' +
      '우리는 모든 SFT 데이터의 구조를 대화 형식으로 통일한다. 우리는 먼저 LLM을 지도하는 일반적인 지시를 설정하여 예의와 도움이 되는 답변을 제공하기 위해 처음부터 "시스템" 역할을 추가한다. 우리는 또한 명령어 튜닝 데이터 세트로부터의 명령어 및 응답 쌍을 통합하기 위해 "사용자" 및 "보조" 역할을 추가한다. 우리는 LLM 기반 모델에 이 통일된 형식을 사용하여 미세 조정 작업을 적용한다.\n' +
      '\n' +
      '##-2: 텍스트 강화 보증\n' +
      '\n' +
      '주어진 맥락에 걸쳐 모델의 대화 QA 능력을 더욱 향상시키기 위해 컨텍스트화된 QA 데이터 세트를 명령어 튜닝 블렌드에 통합하는 제2 스테이지 명령어 튜닝을 수행한다. 구체적으로, 스테이지-2 명령어 튜닝 데이터셋은 컨텍스트화된 단일턴 QA 및 대화형 QA 데이터셋의 혼합으로 구성된다. 아래 단계-2 명령어 튜닝 데이터셋에 대한 자세한 내용을 제시한다.\n' +
      '\n' +
      '3.2.1.1 인간신고 데이터####### 3.2.1, 인간신고 데이터######\n' +
      '\n' +
      '공개 가능한 데이터 세트 외에도 스테이지-2의 핵심 요소 중 하나는 고품질 문서 지상 대화 QA 데이터 세트를 얻는 것이다. 우리는 7k 대화로만 구성된 인간 표지화된 대화 QA(이른바 인간 노티콘vQA) 데이터세트를 생성한다. 이 데이터 세트를 구축하기 위해 먼저 인터넷으로부터 다양한 주제를 다루는 7k 문서를 수집했다. 그런 다음 주석으로 하여금 문서에 대한 질문(및 후속 질문)과 답변을 제공하기 위한 에이전트로서 호기심 있는 사용자로 행동하도록 지시한다. 우리는 각 문서에 대한 멀티턴 대화를 만들어 대화당 평균 5개의 사용자-대리점 턴을 갖는 총 7k 대화 QA 대화들을 생성한다. 데이터 수집 지침의 세부 사항은 부록 G에서 확인할 수 있다.\n' +
      '\n' +
      '또한, 응답할 수 없는 사례에서 환각된 답을 줄이기 위해 주어진 맥락에서 답을 찾을 수 없을 때 모델을 명시적으로 나타내기 위해 권한을 부여하는 것을 목표로 한다. 이러한 허용 불가능한 데이터 샘플을 얻기 위해 주석을 요청하여 사용자 질문에 모든 컨텍스트 위치를 제공했습니다. 따라서 컨텍스트에서 해당 위치에서 텍스트를 삭제함으로써 응답할 수 없는 시나리오를 구성할 수 있도록 했다. 해당 텍스트를 질문에 삭제한 후, 응답할 수 없는 질문에 대한 응답으로 "미안해. 맥락을 바탕으로 답을 찾을 수 없다"는 문장을 사용한다. 마지막으로, 우리는 다른 1.5k 사용자-응답 가능한 주석으로 또 다른 1.5k 사용자-인가 턴을 구성하며, 이는 답변 가능 및 허용 불가능한 사례의 좋은 절충(자세한 내용은 SS6.5 참조)을 제공한다.\n' +
      '\n' +
      '합성 데이터 세대 3.2.2.2합성 데이터 세대#####\n' +
      '\n' +
      '인간 노화ConvQA의 품질을 검증하기 위해 GPT-3.5-turbo를 레버리지하여 합성 대화형을 생성한다.\n' +
      '\n' +
      '그림 1:2단계 ChatQA에 대한 명령어 튜닝 프레임워크.\n' +
      '\n' +
      'QA 데이터 세트는 강력한 명령어-폴딩 및 텍스트 생성 능력을 부여했습니다. 대화 QA를 위한 대규모 합성 데이터도 Dai et al.(2022)에서 탐구되었다. 이 작업에서 우리는 LLM 미세 조정에 대한 중형 고품질 합성 데이터에 초점을 맞추고 있다.\n' +
      '\n' +
      'GPT-3.5-투르보에 대한 명령어는 모델(1)이 유용한 답을 제공하기 위해 안내하는 시스템 역할, 필요한 데이터 유형을 나타내는 대화 QA의 예 2) 및 그 내용에 기초하여 대화 QA를 생성하기 위해 모델을 지시하는 문서(3)를 포함한다. 우리는 광범위한 영역을 덮는 공통 크롤에서 7k 문서(문서당 평균 \\(\\ason\\)1k 단어)를 수집한다. 각 문서는 단일 대화 QA 샘플의 생성에 사용되며, 이는 대화당 평균 4.4개의 사용자-대리점 변환(이른바 합성콘비큐A)을 갖는 총 7k 다중-턴 QA 대화들로 이어진다.\n' +
      '\n' +
      '인간 표지화된ConvQA와 유사한 결과로, 우리는 이 합성 데이터 세트에서 응답할 수 없는 주석으로 또 다른 1.5k 사용자-대리인 턴을 구성한다. 에이전트의 답을 위한 컨텍스트 위치의 주석은 없기 때문에 합성ConvQA에서 합성 허용 가능한 샘플을 구성한다. 구체적으로, 우리는 먼저 문서(각 대화에 대한)를 서로 다른 청크들로 절단했다. 그런 다음 "높은 중첩"을 갖는 청크가 제거되어야 할 에이전트의 답변과 있고 나머지 청크들은 에이전트 답변과 "낮은 중첩"을 보이는 경우에만 유효한 허용 가능한 표본으로 간주한다. 각 청크와 에이전트의 답변 사이의 4그램 리콜 점수(답의 4그램 문구의 비율이 각 청크 내에 있는 것을 측정)를 메트릭으로 사용하여 중첩을 측정하고 0.5보다 높은 것을 "높은 중복"으로 간주하고 0.1보다 낮은 것을 "저 중복"으로 간주한다.\n' +
      '\n' +
      '3.2.3개의 훈련블로그에 3.2.3개의 훈련블로그가 포함되어 있으며, 3.2.3개의 훈련블로그는##################이다.\n' +
      '\n' +
      '이 부분에서는 스테이지-2 지시 튜닝을 위한 훈련 블렌드의 세부 정보를 소개합니다. 탭 문서 및 산술 계산을 처리하는 QA 능력을 향상시키기 위해 두 요소를 모두 포함하는 TAT-QA 데이터세트(Zhu et al, 2021)를 추가한다. 또한, 컨텍스트화된 단일턴 QA 데이터 세트를 통합하여 모델의 QA 능력을 추가로 강화한다. 또한, 우리는 모델의 지시 제거 능력을 유지하기 위해 여전히 스테이지-1 SFT 데이터 세트를 트레이닝 블렌드에 유지한다.\n' +
      '\n' +
      '마지막으로, 단계-2에 대한 훈련 블렌드는 DROP(DuaconvQA 또는 Synthetic QA 데이터세트: DROP(DuaConvQA 또는 Synthetic QA) 단일-turn QA 데이터세트: NarrativeQA(Karinc et al.,2018), NarrativeQA(Dasigi et al.,2018), Quoref(Dasigi et al., 2019), ROPES(ROPES), ROPES(Lin et al., 2019), ROPES(Lin et al., ROPES), ROPES(Lin et al., 2019), ROPES(Lin et al., 2019), ROPES(Lin et al.,Lin et al., 2019), ROPES(Lin et al.,Lin et al., 2019), ROPES(ROPES), ROPES(Lin et al., 2019), ROPES(Lin et al., 2019), ROPES), SOPES(Lin et al., 2019), SOPES(Lin et al., 2019), SOPES), SOPES(Rajpurkar et al., 2019), SOPES\n' +
      '\n' +
      '달리 명시되지 않은 부트 1: Unless은 실험이 기본 설정으로 인간 안토티드ConvQA를 사용한다.\n' +
      '\n' +
      '우리는 모든 단일턴 QA 및 대화 QA 데이터 세트를 단일화하기 위해 스테이지-1에서와 유사한 템플릿을 따른다. 그 차이는 1) 시스템 역할에 따라 단일-턴 질문 또는 다중-턴 대화에 대한 관련 맥락을 충원하며, 2) 서로 다른 QA 데이터셋(예: 단답, 장답, 산술 계산)의 답변 유형에 기초하여 단일-턴 질문 또는 다중-턴 대화 직전에 추가 명령어를 통합한다. 우리는 스테이지-1. 2. 2의 SFT 데이터셋에 대한 포맷을 스테이지-1. 2의 SFT 데이터셋에 사용한다.\n' +
      '\n' +
      '단계-1 및 단계-2 명령어 튜닝과 합성 데이터 생성 모두에 대한 템플릿의 부록 2: 소매는 부록 A에서 찾을 수 있다.\n' +
      '\n' +
      '4번 QA를 회수합니다.\n' +
      '\n' +
      '대화 QA 작업에서 문서가 LLM으로 직접 먹이를 주기에는 너무 길어질 때 대화 질의를 처리할 수 있는 리트리버가 필수적이다. 이 대화 리트리버는 대화 이력 및 현재 질의의 연결을 인코딩한 다음 문서로부터 관련 컨텍스트를 검색한다. 그 후 LLM의 입력으로서 관련 컨텍스트만 사용될 것이다. 드래곤(Lin et al., 2023)과 같은 최첨단 검색기는 단일턴 질의에 최적화되어 다중턴 대화 질의에 대한 제한된 일반화 능력을 초래한다. 그림 2에서 우리는 이 문제를 완화하기 위해 재역적 미세 조정 방법을 묘사했다. 대화 입력에 더 잘 대처하기 위해 단일턴 리트리버를 추가로 미세화하기 위해 대화 질의 및 컨텍스트 쌍을 사용할 것을 제안한다.\n' +
      '\n' +
      '대안적인 해결책은 질의 재작성기를 사용하여 대화 이력에 기초하여 현재 질문을 재작성하는 대화 질의 재작성 방법이다. 그런 다음 리필된 쿼리는 관련 컨텍스트를 검색하기 위한 단일턴 쿼리 리트리버에 대한 입력으로 직접 사용된다. 쿼리 재작성 모델은 임베딩 및 검색 비용 외에도, 재작성 쿼리를 생성하기 위해 많은 양의 추가 계산 비용을 도입한다.\n' +
      '\n' +
      '그림 2: 멀티턴 QA에 대한 미세 조정 재순환의 일화이다.\n' +
      '\n' +
      '멀티턴 QA를 위해 리모델링을 할 수 있습니다.\n' +
      '\n' +
      '고품질 미세 조정 데이터 세트를 구축하기 위해 인간 안치된ConvQA 또는 합성ConvQA에서 대화형 QA 데이터 세트를 레버리지하여 대화 질의 및 컨텍스트 쌍을 구성한다.\n' +
      '\n' +
      '인간 안치된ConvQA의 경우, 우리는 대화 질의와 컨텍스트 쌍의 주석을 직접 취하고, 이를 사용하여 단일턴 쿼리 리트리버를 추가로 미세 조정한다. 합성ConvQA의 경우, 우리는 먼저 대화 QA 데이터 세트의 각 문서를 다른 청크로 절단했다. 그런 다음 에이전트 답변과 각 청크 사이의 4그램 리콜 점수를 계산합니다. 그 후, 우리는 리콜 점수가 가장 높은 청크를 현재 사용자의 질문에 대한 금 청크로 간주한다. 마지막으로, 구성된 대화 질의 및 컨텍스트 쌍은 단일턴 질의 리트리버를 미세 조정하기 위해 사용된다.\n' +
      '\n' +
      '대략적인 쿼터 작성.\n' +
      '\n' +
      '강력한 대화 질의 재작성 모델을 구축하기 위해 갈림자노바(2023)가 GPT-3.5-투르보를 사용하여 최첨단 질의 재작성 결과를 입증했다는 점을 감안할 때 GPT-3.5-투르보를 리글라이저로 취한다. 갈림자노바(2023)와 유사하게 GPT-3.5-투르보에게 재작성 작업 지시를 제공할 뿐만 아니라 재작성 결과의 품질을 높이기 위해 몇 가지 샷 재작성 예시를 제공한다. 보다 자세한 내용은 부록 B.1에서 찾을 수 있다.\n' +
      '\n' +
      '### Comparisons\n' +
      '\n' +
      '표 1에서 우리는 제로 샷 설정에서 5개의 데이터셋에 걸쳐 쿼터 재작성 및 미세 조정 방법을 비교한다. 이러한 데이터셋에 대한 자세한 내용은 SS5.2.1에서 확인할 수 있다. 우리는 MS MACRO(Nguyen et al. 2016.Nguyen et al. 2016.)에 적합하지 않은 최첨단 레트리버, 드래곤(Lin et al., 2023), 강력한 비지도 리트리버인 E5(Wang et al., 2022)에 대한 실험을 수행한다. 드래곤에 대한 실험 측면에서, 우리는 미세 조정이 평균 상위 1회 리콜에서 1.74%로 질의 재작성보다 약간 더 악화되는 반면 평균 상위 5회 리콜에서 0.54% 더 나은 결과를 달성한다는 것을 발견했다. 대화 검색에 대한 미세 조정 접근법의 효과를 보여준다. 또한, 우리는 결과가 미세 조정에 대해 인간 노토화ConvQA와 합성ConvQA를 사용하는 것 간에 비슷하다는 것을 관찰했다. 이것은 우리의 인간 표시 데이터셋이 고품질임을 강조하며, 우리는 _do가 최첨단 멀티턴 쿼리 리트리버를 구축하기 위한_ ChatGPT 모델에 의존하지 않는다는 것을 강조한다.\n' +
      '\n' +
      '놀랍게도, 미세 조정은 E5를 재작성하는 것보다 훨씬 더 나은 성능을 발휘합니다. 우리는 E5가 요약된 것은 이전에 훈련하는 단계에서 인간 미표시 질의와 컨텍스트 쌍을 사용하지 않기 때문에 고품질 재작성 질의에 대한 약한 일반화를 초래한다는 것을 추측한다. 대조적으로, 고품질의 데이터 세트를 사용하여 미세 조정 E5 점수를 사용하는 것은 평균 상위 1점 및 상위 5점 리콜 점수 모두에서 15% 이상의 개선으로 거대 부스트를 가져온다.\n' +
      '\n' +
      '따라서 고품질 대화 질의 컨텍스트 쌍에 좋은 단일턴 리트리버를 미세 조정하면 최첨단 리글라이저를 활용하는 것과 일치한다. 그러나 재작성 방법은 자가회귀 생성 과정에 대한 추가 계산 시간과 아마도 GPT-3.5-투르보와 같은 강력한 모델을 사용하기 위한 API 비용도 필요하다. 대조적으로, 제안된 멀티턴 미세 조정은 이러한 문제를 우회한다. 이 5개의 데이터 세트에 걸친 QA 평가를 위해 모든 QA 모델에 대해 미세 조정 접근법에서 검색된 상위 5 결과를 일관되게 사용한다. 우리는 부록 B.2에서 재작성 방법과 미세 조정 방법 간의 비교에 더 많은 결과를 두었다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c c c c c c c c c c} \\hline \\hline \\multirow{2}{*}{Models} & \\multirow{2}{*}{Average} & \\multicolumn{2}{c}{Doc2Dial} & \\multicolumn{2}{c}{QuAC} & \\multicolumn{2}{c}{QReCC} & \\multicolumn{2}{c}{TopiOCQA} & \\multicolumn{2}{c}{INSCIT} \\\\ \\cline{2-11}  & top-1 & top-5 & top-1 & top-5 & top-1 & top-5 & top-1 & top-5 & top-5* & top-20* & top-5* & top-20* \\\\ \\hline Adlakha et al. (2022) & - & - & - & - & - & - & - & - & - & 70.40\\({}^{\\triangle}\\) & - & - \\\\ Wu et al. (2023) & - & - & - & - & - & - & - & - & - & - & - & 71.10\\({}^{\\triangle}\\) \\\\ \\hline E5-unsupervised\\({}^{\\dagger}\\)(Wang et al., 2022) & 31.56 & 59.22 & 23.02 & 55.33 & 43.49 & 77.68 & 44.71 & 84.99 & 26.25 & 37.67 & 20.32 & 40.44 \\\\ E5-unsupervised + Rewrite\\({}^{\\ddagger}\\) & 33.23 & 61.02 & 25.56 & 58.00 & 46.00 & 80.01 & 45.50 & 85.89 & 27.58 & 39.15 & 21.53 & 42.04 \\\\ ES-unsupervised + Fine-tune\\({}^{\\ddagger}\\) & **47.79** & **75.00** & 45.28 & 80.96 & 46.52 & 80.74 & 53.37 & 89.91 & 41.01 & 51.07 & 52.79 & 72.31 \\\\ \\hline Dragon\\({}^{\\dagger}\\)(Lin et al., 2023) & 46.29 & 73.09 & 43.33 & 75.61 & 56.80 & 82.86 & 46.17 & 81.96 & 57.68 & 78.80 & 27.49 & 46.22 \\\\ Dragon + Rewrite\\({}^{\\dagger}\\) & **54.46** & 80.13 & 47.60 & 80.60 & 47.10 & 77.15 & 51.73 & 58.78 & 73.07 & 88.19 & 52.79 & 68.92 \\\\ Dragon + Fine-tune\\({}^{\\dagger}\\) & 52.72 & **80.67** & 48.94 & 83.01 & 52.64 & 81.95 & 50.73 & 87.17 & 67.86 & 86.28 & 43.43 & 64.94 \\\\ - SyntheticConvQA\\({}^{\\diamond}\\) & 52.98 & **81.15** & 48.64 & 83.47 & 54.75 & 83.23 & 49.63 & 86.70 & 64.48 & 85.24 & 47.41 & 67.13 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 1: 평균 상위-1 및 상위-5 리콜 점수를 갖는 5개의 멀티턴 QA 데이터 세트에 걸쳐 반환 결과를 보여준다. 재작성하는 것에 비해 미세 조정은 E5로 구현되고 드래곤에서 비슷하기 위해 훨씬 더 나은 성능을 발휘합니다. *는 TopiOCQA 및 INSCIT의 평균 상황 길이가 다른 데이터 세트보다 작기 때문에 상위-5 및 상위-20을 보고하여 다른 데이터 세트에서는 각각 상위-1 및 상위-5의 컨텍스트 길이와 대략 일치하도록 보고한다. ({}^{\\dagger}\\) 이 두 모델의 입력은 대화 역사와 현재 질의의 연결이다. 이 모델의 입력은 재작성 질의이다. \\({}^{\\ddagger}\\) ({}^{\\diamond}\\) 몰테스는 인간 노광된ConvQA 데이터셋이 미세 조정용 SyntheticConvQA로 대체된다는 것을 나타낸다. ({}^{\\triittee}\\) 수는 사과 대애플 비교(예를 들어 미세 조정을 위해 훈련 세트를 사용하는 것)가 아니다.\n' +
      '\n' +
      '5개의 통찰력을 제공합니다.\n' +
      '\n' +
      '이 절에서는 대화형 질문 답변 과제에 대한 실험 설정의 세부 사항을 제시한다.\n' +
      '\n' +
      '### Baselines\n' +
      '\n' +
      '다양한 모델 크기에 대한 실험을 수행합니다. 먼저, 스테이지-2 컨텍스트 강화 명령어 튜닝의 효과를 보여주기 위해 스테이지-1 감독 미세 조정 후 라마2-7B/13B/70B 기반 모델인 **Llama2-SFT-7B/13B/70B**와 비교한다(SFT). 둘째, 우리는 라마2-챗봇 모델이 변환 QA 능력(Touvron et al, 2023)에 따라 강한 지시를 갖는 것으로 나타났기 때문에 **Llama2-Chat-7B/13B/70B**와 비교한다. Llama2 모델 외에도 사내 GPT-8B 기반 모델에 대한 실험을 수행하고 단계-1 SFT 기준선(**GPT-8B-SFT**)과 비교한다. 마지막으로 **GPT-3.5-투르보(4k)** 및 **GPT-4(8k)**의 두 가지 매우 강력한 오픈AI 모델과 비교한다. 공정 비교를 위해 모델과 기저부에 대한 입력과 동일한 맥락을 사용한다. 가능한 가능한 결과를 최대한 잘 달성할 수 있도록 모든 기저부에 대한 지침을 조심스럽게 조정했습니다.3.3\n' +
      '\n' +
      '부츠 3: 이러한 기저부에 대한 프롬프트는 부록 C에서 찾을 수 있다.\n' +
      '\n' +
      '### Evaluation Benchmarks\n' +
      '\n' +
      '롱다큐멘터리 다타셋셋 5.2.1 롱다큐멘터리 데이터베이스### 5.2.1.\n' +
      '\n' +
      '4K 토큰의 시퀀스 길이를 갖는 LLM에 직접 장착할 수 없는 긴 문서를 가진 5개의 대화 QA 데이터 세트를 수집한다. 따라서 우리는 입력(경험은 SS4.3에서 찾을 수 있기 때문에 상위 5개의 관련 청크를 얻기 위해 멀티턴 리트리버를 운영한다.\n' +
      '\n' +
      '* Doc2Dial(Feng et al., 2020)은 DMV, SSA, VA 및 학생 보조제의 4가지 영역을 포함하는 문서 지상 대화 QA 데이터세트이다. 각 샘플은 사용자가 문서에 대한 질문을 제기하는 대화로 구성되며 에이전트는 해당 질문에 응답한다. 평균 문서 길이는 약 101K 단어입니다.\n' +
      '* QuAC(최 등 2018)는 위키피디아 문서를 기반으로 합니다. 원래는 문서가 짧습니다. 각 대화는 여러 위키피디아 URL과 연결되기 때문에 이러한 링크에서 텍스트를 추출하여 문서 크기를 약 평균 15K 단어로 증가시킨다. 주어진 맥락에서 답을 찾을 수 없는 미답변 사례를 포함하고 있다.\n' +
      '* QReCC(Anantha et al., 2021)는 여러 출처에 걸쳐 열린 도메인 변환 QA 데이터세트이다. CapAC와 유사하게 각 대화에는 대응하는 URL도 있습니다. 우리는 해당 URL에서 문서를 구성하기 위해 텍스트를 추출합니다. 결국 평균 문서 크기는 약 5K 단어이며, 최대 문서 크기는 20K 단어이다.\n' +
      '* TopiOCQA(Adlakha et al., 2022)는 위키피디아 전체에 접지되어 있다. 주제 전환을 통합하고 에이전트가 사용자 질문에 대한 답변을 위해 위키피디아 전체를 검색하도록 요구한다.\n' +
      '* INSCIT(Wu et al., 2023)도 위키피디아 전체에 갈렸다. 사용자 질문이 과소 지정되고 설명이 필요한 경우를 연구한다.\n' +
      '\n' +
      'Doc2Dial, QuAC 및 QReCC의 경우 약 300-워드 청크로 문서를 분할하고 사용자 질문마다 컨텍스트로 상위-5개의 관련 청크를 검색한다. 토티오CQA와 INSCIT의 경우 원래 분할을 따르고 있어 청크가 더 작습니다. 따라서, 우리는 상위 20개의 청크를 검색하여 처음 세 개의 데이터 세트와 유사한 컨텍스트 길이를 얻었다.\n' +
      '\n' +
      '5.2.2개의 짧은 문서 다타셋 세트 5.2.2개의 짧은 문서 데이터베이스#####\n' +
      '\n' +
      '문서 길이의 다양성을 높이기 위해 짧은 문서(1.5K 단어 미만)가 있는 5개의 대화 QA 데이터 세트를 수집한다. 평균적으로 1단어는 1.5 토큰으로 토큰화된다. 따라서, 문서는 4K 토큰의 시퀀스 길이를 갖는 LLM 내에 직접 끼워질 수 있다.\n' +
      '\n' +
      '* CoQA(레드디 et al., 2019)는 짧은 통로에서 각 대화가 접지된 대화형 QA 데이터세트이다. 답변은 일반적으로 짧으며, 통로는 어린이 이야기, 문학, 중·고등학교 시험, 뉴스, 위키피디아와 같은 광범위한 영역을 다루고 있다.\n' +
      '* DoQA(Campos et al, 2020)는 활발한 스타크 거래소4 포럼에서 수집한 요리, 여행, 영화 등 세 가지 영역을 다룬다. 데이터셋에는 주어진 문서 내에서 답을 찾을 수 없는 미답변 사례가 포함되어 있다. 폐지 4: [국정신경사체 변화.com/] (국부신경사체 변화.com/)\n' +
      '* ConvFinQA(Chen et al., 2022)는 금융 영역을 기반으로 한다. 각 문서에는 테이블을 둘러싼 관련 텍스트와 함께 단일 재무보고표가 포함되어 있다. 이 데이터 세트는 산술 계산 및 복잡한 수치 추론을 포함한다.\n' +
      '* SQA(Pasupat and Liang, 2015)는 주변 텍스트 없이 단 하나의 표만을 포함하는 문서에 근거한다. 문서는 위키피디아에서 수집되며, 질문은 구성이 매우 높기 때문에 정확한 답변을 할 수 있는 강력한 테이블 이해 능력을 가진 모델이 필요하다.\n' +
      '* 하이브리드Dial(나카무라 등 알, 2022)은 위키피디아 표와 텍스트 데이터를 모두 포함하는 문서에 접지된 대화형 QA 데이터세트이다. 문항에 대한 추론이 필요한 질문은 복잡하다.\n' +
      '\n' +
      '모든 10개의 데이터 세트 동안 ConvFinQA, SQA 및 하이브리드-Dial 데이터 세트는 문서에 표 데이터를 포함하는 반면 나머지 데이터 세트의 문서는 텍스트 전용.5이다.\n' +
      '\n' +
      '이러한 벤치마크 데이터 세트의 부록 5: 소매는 부록 C에 있다.\n' +
      '\n' +
      '### Evaluation Metrics\n' +
      '\n' +
      'F1 점수가 QA 모델을 평가하기 위해 가장 일반적으로 사용되는 자동 메트릭이라는 점을 감안할 때 ConvFinQA를 제외하고 모든 데이터 세트에 사용한다. 콘비핀QA에서 ConvFinQA의 답변이 산술 계산뿐만 아니라 문서로부터 숫자를 추출하는 것이기 때문에 정확한 일치 메트릭을 사용하기 위해 Chen et al.(2022)를 따른다. 따라서 답은 정답과 정확히 같을 때만 의미가 있다. 모델이 연산식을 생성할 때 계산기를 기반으로 최종 결과를 계산하고 금 답과 비교할 것이다.\n' +
      '\n' +
      '또한, 우리는 또한 최고의 모델과 GPT-4 사이의 생성된 답변의 올바른 가능성을 평가하기 위해 인간 평가를 수행한다.\n' +
      '\n' +
      '## 6 Results\n' +
      '\n' +
      '### Main Results\n' +
      '\n' +
      '#### 6.1.1 overview\n' +
      '\n' +
      '표 2에서 10개의 대화 QA 데이터 세트에 걸쳐 서로 다른 모델 변이체 및 OpenAI 모델을 비교한다.\n' +
      '\n' +
      '우리는 ChatQA 방법이 모델의 대화 QA 능력을 크게 향상시킨다는 것을 발견했다. 평균 점수 측면에서 라마2-챗 모델은 작은 마진으로 SFT 모델 대응물을 능가하는 반면, 우리의 ChatQA 모델은 SFT 및 Chat 대응물에 대해 약 10점 이상의 절대 개선을 달성한다. 예를 들어, ChatQA-13B는 Llama2-13B-SFT 및 Llama2-13B-Chat에서 13.17(37.69~50.86) 및 10.52(40.34~50.86) 각각 개선된다. 상황 강화 명령어 미세 조정은 모델이 검색되거나 관련된 맥락에서 유용한 정보를 효과적으로 추출하는 방법을 학습할 수 있기 때문이다.\n' +
      '\n' +
      '오픈AI 모델에 비해 최고의 모델 ChatQA-70B는 GPT-3.5-turbo를 3.77 평균 점수로 초과하고 GPT-4를 0.24 평균 점수로 약간 능가한다. 또한, 훨씬 더 작은 크기의 ChatQA-13B는 평균 점수 0.49로 GPT-3.5-turbo를 약간 능가할 수 있다.\n' +
      '\n' +
      '1 SFT-1 SFT-1 SFT#################### 6.1.2의 기준치 6.1.2.\n' +
      '\n' +
      '표 2에서 ChatQA의 능력에 따라 지시를 향상시키는 단계-1 SFT의 중요성에 대한 절제 연구를 수행한다. 우리는 미세 조정 단계에서 스테이지-1 SFT를 제거하고 파운데이션 LLM 위에 스테이지-2 컨텍스트 강화 명령어 튜닝만 적용한다. 우리는 평균 점수가 1.9점(54.08점에서 52.18점)으로 감소한다는 것을 알게 된다. SQA 외에도 스테이지-1을 제거하는 것은 모델을 다른 데이터 세트에 대해 일관되게 더 악화시킨다. 결과는 단계-1의 모든 SFT 데이터 세트를 통해서도 단계-1이 여전히 중요한 역할을 한다는 것을 나타낸다. 우리는 먼저 지시 제거 능력을 구축하는 것이 스테이지-2 튜닝에 유익하다는 것을 보여준다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c c c c c c c c c} \\hline \\hline Models & Average & Doc2Dial & QuAC & QReCC & CoQA & DoQA & ConvFinQA & SQA & TopiOCQA & HybridDial & INSCIT \\\\ \\hline GPT-8B-SFT & 34.46 & 31.03 & 20.07 & 37.69 & 59.24 & 21.72 & 15.44 & 40.06 & 38.17 & 52.29 & 28.86 \\\\ ChatQA-8B & **49.36** & 36.76 & 33.95 & 45.54 & 77.90 & 44.65 & 61.68 & 60.74 & 47.03 & 53.81 & 31.50 \\\\ \\hline Llama2-7B-SFT & 34.81 & 30.26 & 19.21 & 37.55 & 62.75 & 21.76 & 34.43 & 32.18 & 32.88 & 48.96 & 28.16 \\\\ Llama2-7B-Chat & 38.86 & 33.27 & 25.83 & 46.02 & 72.28 & 33.15 & 36.58 & 26.14 & 36.68 & 47.02 & 31.67 \\\\ ChatQA-7B & **47.71** & 37.88 & 29.69 & 46.97 & 76.61 & 41.57 & 51.61 & 61.87 & 45.45 & 54.51 & 30.96 \\\\ \\hline Llama2-13B-SFT & 37.69 & 30.68 & 21.59 & 38.25 & 69.52 & 21.70 & 41.14 & 37.85 & 35.26 & 52.22 & 28.73 \\\\ Llama2-13B-Chat & 40.34 & 34.74 & 27.89 & 47.19 & 72.50 & 32.60 & 41.54 & 25.39 & 39.25 & 49.82 & 32.52 \\\\ ChatQA-13B & **50.86** & 38.05 & 34.28 & 48.06 & 77.23 & 43.31 & 65.44 & 66.41 & 48.88 & 56.19 & 30.79 \\\\ \\hline Llama2-70B-SFT & 43.22 & 34.42 & 25.65 & 41.88 & 73.04 & 28.21 & 46.64 & 58.90 & 37.20 & 55.52 & 30.71 \\\\ Llama2-70B-Chat & 45.21 & 36.87 & 32.47 & 49.40 & 80.41 & 38.97 & 46.85 & 37.62 & 44.31 & 50.35 & 34.88 \\\\ ChatQA-70B & **54.14** & 38.90 & 41.82 & 48.05 & 78.57 & 51.94 & 73.69 & 69.14 & 50.98 & 56.44 & 31.90 \\\\ - SyntheticConvQA\\({}^{\\diamond}\\) & **54.08** & 39.19 & 38.33 & 48.73 & 79.83 & 48.65 & 76.44 & 68.63 & 51.30 & 55.68 & 33.98 \\\\ - w/o stage-1\\({}^{\\dagger}\\) & 52.18 & 38.43 & 37.52 & 46.08 & 73.51 & 49.42 & 72.15 & 72.08 & 51.28 & 50.74 & 30.56 \\\\ - w/o single-turn* & 52.25 & 38.30 & 37.89 & 47.08 & 76.74 & 46.43 & 72.42 & 67.41 & 49.85 & 53.16 & 33.18 \\\\ \\hline GPT-3.5-turbo (4k) & 50.37 & 34.83 & 37.17 & 50.46 & 79.33 & 41.11 & 73.15 & 60.63 & 44.30 & 47.42 & 35.27 \\\\ GPT-4 (8k) & **53.90** & 34.16 & 40.29 & 52.01 & 77.42 & 43.39 & 81.28 & 79.21 & 45.09 & 49.81 & 36.34 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 2: 10개의 데이터셋에 걸친 제로 샷 변환 QA 결과. \\ 10개의 데이터셋에 걸친 제로 샷 변환 QA 결과는 표 2: ({}^{\\\\diamond}\\)는 인간 노광된ConvQA가 합성ConvQA로 대체되었음을 나타낸다. ({}^{\\dagger}\\)는 스테이지-1(SFT)을 제거하고 ChatQA 스테이지-2 튜닝만을 적용함을 나타낸다. *데노트는 ChatQA 스테이지-2 트레이닝 블렌드에서 단일턴 QA 데이터 세트가 제거된다는 것을 나타낸다. "w/o 스테이지-1" 및 "w/o 단일턴" 설정 모두 합성ConvQA 데이터를 사용한다. 평균 점수 측면에서 ChatQA 모델은 SFT 및 Chat 대응물을 크게 능가하고 최고의 모델 ChatQA-70B는 GPT-4를 약간 능가한다.\n' +
      '\n' +
      '단일-턴 데이터##### 6.1.3의 단일-턴 데이터 데이터 유효성 6.1.3.3의 효과성.\n' +
      '\n' +
      '단일턴 QA 데이터셋이 모델의 다중턴 QA 능력에 어떻게 영향을 미치는지 조사하기 위해 스테이지-2의 ChatQA-70B 훈련 블렌드에서 제거함으로써 절제 연구를 수행하는데, 표 2와 같이 단계-2 훈련 블렌드에 단일턴 QA 데이터셋(ChatQA-70B)을 통합하면 일반적으로 모든 벤치마크 데이터셋에 점수가 증가하여 평균 1.83 점수로 이어진다. 흥미롭게도 추가된 단일턴 QA 데이터 세트에도 불구하고 ConvFinQA, SQA 및 하이브리드Dial(테이블 기반 데이터 세트)의 개선을 관찰한다. 이러한 결과는 직관과 일치합니다. 단일턴 데이터 세트를 추가하면 문맥으로부터 답을 추출하는 모델의 능력이 향상되어 대화 QA 데이터 집합에서 더 나은 점수를 얻는다.\n' +
      '\n' +
      '#### 6.1.4 인간노화 데이터 대. 5.5터보 합성 데이터PT-3.5-터보 합성 데이터\n' +
      '\n' +
      '우리는 인간-개방형 QA 모델을 사용하여 7k GPT 및 DoQA 데이터 세트에 대한 상당한 개선을 달성하지 못한다는 것을 발견했으며, 이는 인간-개방형 데이터 세트(인간-합성 데이터 세트)와 수집된 7k 데이터 세트에 대해 더 높은 품질을 가질 수 있음을 시사하며, 이는 인간-개방형 데이터 세트(인간-합성 데이터 세트)를 사용하여 ChatQA 모델을 사용하여 평균 점수 측면에서 비교될 필요가 없다는 것을 알 수 있다.\n' +
      '\n' +
      '인체평가 6.1.5의 인적평가##### 6.1.5의 인적평가##### 6.1.5입니다.\n' +
      '\n' +
      'F1 점수는 QA 모델의 품질을 평가하기 위해 가장 일반적으로 사용되는 메트릭임에도 불구하고, 질문에 답할 수 있는 여러 가지 방법이 종종 있어 자동 메트릭이 완벽한 것보다 적다. 따라서 우리는 ChatQA-70B 및 GPT-4의 출력과 GPT-4의 결과를 추가로 비교하기 위해 인간 평가를 사용하고 질문6에 대한 정확한 반응을 결정하는 것을 주석으로 요청하며, 10개의 데이터 세트에 대한 인간 평가 결과는 표 3에 나와 있으며, 먼저 ChatQA-70B 및 GPT-4가 대부분의 시간(69.09%), GPT-4가 우리보다 약간 더 높은 승률(\\(\\ Res\\)3.3%)을 달성한다는 것을 알게 되었다. 이것은 우리의 모델이 정답을 생성하는 강력한 능력을 가지고 있음을 추가로 확인시켜준다. 둘째, 우리는 우리의 모델이 모델의 강력한 산술 계산 능력을 나타내는 ConvFinQA에서 GPT-4보다 약간 더 나은 승률을 달성한다는 것을 발견했다. 셋째, 우리는 GPT-4가 SQA 작업에서 훨씬 더 나은 승률을 달성한다는 것을 발견하며, 이는 표상 추론 작업에 대한 우리의 모델과 GPT-4 사이에 여전히 격차가 있음을 시사한다.\n' +
      '\n' +
      '부표 6: 모자의 인적 평가 설정은 부록 D에서 찾을 수 있다.\n' +
      '\n' +
      '### Fine-grained Analyses\n' +
      '\n' +
      '표 4에서 대화 QA 벤치마크에서 다양한 데이터세트 유형에 걸쳐 모델과 OpenAI 모델을 추가로 비교했다. ChatQA-70B와 GPT-4의 비교에서 ChatQA-70B는 텍스트 전용 문서(avg-텍스트)에서 더 나은 결과를 달성하며, 이는 우수한 텍스트 이해 능력을 보여준다. 그러나 GPT-4는 아바테이블의 비교를 고려할 때 표형 데이터에서 더 나은 QA 능력을 보여준다. 검색이 필요하거나 필요하지 않은 데이터 세트는 ChatQA-70B 및 GPT-4가 비슷(캡은 평균 점수 1 이내)한다.\n' +
      '\n' +
      'ChatQA-13B와 GPT-3.5-turbo 사이의 비교에서 ChatQA-13B와 GPT-3.5-turbo 사이의 비교에서\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c c c} \\hline \\hline Models & Avg-text & Avg-table & Avg-ret & Avg-nonret \\\\ \\hline ChatQA-13B & 45.80 & 62.68 & 40.01 & 61.72 \\\\ ChatQA-70B & **48.88** & 66.42 & **42.33** & 65.96 \\\\ \\hline GPT-3.5-turbo (4k) & 46.07 & 60.40 & 40.41 & 60.33 \\\\ GPT-4 (8k) & 46.96 & **70.10** & 41.58 & **66.22** \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 4: 다양한 데이터세트 유형의 평균 점수에 대한 연구였다. 아그-텍스트는 문서들이 Doc2Dial, QuAC, QReCC, CoQA, DoQA, Topi-OCQA 및 INSCIT를 포함한 텍스트만 갖는 데이터셋을 포함한다. 아그 테이블은 ConvFinQA, SQA 및 하이브리드Dial을 포함한 문서에 테이블을 갖는 데이터 세트를 커버한다. 아그레트 커버는 Doc2Dial, QuAC, QReCC, TopiOCQA 및 INSCIT를 포함하여 검색이 필요한 긴 문서를 갖는 데이터셋을 포함한다. 아그-비레트 커버는 CoQA, DoQA, ConvFinQA, SQA 및 하이브리드Dial을 포함하여 검색이 필요하지 않은 짧은 문서를 갖는 데이터셋을 포함한다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c c} \\hline \\hline  & Ours Win & Tie & GPT-4 Win \\\\ \\hline Average & 13.81\\% & 69.09\\% & 17.10\\% \\\\ \\hline Doc2Dial & 14.29\\% & 68.00\\% & 17.71\\% \\\\ QuAC & 11.67\\% & 73.33\\% & 15.00\\% \\\\ QReCC & 11.11\\% & 77.22\\% & 11.67\\% \\\\ CoQA & 7.78\\% & 80.00\\% & 12.22\\% \\\\ DoQA & 22.78\\% & 57.78\\% & 19.44\\% \\\\ ConvFinQA & 16.67\\% & 67.78\\% & 15.55\\% \\\\ SQA & 11.11\\% & 61.67\\% & 27.22\\% \\\\ TopiOCQA & 19.31\\% & 60.69\\% & 20.00\\% \\\\ HybridDial & 7.78\\% & 78.33\\% & 13.89\\% \\\\ INSCIT & 15.56\\% & 66.11\\% & 18.33\\% \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '10개의 데이터셋에 걸쳐 ChatQA-70B와 GPT-4를 비교한 인간 평가(A/B 테스트)는 표 3과 같다. 평균 점수 측면에서 우리의 모델과 GPT-4는 대부분의 시간(69.09%), GPT-4는 우리보다 약간 높은 승률(\\(\\ Res\\)3.3%)을 달성한다.\n' +
      '\n' +
      'ChatQA-13B는 Avg-테이블의 점수를 감안할 때 더 나은 표형 QA 능력을 보여준다. ChatQA-13B는 또한 검색이 필요 없는 문서가 있는 데이터셋에서 더 나은 점수를 나타내는 반면 텍스트 전용 문서 및 검색이 필요한 문서에서 GPT-3.5-turbo와 일치한다.\n' +
      '\n' +
      '스테이지-2 인스트라이지-2 천골에는 탑-\\(k\\)가 포함됩니다.\n' +
      '\n' +
      '단계-2 튜닝에 의해 사용되는 모든 데이터셋에 대해, 컨텍스트는 답을 포함하는 연속 단락 또는 문서로서 제공된다. 대조적으로, 모델은 긴 문서들에 대해 추론에서 탑\\(k\\) 검색 청크를 처리할 필요가 있다. 이러한 열차/테스트 불일치를 줄이기 위해, 우리는 일부 연속 단락들을 검색된 톱크 청크로 대체하는 것이 모델의 견고성을 향상시킬 것인지 여부를 조사한다.\n' +
      '\n' +
      '우리는 이 연구를 위해 NarrativeQA를 사용하는데, 각 질문은 상응하는 긴 문서를 가지고 있기 때문이다. NarrativeQA의 경우 원래 긴 문서의 요약본을 답안을 포함하는 맥락으로 사용한다. 불연속적인 맥락을 통합하기 위해 우리는 먼저 긴 문서를 300-워드 청크로 절단했다. 그런 다음 드래곤 레트리버를 사용하여 추가 맥락으로 질문에 상위 4개의 청크를 회수합니다. 마지막으로, 검색된 4개의 청크와 긴 문서의 요약을 "톱-5" 청크라고 한다. 7 우리는 이 재구성된 NarrativeQA를 사용하여 단계-2 명령어 튜닝에 대한 원래 것을 대체한다.\n' +
      '\n' +
      '부츠 7: 노트, 우리는 답을 포함하지 않을 수 있기 때문에 훈련을 위해 상위 5개의 검색된 청크를 직접 사용하지 않았다. 이러한 경우, 답을 생성하기 위해 모델을 미세 조정하면 복당을 장려할 수 있다.\n' +
      '\n' +
      '표 5에서 훈련의 맥락으로 "톱-5" 청크를 사용하는 것이 검색이 필요한 데이터 세트의 개선으로 이어진다는 것을 발견했다. 그러나 이것은 비재수출 데이터셋에 대한 성능을 하향 조정합니다. 전반적으로, 이 두 모델은 비슷합니다. 스테이지-2 튜닝에 검색된 \'톱-5\'를 통합하는 것은 검색이 필요한 추론 단계와 정렬되어 Avg-ret 점수가 향상되기 때문이다. 그러나 연속적이고 불연속적인 문서를 혼합하면 스테이지-2 튜닝이 덜 안정적이게 되어 비지정 데이터셋에서 최적이 아닌 결과를 초래할 수 있다. 우리는 스테이지-2 튜닝에 연속적인 컨텍스트와 탑-\\(k\\) 검색 청크를 통합하는 균형에 대해 더 많은 미래 작업을 수행할 수 있다고 믿는다.\n' +
      '\n' +
      '에포트스테이트에 대한 규제\n' +
      '\n' +
      '표 6에서 검색된 컨텍스트/춘크 수, 컨텍스트 순서 및 상이한 검색자가 대화 QA 결과에 어떻게 영향을 미치는지 절제 연구를 보여준다.\n' +
      '\n' +
      '먼저, 더 많은 컨텍스트를 입력으로 사용하는 것이 항상 결과를 개선하는 것은 아니라는 것을 알게 된다. 상위-5 컨텍스트를 입력으로 사용하면 상위-3 또는 상위-10 컨텍스트를 사용하는 것에 비해 더 나은 결과를 얻을 수 있다. 직관적으로, 더 많은 맥락들은 정답(더 빠른 회상 점수)을 포함할 확률이 더 높다. 그 결과 톱-5 컨텍스트를 사용하면 톱-3을 사용하는 것보다 더 나은 결과를 얻을 수 있지만, 맥락의 수가 더 증가함에 따라 모델은 "중도(Liu et al, 2023) 현상(Liu et al., 2023)으로 고통받고 제공된 맥락에서 답을 추출하는 어려움도 증가할 수 있으며, 이는 상위-10 컨텍스트를 사용하여 열등한 결과로 이어질 수 있다.\n' +
      '\n' +
      '둘째, 상위 5개 맥락의 서로 다른 순서를 사용하는 것이 결과에 어떤 영향을 미치는지를 연구한다. 우리는 순차 주문(1\\)부터 \\(5\\) 맥락까지의 순차 주문(5\\)을 비교하여 (5\\에서 \\(1\\) 맥락의 역주문), 스윙 주문(중간에서의 비용) 현상, 즉 입력 컨텍스트의 시작과 끝에 나타나는 가장 관련된 맥락을 배열한다. 따라서 주문량은 \\(\\{1\\)st, \\(3\\)rd, \\(5\\), \\(4\\)th, \\(2\\)\\(\\}\\)) 및 랜덤 순서(랜덤이 상위-5 컨텍스트를 셔플링한다. 순차 주문을 사용하는 것은 역 및 스윙 순서를 사용하는 것과 비슷하며 무작위 셔플링은 약간 더 나쁘다. 결과는 우리 모델이 답의 위치와 상관없이 긴 맥락에서 정답을 추출하는 데 탁월함을 나타낸다. ChatQA 미세 조정 시, 정답의 위치가 문맥 내에서 무작위로 발생하기 때문이다.\n' +
      '\n' +
      '셋째, 우리는 "드래곤 + 파인-테이크"를 원래 비피네이드 드래곤 레트리버로 대체할 때 평균 점수가 1.81(42.31에서 40.50) 감소한다는 것을 관찰했다. 또한 INSCIT 데이터셋(33.98~27.87)에서 점수차가 크게 떨어져 INSCIT 데이터셋(33.98~27.87)의 성능 격차가 커 점수가 크게 떨어졌다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l l l l l l l} \\hline \\hline Models & Avg. & D2D & QuAC & QReCC & TopIO & INSCIT \\\\ \\hline ChatQA-70B & 42.31 & 39.19 & 38.33 & 48.73 & 51.30 & 33.98 \\\\ - \\# of ctx: top-3 & 41.91 & 37.20 & 38.35 & 48.94 & 52.78 & 32.27 \\\\ - \\# of ctx: top-10 & 40.71 & 37.06 & 36.95 & 47.61 & 49.40 & 32.53 \\\\ - \\# ctx reverse ordering & 42.48 & 39.08 & 38.85 & 49.63 & 51.16 & 33.69 \\\\ - ctx swing ordering & 42.30 & 39.35 & 38.09 & 49.09 & 50.98 & 33.99 \\\\ - ctx random ordering & 42.01 & 39.32 & 38.28 & 48.79 & 50.13 & 33.51 \\\\ - Dragon Retrieval & 40.50 & 37.92 & 38.44 & 47.88 & 50.39 & 27.87 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 6: 검색이 필요한 데이터셋에 걸친 입력 컨텍스트에 대한 번역 연구는 다음과 같다. 모든 모델은 합성ConvQA를 사용하고 있습니다. D2D는 Doc2Dial을 나타내고 TopIO는 TopiOCQA를 나타낸다. 입력(#의 ctx), 컨텍스트 순서(역, 스윙, 무작위) 및 원래 드래곤에서 검색된 컨텍스트에 사용되는 컨텍스트의 수를 연구한다. 이에 비해 ChatQA-70B(디폴트 설정)는 탑-5 컨텍스트를 검색한 \'드래곤 + 파인-테네\'와 상위-5에서 첫 번째에서 다섯 번째 맥락에서 순차적인 순서를 사용하고 있다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l l l l} \\hline \\hline Models & Avg-all & Avg-ret & Avg-nonret \\\\ \\hline ChatQA-70B & **54.14** & 42.33 & **65.96** \\\\ - \\# of “top-5” chunks & 54.04 & **42.91** & 65.16 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '"톱-5"를 사용한 Ablation 연구는 스테이지-2 명령어 튜닝의 맥락에서 청크를 검색했다. 모든 데이터셋(Avg-all), 5개의 검색 데이터셋(Avg-ret) 및 5개의 비수익 데이터셋(Avg-nonret)에 대한 평균 점수를 보고한다.\n' +
      '\n' +
      '두 가지 검색자(표 1에 나와 있다) 기본적으로 검색의 질이 향상되면 질문 응답의 성능을 직접적으로 향상시킵니다.\n' +
      '\n' +
      '불만 사건.\n' +
      '\n' +
      '6.5.1평가정류장 6.5.1평가정류장 6.5.1평가정류실##########\n' +
      '\n' +
      '이 절에서는 제공된 맥락에서 질문을 답할 수 있는지 식별하는 모델의 능력의 또 다른 측면을 연구한다. 답변할 수 없는 사건에서 답을 만드는 것은 환각으로 이어질 것이다. 이 평가를 허용하려면 주어진 맥락에서 답을 찾을 수 없을 때 모델을 표시해야 한다.\n' +
      '\n' +
      '우리는 그러한 능력을 평가하기 위해 그러한 응답할 수 없는 케이스가 있는 QuAC 및 DoQA 데이터 세트를 사용한다. 구체적으로, 응답할 수 없는 경우에 대해 질문을 올바른 8으로 대답할 수 없음을 나타내는 모델을 고려하고, 답변 가능한 경우 질문을 나타내지 않는 모델이 정답(즉, 답을 주는 모델)으로 간주될 수 없다고 생각한다. 답변 가능한 경우 정확한 컨텍스트가 검색되는 샘플만 선택합니다. 우리의 모델 체크포인트(ChatQA-70B w/1.5k 비응답 및 ChatQA-70B w/합성ConvQA)는 표 2에 보고된 것과 동일하다.\n' +
      '\n' +
      '발주 8: 생성된 모든 샘플에서 휴리스틱 매칭 패턴 세트를 수집하여 모델이 질문이 응답할 수 없음을 시사하는지 확인했다. 보다 자세한 내용은 부록 E에서 찾을 수 있다.\n' +
      '\n' +
      '결국, 우리는 응답할 수 없고 답할 수 없는 사례의 평균 정확도 점수를 최종 메트릭으로 계산한다. 우리는 정밀도 및 리콜 점수의 고조파 평균을 측정하는 F1 메트릭의 정신과 동일하기 때문에 이 평균 정확도를 신뢰할 수 있는 메트릭으로 간주한다.\n' +
      '\n' +
      '#### 6.5.2 Results\n' +
      '\n' +
      '표 7에서 우리는 모델을 QuAC 및 DoQA 데이터 세트에 걸쳐 OpenAI 모델과 비교한다. 먼저, 인간 표지화된ConvQA를 사용하여 합성ConvQA를 사용하는 것과 비교하여 QuAC 및 DoQA 모두에서 평균 정확도를 크게 증가시키는 것을 발견했다. 답변할 수 없는 주석들은 사람 미공개 데이터에 대해 더 높은 품질을 가지고 있어 응답 불가능한 사례에 대한 정확도를 크게 향상시켰기 때문이다. 둘째, OpenAI 모델은 이 작업, 특히 GPT-4에 대해 강력한 능력을 보여주는데, 이에 비해 최고의 모델은 GPT-3.5-turbo보다 훨씬 더 나은 평균 정확도를 달성했지만 여전히 GPT-4(약 3.5%)에 비해 약간의 간격을 가지고 있다. 셋째, 응답할 수 없는 샘플에 대해 더 높은 정확도를 달성하는 모델이 답변 가능한 샘플에 대해 더 낮은 정확도를 얻는 경향이 있음을 발견하며 그 반대의 경우도 마찬가지이다. 모델이 "진보"되는 경향이 있고 응답할 수 없는 질문에 다소 관련된 답을 제공할 때 답변 가능한 사례에 대한 정확도를 향상시키지만 응답할 수 없는 경우에 대한 정확도를 감소시킬 것이라고 추측한다. 반대로 모델이 더 "보수적"인 경우, 질문이 답변될 수 있는지 엄격하게 확인하는 것은 반대 효과를 초래할 것이다.\n' +
      '\n' +
      '우리는 인간 표지화된ConvQA에서 허용 불가능한 샘플의 수 측면에서 절제 연구를 수행한다. 소량의 비응답 샘플(예를 들어, 1.5k)을 사용하면 허용 불가능한 평가에서 현저한 결과를 얻을 수 있고 전체 대화 QA 점수(즉, Avg-CQA)를 달성할 수 있다는 것을 발견했다. 흥미로운 사실은 더 많은 응답할 수 없는 샘플을 통합하는 것은 반드시 응답할 수 없는 평가에서 더 높은 정확도 점수를 초래하는 것은 아니다.\n' +
      '\n' +
      '### Case Study\n' +
      '\n' +
      '표 8에서 우리는 ChatQA-70B 및 GPT-4 출력 9.9의 4가지 예를 보여준다.\n' +
      '\n' +
      '부츠 9: 모음 예는 부록 F에서 찾을 수 있다.\n' +
      '\n' +
      '첫 번째 예(약 _Board 청각_)는 문제를 찾는 간단한 정보이며, ChatQA-70B와 GPT-4는 모두 올바르게 답변한다. 두 번째 예(약 _Arya_)에서 모델은 답을 제공하기 위해 암묵적인 정보(파란색으로 고라이트)를 찾아야 한다. GPT-4는 안전하다는 경향이 있다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l|c|c c c|c c c||c} \\hline \\hline Models & Avg-Both & Avg-QuAC & QuAC (no*) & QuAC (yes*) & Avg-DoQA & DoQA (no*) & DoQA (yes*) & Avg-CQA \\\\ \\hline ChatQA-70B & & & & & & & & \\\\ - 1k unanswerable\\({}^{\\dagger}\\) & 76.88 & 80.89 & 75.10 & 86.67 & 72.88 & 64.49 & 81.26 & **54.16** \\\\ - **1.5k unanswerable\\({}^{\\dagger}\\)** & **77.25** & **80.76** & 77.66 & 83.85 & **73.74** & 68.81 & 78.67 & **54.14** \\\\ - 2k unanswerable\\({}^{\\dagger}\\) & 77.10 & 80.82 & 77.59 & 84.05 & 73.38 & 67.95 & 78.80 & 53.86 \\\\ - 2.5k unanswerable\\({}^{\\dagger}\\) & 75.87 & 78.81 & 73.76 & 83.85 & 72.93 & 66.54 & 79.31 & 53.78 \\\\ - SyntheticConvQA\\({}^{\\diamond}\\) & 69.84 & 72.92 & 55.38 & 90.42 & 66.77 & 45.09 & 88.45 & 54.08 \\\\ \\hline GPT-3.5-turbo (4k) & 73.27 & 78.34 & 61.91 & 94.76 & 68.21 & 51.99 & 84.43 & 50.37 \\\\ GPT-4 (8k) & **80.73** & **87.42** & 83.45 & 91.38 & **74.05** & 74.28 & 73.82 & **53.90** \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 7: QuAC 및 DoQA 데이터 세트에 걸쳐 답변 가능한 샘플 및 응답할 수 없는 샘플에 대한 승인. 두 점 모두 QuAC와 DoQA 사이의 평균 점수이다. \\는 모두 QuAC와 DoQA 사이의 평균 점수이다. ({}^{\\diamond}\\)는 인간 노광된ConvQA가 합성ConvQA로 대체되었음을 나타낸다. ****-no\'********************************************************************************************************************************************************************************************************************************************************* ({}^{\\dagger}\\) 인간 바람직하지 않은ConvQA의 허용 가능한 샘플의 수 측면에서 절제 연구를 수행한다. Avg-CQA는 10개의 대화 QA 데이터 세트를 가로지르는 평균 점수이다. 우리는 고품질 생성과 덜 환각성을 모두 생성하기 때문에 최종 ChatQA-70B에 1.5k 허용되지 않은 샘플을 사용한다.\n' +
      '\n' +
      '답변 제공, 맥락이 연령에 대한 정확한 정보도 제공하지 않는다는 것을 답한다.\n' +
      '\n' +
      '세 번째 예와 네 번째 예 모두 모델이 좋은 표적 이해와 추론 능력을 갖도록 요구한다. 세 번째 예(약 _Massif_)에서 ChatQA-70B는 3100ha에 대한 보존 영역의 크기를 비교하여 정답을 주는 반면 GPT-4는 그렇게 하지 못한다. 네 번째 예(약 _John B. 잉글랜드_)에서 ChatQA-70B는 세 날짜를 올바르게 나열하지만 한 날짜를 놓치지 않는 반면 GPT-4는 질문에 올바르게 응답한다.\n' +
      '\n' +
      '## 7 Conclusion\n' +
      '\n' +
      '본 논문에서는 모델 크기가 7B에서 70B까지 다양한 ChatQA 모델 계열을 구축한다. 10개의 대화 QA 데이터 세트에 대한 포괄적인 평가는 최고의 ChatQA-70B 모델이 현저하게 GPT-3.5-turbo를 능가하고 ChatGPT 모델의 합성 데이터를 사용하지 않고 GPT-4와 함께 수행할 수 있음을 보여준다. 또한, 우리는 큐레이션된 대화 QA 데이터를 사용하여 단일턴 쿼리를 재작성하는 것이 재작성에서 추가 계산 시간과 잠재적인 API 비용이 필요 없이 최첨단 LLM 기반 쿼리 재작성 모델에 필적하는 것을 수행한다는 것을 보여준다. 또한 소량의 "불응답 가능한" 샘플을 통합하면 답변이 불가능한 시나리오를 처리할 수 있는 모델의 능력을 크게 향상시킬 수 있음을 보여준다. 답변할 수 없는 사례 평가는 최고의 모델 ChatQA-70B가 GPT-4에 비해 약간의 갭만 가지고 있음을 강조한다.\n' +
      '\n' +
      '## References\n' +
      '\n' +
      '*[1]A. 아돌라카, S. Dhuliawala, K. 수맨, H. 데 브리 및 S. 레드디(2022) 토티코큐A: 개방형 도메인 대화 질문으로 토픽 전환을 응답합니다. TACL. SS1: SS1로 받았습니다.\n' +
      '*[2]M. 알리안네자디, J Kiseleva, A. Chuklin, J. 달튼, M.M. 버르트세프(2021) 빌딩과 개방형 도메인 대화 기업 평가를 명확히 하고 있다. EMNLP에서: SS1에 의해 계산된다.\n' +
      '*[3]R. 안탄다, S. 박굴렌코, Z. 투, S. 장기, S. 풀만과 S. 응답하는 샤피디(2021) 오픈 도메인 질문은 질문 재작성을 통해 대화한다. NAACL에서: SS1에 의해 계산된다.\n' +
      '*[4]T. 안트라리아(2023)는 100k 문맥 창을 소개합니다. 외부 링크: SS1에 의해 링크되었습니다.\n' +
      '*[5]Q. Brabant, G. Lecorve 및 L. M. Barahona(2022) Coqar: coqa에서 질문 재작성한다. LREC에서: SS1에 의해 계산된다.\n' +
      '\n' +
      '[MISSING_PAGE_POST]\n' +
      '\n' +
      '* 첸 et al(2022a) Chen, Z, Li, S, 스마일리, C, Ma, Z, Shah, S 및 왕, W. Y. Convfinaq: 대화형 금융 질문에서 수치 추론의 사슬을 요약한다. 72a에서 _EMNLP_에서.\n' +
      '* 첸 등은 (2022b) 천, Z, Zhao, J, Fang, A, 페타후, B, 로켄코, O 및 말마티, S. 대화형 질문 답변에 대한 강화 질문 재작성. i_EMNLP_, 2022b에서.\n' +
      '* 최씨는 (2018) 최씨, 에씨, 하이, H씨, 이이어, M씨, 야츠카르, M씨, 이씨, W. 최, Y, 리앙, P, 제트렘로저, L. 쿼: 질문은 맥락에서 대답합니다. 2018년 _EMNLP_에서.\n' +
      '* 추 등은 추(2020) 추, Z, 첸, M, 첸, J, 왕, M, 김펠, K, 푸루키, M 및 Si, X이다. 더 나은 질문을 하는 방법은 무엇입니까? 불선택된 질문을 다시 쓰기 위한 대규모 멀티 도메인 데이터셋입니다. 2020년 _AAAI_에서.\n' +
      '그룹, 스즈건, 자이, 스즈즈, 스즈즈, 스즈네, 스즈네, 스웰슨, 케이, 브래지슨, 케이, 레이, 노랑, 스, 리, 지, 아, 아, 유, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아, 아 arXiv 프리프린트 arXiv: 2022. 2210.11416_입니다.\n' +
      '* 콘버 등 (2023a) 컨버, M, 하네스, M, 마투르, A, 멍, X, X, 완, J, Shah, S, Ghodsi, A, Wendell, P, Zaharia, M) 등은 세계 최초로 진정한 열린 지시로 제작된 llm, 2023a.\n' +
      '*다이 등은 Dai(2022b) Dai, Z, Chaganty, A T, Zhao, V, Amini, A, 녹색, M, 라시드, Q 및 구우, K. 대담화: 문서를 대화로 돌리는 것. _ICML_, 2022b.\n' +
      '* 다지기는 (2019) 다지, P, 류, N F, 마라스토비치, A, 스미스, N, 가드너, M. 질문: 핵심 추론이 필요한 질문으로 읽기 이해 데이터셋입니다. 2019년 _EMNLP_에서.\n' +
      '* 델 테레디시 등(2021) 델 테레디치, M, 바르락치, G, 선전, X, 청, W 및 드 지퍼퍼스를 비롯해 개방형 대화형 qa: 최고의 관행 및 한계를 묻는 질문이다. 2021년 _CIKM_에서.\n' +
      '* 덩 등은 (2022) 덩, 예, 르, W, 장, W, 람, W 및 추아, T. S. 태평양: 금융에서 표상 및 텍스트 데이터에 대해 사전적 대화 질문이 대답한다. 2022년 _EMNLP_에서.\n' +
      '* 듀 등은 (2022) 듀, Z, Qian, Y, Liu, X, Ding, M, Qiu, J, 양, Z 및 탕, J GIm: 자기회귀 블랭크 주입을 치료한다. 2022년 _ACL_에서.\n' +
      '* 듀아 등은 (2019) 듀아, D, 왕, Y, 다지, P, 스탠코프스키, G, 싱, S, 가드너, M. 드롭: 단락보다 이산적인 추론을 필요로 하는 읽기 이해 기준. 2019년 _NAACL_에서.\n' +
      '* 엘고하리 등 (2019) 엘고하리, A, 페스코프, D, 보드그라버, J는 그것을 포장할 수 있습니까? 질문-인-텍스트를 다시 쓰기 위한 학습입니다. 2019년 _EMNLP_에서.\n' +
      '* 판 등은 A(2019) 판, A, 제나이트, Y, 페레스, E, 그랑에, D, 웨스트온, J 및 아리, M. Eli5: 롱 폼 질문 답변입니다. 2019년 _ACL_에서.\n' +
      '*펑 등은 (2020)펑, 스, 완, H, 군세카라, C, 파텔, S, 조시, S, 라스트라스, L. doc2dial: A 목표 지향 문서 지상 대화 데이터셋입니다. 2020년 _EMNLP_에서.\n' +
      '* 갈리만노바(2023) 갈리만노바, E, 문테안, C. I, 나디니, F. M, 페레고, R. 및 로키티, G. 리글레이팅 대화 발언에 대해 지시한 대형 언어 모델들이 있다. IEEE/WIC 국제 웹정보 컨퍼런스 및 지능형 아젠트 기술_, 2023.\n' +
      '* 가오 등은 (2022) 가오, C, 장, W 및 Lam, W. 미혼: 목표 지향적인 문서 중심 대화를 위한 통일된 생성 틀이다. 2022년 _ACL_에서.\n' +
      '* 가오 등은 (2023) 가오, Y, Xiong, Y, 가오, X, 지아, K, 판, J, Bi, Y, Dai, Y, 선, J, 왕, H. 리베리발-증강 세대이다. arXiv 프리프린트 arXiv:2312.10997_, 2023.\n' +
      '* 구글(2023) 구글입니다. 세련된 2023년 제품을 소개합니다.\n' +
      '* 구는 (2021) 구오, M, 장, M, 레드디, S, 알리칸니, M. Abgo-coqa: 대화형 질문 답변에서 모호성을 해소합니다. 2021년 _AKBC_에서.\n' +
      '* 호노비치 등은 (2022) 호노비치, O, 인텔럼, T, 레비, O 및 슈크, T. 자연적이지 않은 지침, 즉 (가장) 인간 노동력이 없는 튀는 언어 모델: (가장)이 있는 튀긴 언어 모델은 아니다. arXiv 프리프린트 arXiv:2212.09689_, 2022.\n' +
      '* 이시이 등은 (2022) 이시이, E, Xu, Y, 카하위자야, S, Wilie, B. 질문 다시 쓰기가 대화 질문 응답에 도움이 되는가? 2022년 NLP_의 네거티브 결과에 대한 인벤션에 대한 제3워크숍의 _수익에서.\n' +
      '* 이이어 등(2022) 이이어, 에스, 린, XV, 파스누루, R, 미하예로프, T, 시미그, D, 유, P, Shuster, K, 왕, T, 류, Q, 쿠우, P. S. 등 일반화의 렌즈를 통한 스칼링 언어 모델 지시 메타 학습. arXiv 프리프린트 arXiv:2212.12017_ 2022년입니다.\n' +
      '\n' +
      '* 이자카드 & 그레이브(2021) 아이자카드, G. 및 그레이브, E. 루버징 통로 검색은 개방형 도메인 질문 응답에 대한 생성 모델로 검색된다. 2021년 유럽 컴퓨터 통계협회 제16차 회의의 _검토에서.\n' +
      '* 이자카드, G(2022) 이자카드, G, 카르손, M, 호세니, L, 리델, S, 보잔프스키, P, 자울린, A 및 그레이브, E.의 조밀한 정보 검색은 대조 학습이 있는 것으로 나타났다. 기계학습연구_ 2022년 거래.\n' +
      '김씨(2022)는 김모(2022)씨, H., Hessel, J., 장, L., 루, X, 유, 저우, P., 브루스, R. L., 알리칸니, M, 김, G, Sap, M. 등 사회 커먼센스 맥락화를 가진 100억 규모의 대화 증류이다. arXiv 프리프린트 arXiv:2212.10465_, 2022.\n' +
      '* 코시스키 등은 (2018) 코시스키, T, 슈워츠, J, 블러솜, P, 데르놈, C, 헤르만, K, 멜리스, G 및 그르펜스테트, E. 서사적 읽기 이해 과제. TACL_ 2018.\n' +
      '* 코프 등은 A(2023) 코프, A, 킬러, Y, 폰 루테, D, 아노노스티디스, S, 타미, Z. R, 스티븐스, K, 바우름, A, Duc, N.M, 스탠리, O, 나고피, R. 등 다양한 대화-민주화 대형 언어 모델 정렬. arXiv 프리프린트 arXiv:2304.07327_, 2023.\n' +
      '대형 언어 모델 정렬 __* 민주화 대형 언어 모델 정렬 __ 민주주의화 대형 언어 모델 정렬. _* 민주화 대형 언어 모델 정렬. arXiv 프리프린트 arXiv: 2304.07327_, 2023.\n' +
      '* Lin 등은 (2019) Lin, K, Tafjord, O, Clark, P 및 Gardner, M. 상황에서 단락 효과에 대한 이유. 2차 워크숍의 _검토에서 2019년 질문 안드링_를 위한 기계 판독에 관한 것이다.\n' +
      '* Lin 등은 S.(2023a) Lin, S. 아사이, A, 리, M, 오구즈, B, 린, J, Mehdad, Y, W. 텐, X. 룡을 훈련하는 방법, 즉 용을 훈련하는 방법은 일반적인 조밀한 검색에 대한 역 증강이다. __ arXiv 프리프린트 arXiv:2302.07452_, 2023a.\n' +
      '(2023b) 린, X.(2023b) 린, X., Chen, X, Chen, M., Shi, W., Lomeli, M., 제임스, R., 로드리게스, P., Kahn, J., Szilvasy, G., Lewis, M., Trrival-증강 이중 명령 튜닝. arXiv 프리프린트 arXiv:2310.01352_, 2023b.\n' +
      '* Liu et al. (2023) Liu, N. F. (2023) Lin, K, Hewitt, J, Paranjape, A, Bevilacqua, M, 페트리니, F. 및 Liang, P. Lost의 중간에서 언어 모델이 긴 컨텍스트를 사용하는 방법. arXiv 프리프린트 arXiv:2307.03172_, 2023.\n' +
      '* 롱pre et al.(2023) 롱프레 등은 S, Hou, L, Vu, T, Webson, A, 정, H W, Tay, Y, Zhou, D, Le, B, Wei, J 등 효과적 지시 튜닝을 위한 설계 데이터 및 방법. arXiv 프리프린트 arXiv:2301.13688_, 2023.\n' +
      '*Mele et al.(2021) Mele, I, Muntean, C. I, Nardini, F. M, 페레고, R, Tonellotto, N 및 프리더, O. 대화 탐색을 위한 적응 발화 재작성. __ 대화 탐색을 위한 적응 발화 재작성. 정보처리 및 관리_ 2021.\n' +
      '* 미샤라 등은 S.(2022) 미슈라, S., 카샤비, D., 바랄, C. 및 하지시르지, H. 크로스 태스크는 자연어 인파소싱 지시를 통해 일반화된다. 2022년 _ACL_에서.\n' +
      '* Mo(2023) 모, F, 마오, K, 주, Y, 우, Y, 황, K 및 니, J-Y. 콘vgqr: 대화 탐색을 위한 유전 질의 개편. __ 대화 탐색을 위한 개념 질의 개편. arXiv 프리프린트 arXiv:2305.15645_, 2023.\n' +
      '* 무니혼프 등은 (2022) 무니호프, 나, 왕, 투타비카, 루츠, 로버츠, A, 바이데르만, S, 스바오, T, 바리, M., 선, S, 용, Z. M_X, Schoelkopf, H., et al. 크로스클링 일반화는 멀티태스핀셋링을 통한 것이다. arXiv 프리프린트 arXiv:2211.01786_ 2022년.\n' +
      '* 나카무라 등은 (2022) 나카무라, K, 레비, S, 투안, Y. L, Chen, W 및 왕, W. Y. 하이브리얼로그: 표와 텍스트 데이터에 대한 정보 추구 대화 데이터셋이 접지되었다. 2022년 ACL_의 _발견에서.\n' +
      '* 응우옌 등은 (2016) 응우옌, T, 로젠버그, M, 송, X, 가오, J, 티와리, S, 마제마더, R 및 덩, L. M marco: 인간 생성 기계 판독 이해 데이터셋. __M marco: 인간 생성 기계 판독 이해 데이터셋. 선택_2016.\n' +
      '* 오픈AI(2022) 오픈AI입니다. 2022년 ChatGPT를 소개합니다.\n' +
      '* 오픈AI(2023) 오픈AI입니다. GPT-4, 2023.\n' +
      '*오양(2022) 오양(2022) 오양(주, 우, J, 장, X, 알메시다, D, 알메시다, 웨인라이트, C, 미슈킨, P, 장, C, 아가왈, S, 슬라, K, 레이, A) 등은 인간의 피드백으로 지침을 따르도록 언어 모델을 훈련시킨다. NeurIPS_ 2022.\n' +
      '* 파수파트 & 리앙(2015) 파스푸파트, P. 및 리앙, P. 구성 의미론은 반구조화된 테이블에서 파싱된다. 2015년 _ACL_에서.\n' +
      '* Qu 등은 (2020) Qu, C, 양, L, Chen, C, Qiu, M, 크프트, W. B, Iyyer, M. 개방형 대화형 질문 답변. 2020년 _SIGIR_에서.\n' +
      '* 라자푸르카 등 (2016) 라자푸르카르, P, 장, J, Lopyrev, K 및 리앙, P. Squad: 텍스트에 대한 기계 이해를 위한 10만+ 질문이다. 2016년 _EMNLP_에서.\n' +
      '* 라자푸르카 등(2018) 라자푸르카, P, Jia, R, 리앙, P.는 당신이 모르는 것을 알고 있다. 2018년 _ACL_에서.\n' +
      '* 라포소 등은 (2022) 라포소, G., 리베로, R., 마르틴, B 및 Coheur, L. 질문 재작성? 대화적 질문 답변에 대한 중요성을 평가한다. 2022년 _ECIR_에서.\n' +
      '\n' +
      '시그니, S, Chen, D 및 매니닝, C. D. Coqa: 대화 질문 응답 도전. __ 변환 질문 답변 질문. TACL_ 2019.\n' +
      '2018] 새디, M, Bartolo, M, Lewis, P., Singh, S., Rocktaschel, T., Sheldon, M., Bouchard, G 및 Riedel, S. 대화 기계 판독에서 자연어 규칙을 해석합니다. 2018년 _EMNLP_에서.\n' +
      '*[산호 등2022] V, 위슨, A, 라펠, C, 바흐, S. H, 스투와이카, L., 솔리페리, Z, 차핀, A, 스타글러, A, 스카오, T. L., 라자, A. 등은 제로샷 태스크 일반화를 가능하게 한다. 2022년 _ICLR_에서.\n' +
      '*[Touvron et al.2023] Touvron, H., 마르틴, L., K., Albert, P., Almahairi, A., Babaei, Y., Bashlykov, N., 바트라, S, Bhargava, P., Bhosale, S., E. Llama 2: 오픈 파운데이션 및 미세 색채 모델. arXiv 프리프린트 arXiv:2307.09288_, 2023.\n' +
      '*[트리스클러 등.2017] 트리스클러, A, 왕, T, 원, X, 해리스, J, 소도니, A, 바흐만, P 및 수맨, K. 뉴스카: 기계 이해 데이터셋입니다. 2017년 NLP_에 대한 발표 학습 2차 워크숍 _검토에서.\n' +
      '*[바쿨렌코] Vakulenko, al.2021a] Vakulenko, S, 롱프레, S, Tu, Z 및 아나안타, R. 대화형 질문 답변에 대한 질문 재작성. 2021년에 _WSDM_a.\n' +
      '*[바쿨렌코] Vakulenko, al.2021b] Vakulenko, S, Voskarides, N., Tu, Z 및 롱프레, S. 대화 통로 검색을 위한 질문 재작성 방법을 비교한 것이다. 2021년 _ECIR_에서.\n' +
      '*[왕 et al.2023a] 왕, B, Ping, W, 맥아피, L, Xu, P, Li, B, Shoeybi, M 및 Catanzaro, B. 구조: 검색-증강 전처리 후 명령 조정 arXiv 프리프린트 arXiv:2310.07713_, 2023a.\n' +
      '*[왕 등 알2022a] 왕, 양, 나, 황, X, 자오, B, 양, L, 장, D, 마제마더, R 및 웨이, F. 텍스트 임베딩은 약하게 나타난 대조적인 사전 학습을 통해이다. arXiv 프리프린트 arXiv:2212.03533_, 2022a.\n' +
      '*[왕 등 알2022b] 왕, Y, 코디, Y, 미슈라, S, 류, A, 스미스, N, 카샤비, D, 하지시르지, H. 셀프 구조: 자체 생성 지침을 사용하여 언어 모델을 정렬한다. arXiv 프리프린트 arXiv:2212.10560_, 2022b.\n' +
      '*[왕 et al2022c] 왕, Y, Mishra, S, Alipoormolabashi, P, Kordi, Y, Mirzaei, A, Nshok, A, A, Dhanasekaran, A, Arunkumar, A, Stap, D 등 1600+ nlp 작업에 대한 선언적 지침을 통한 일반화. i_EMNLP_, 2022c.\n' +
      '*[왕 et al.2023b] 왕, 이비슨, H., 다지, P., 헤세이, J, Khot, T. 찬두, D.와덴, 맥밀란, K, 스미스, 네, 벨라기, 아이. 오픈 리소스에 대한 명령어 튜닝 상태를 설명하는 _ _ 오픈 리소스에 대한 명령어 튜닝 상태를 탐구한다. arXiv 프리프린트 arXiv:2306.04751_, 2023b.\n' +
      '*[위:2022a] 위, 조, 보스마, M, 자오, V. Y, 구우, K, 유, A W, 리스터, B, 듀, N, Dai, A.M 및 Le. 핀셋 언어 모델은 0샷 학습자입니다. _ICLR_, 2022a.\n' +
      '*[위:2022b] 위, J, 왕, X, 슈무르만, D, 보스마, M, 샤, F, 치, E, Le, Q, 저우, D 등은 큰 언어 모델에서 추론을 이끌어낸다. NeurIPS_, 2022b.\n' +
      '* [Wu et al2022] 우, Z, 루안, Y, 라시킨, H, 리터, D, 하지시르지, H, 오스트렌도르프, M 및 톰, G. Conqrr: 강화 학습 검색을 위한 대화 질의 재작성. 2022년 _EMNLP_에서.\n' +
      '*[Wu et al.2023] 우, Z, 파라시, R, 청, H, 민, S, 암만나브루, P, 오스트렌도르프, M 및 하지시르지, H. _)는 혼합 해결 상호 작용과의 정보 추구 대화이다. TACL_, 2023.\n' +
      '* [Xu et al.2023a] Xu, C, 선, Q, 정, K, 기가, X, Zhao, P, 펑, 제이, 도, C 및 장, D. 위저드lm: 복잡한 지침을 따르기 위해 대형 언어 모델이다. arXiv 프리프린트 arXiv:2304.12244_, 2023a.\n' +
      '* [Xu et al.2023b] Xu, P., Ping, W, 우, X, 맥아피, L., Zhu, C, Liu, Z, Subramanian, S, Bakhurin, E, Shoeybi, M 및 Catanzaro, B. 리리발은 긴 컨텍스트 대형 언어 모델을 충족한다. arXiv 프리프린트 arXiv:2310.03025_, 2023b.\n' +
      '*[여 등.2023] 예, F, 포, M, Li, S, 요마즈, E. 엔아싱 대화 검색: 대형 언어 모델 유도 정보 질의 재작성. _EMNLP_에서 pp 5985-6006, 2023.\n' +
      '*[유 et al.2020] 유, S, 류, J, 양, J, Xiong, C, Bennett, P., Gao, J 및 Liu, Z. 샷 생성 대화 쿼리가 재작성되는 것은 거의 없다. 2020년 _SIGIR_에서.\n' +
      '*[장 et al.2023] 장, S, 동, L, 리, X, 장, S, 선, X, 왕, S, 리, J, 후, 장, T, 우, F 등 큰 언어 모델에 대한 조정 arXiv 프리프린트 arXiv:2308.10792_, 2023.\n' +
      '*[주 등.2023] 저우, C, 류, P, Xu, P, 이이어, S, 선, J, 마오, Y, 마, X, Efrat, A, 유, P, L., L., L.의 정렬은 더 많다. arXiv 프리프린트 arXiv:2305.11206_, 2023.\n' +
      '*[Zhu et al.2021] 주, F, Lei, W, Huang, Y, 왕, C, 장, S, Lv, J, 펑, F 및 추아, T. S. Tat-qa: 금융의 표형과 텍스트 콘텐츠의 혼성화에 대한 벤치마크에 답하는 질문이다. 2021년 _ACL_에서.\n' +
      '\n' +
      'ChatQA는 ChatQA를 억제하는 역할을 한다.\n' +
      '\n' +
      '####. Stage-1을 검색했습니다.\n' +
      '\n' +
      '단계-1에서 LLM 입력의 포맷 템플릿은 다음과 같다.\n' +
      '\n' +
      '시스템: 이것은 사용자와 인공 지능 어시스턴트의 대화입니다. 어시스턴트는 컨텍스트에 기초하여 사용자의 질문에 대한 도움, 상세 및 예의 응답을 제공한다. 보조자는 또한 컨텍스트에서 답을 찾을 수 없는 경우를 표시해야 한다.\n' +
      '\n' +
      '사용자: { 질문 1} 어시스턴트: {Answer 1} 사용자: {Latest 질문} 어시스턴트: 우리는 어시스턴트의 {Latest Answer}를 모델 출력의 감독으로 사용한다.\n' +
      '\n' +
      '##-2: 텍스트 강화 보증\n' +
      '\n' +
      '단계-1 포맷 템플릿을 기반으로 스테이지-2의 LLM 입력들은 아래 묘사된 바와 같이 선택된 질문} 및 사용자로부터의 명령}에 대한 {콘텍스트를 추가한다.\n' +
      '\n' +
      '시스템: 이것은 사용자와 인공 지능 어시스턴트의 대화입니다. 어시스턴트는 컨텍스트에 기초하여 사용자의 질문에 대한 도움, 상세 및 예의 응답을 제공한다. 보조자는 또한 컨텍스트에서 답을 찾을 수 없는 경우를 표시해야 한다.\n' +
      '\n' +
      '문제} 질문을 위한{컨텍스트: { 지도} + { 설문 1} 보조: {Answer 1} 사용자: {Latest 질문} 어시스턴트: Stage-1으로서, 우리는 어시스턴트의 {Latest Answer}를 모델 출력의 감독으로 사용한다.\n' +
      '\n' +
      '{ 명령}에 대해 답변 유형에 따라 서로 다른 데이터셋에 대해 다른 지침을 사용한다. 자세한 내용은 아래에서 확인할 수 있습니다.\n' +
      '\n' +
      '"질문에 대한 완전하고 완전한 답변 부탁드립니다." 긴 답변이 있는 데이터셋을 위한 것입니다. 우리는 그것을 인간 안티티드ConvQA 또는 합성ConvQA에 사용한다.\n' +
      '\n' +
      '"짧은 시간대로 다음 질문에 답할 필요가 있다. 답은 몇 마디에 그칠 필요가 있다. 짧은 대답이 있는 데이터셋을 위한 것"이다. SQuAD1.1, SQuAD2.0, NarrativeQA, DROP, ROPES, 뉴스QA 및 Quoref에 사용한다.\n' +
      '\n' +
      '"+, -, * 또는/를 사용하여 컨텍스트 또는 수학 연산으로부터 숫자로 다음 질문을 전달하는 것"은 산술 계산을 사용하거나 컨텍스트로부터 숫자를 추출하는 데이터셋에 대한 것이다. 우리는 TAT-QA 데이터셋에 사용하여 문항이 산술 계산을 필요로 하거나 컨텍스트로부터 숫자를 추출한다.\n' +
      '\n' +
      '"짧은 시간, 또는 완전하고 완전한 답변으로 다음 질문을 알려주는 것"은 짧고 긴 대답을 모두 갖춘 데이터셋에 대한 것이다. 모델은 질문에 따라 짧거나 긴 답변을 생성할지 여부를 말할 필요가 있다. 해당 답변의 길이는 짧고 길 수 있기 때문에 산술 계산이 필요하지 않은 TAT-QA 데이터셋에 사용합니다.\n' +
      '\n' +
      '단계-2 명령어 튜닝에 사용되는 스테이지-1 SFT 데이터의 경우 스테이지-1과 동일한 포맷 템플릿을 유지하며, 다른 말로 라스트 질문} 및 { 명령}에 대한 {Con텍스트가 비어 있다.\n' +
      '\n' +
      '합성 데이터 탄생.\n' +
      '\n' +
      '***는 고품질 멀티턴 QA 대화를 얻기 위해 GPT-3.5-투르보에 2단계 프롬프트를 사용하여***** 단계-1에서 GPT-3.5-투어가 주어진 문서를 기반으로 다중턴 QA 대화를 생성하도록 지시했다. 그러나 생성된 대화에는 대화사에서 단어나 문구를 언급할 명사나 공통 명사가 결여되어 있다는 것을 알게 된다. 따라서, 단계-2에서 GPT-3.5-투보는 명사 또는 공통 명사를 추가하여 생성된 대화를 수정하도록 지시했다. 두 단계 모두 고품질 생성을 보장하기 위해 GPT-3.5-투보 몇 가지 예시를 제공합니다.\n' +
      '\n' +
      '단계-1에서 인텍스트 소수의 샷 프롬프트(멀티턴 QA 대화 생성 청구권)는 다음과 같다.\n' +
      '\n' +
      '당신은 도움이 되는 패턴 제거 보조자입니다.\n' +
      '\n' +
      'role-user:\n' +
      '\n' +
      '개인A는 다음 각 호의 통로에서 정보에 접근할 수 있다.\n' +
      '\n' +
      '##은 대학 준비의 중요한 측면이 있다. 대학을 준비하는 학생은 목표와 이익을 정의해야 합니다. 학생 역시 재정적으로, 학문적으로 계획을 세워야 한다. 학생들에게 재정적이고 학문적으로 대비할 수 있도록 돕는 체크리스트가 있습니다.####.#.\n' +
      '\n' +
      '인사우들이 통로에 있는 인물A로부터 정보를 필요로 하는 인사와 사람우 사이에 4개 정도의 대화에 박차를 가한다. 통로에서 발견되는 정보만 사용하세요.\n' +
      '\n' +
      '인원은 대화를 시작하고 질문만 한다. 인사문의 질문은 대부분 이전 문항의 후속 또는 연속이다.\n' +
      '\n' +
      'Conversation:\n' +
      '\n' +
      'role-assistant:\n' +
      '\n' +
      '개인: 대학을 준비하는 방법을 알아야 합니다.\n' +
      '\n' +
      '개인: 먼저 목표와 흥미를 정의하고 대학을 위해 재정적, 학문적으로 계획하는 비용과 방법을 반드시 알아야 한다.\n' +
      '\n' +
      '인사: 준비를 위해 가이드로 사용할 수 있는 게 있나요?\n' +
      '\n' +
      '개인: 우리의 체크리스트를 사용하여 재정적이고 학문적으로 준비할 수 있습니다.\n' +
      '\n' +
      '인우: 다른 팁이요?\n' +
      '\n' +
      '개인: 대학이나 진로 학교에 참석하기 위한 이유를 꼭 확인하십시오.\n' +
      '\n' +
      '인우, 옥, 좋은 것 같아요. 더 많은 팁을 주실 수 있나요?\n' +
      '\n' +
      '개인: 다른 고려 사항은 진로 옵션을 탐색하는 것입니다.\n' +
      '\n' +
      'role-user:\n' +
      '\n' +
      '개인A는 다음 각 호의 통로에서 정보에 접근할 수 있다.\n' +
      '\n' +
      '##에는 몇 가지 장애 보상 혜택이 있습니다. 혜택 중 하나는 연간 의류 수당입니다. 이 수당은 연간 200달러까지 새 옷을 구입하는 비용을 부담합니다.##.\n' +
      '\n' +
      '인사우들이 통로에 있는 인물A로부터 정보를 필요로 하는 인사와 인사의 두 차례 정도의 대화를 거듭한다. 통로에서 발견되는 정보만 사용하세요.\n' +
      '\n' +
      '인원은 대화를 시작하고 질문만 한다. 인사원의 질문은 대부분 이전의 질문에 대한 후속 조치나 연속성을 의미한다. 컨덕션.\n' +
      '\n' +
      'role-assistant:\n' +
      '\n' +
      '개인: 의류에 대한 장애 혜택에 대해 들었습니다. 무슨 일인가요?\n' +
      '\n' +
      '개인: 이것은 연간 의류 수당이라고 알려진 장애 보상 혜택이다.\n' +
      '\n' +
      '저는 이런 혜택에 대해 꽤 관심이 있습니다.\n' +
      '\n' +
      '개인A: 자격이 있는지 알아보시겠어요?\n' +
      '\n' +
      'role-user:\n' +
      '\n' +
      '개인A는 다음 각 호의 통로에서 정보에 접근할 수 있다.\n' +
      '\n' +
      '##Vascepa(icosapent 에틸)는 중성지방 수치가 500 mg/dL 이상인 성인을 치료하기 위해 승인된 처방 어유 약물이다. 이 약을 사용하는 동안 의사의 사무실에서 자주 혈액 검사가 필요할 수 있습니다. 바세파는 식단, 운동, 체중 조절도 포함할 수 있는 치료 프로그램의 일부일 뿐이다. 의사의 지시를 매우 예의주시합니다. 미토사펜트에 알레르기가 있다면 Vascepa를 사용하지 않아야 합니다. 바세파에게 안전한지 확인하기 위해 의사에게 간 질환 1명, 당뇨병 2명, 갑상선 장애 3명, 췌장 질환 4명, 출혈이나 혈액 퇴치 장애 5명, 어패류에 알레르기가 있는 경우 6명 주류를 대량으로 마시면 7개, Vascepa(icosapent)는 간과 혈류에 작동해 매우 저밀도 중성지방을 줄인다.#.\n' +
      '\n' +
      'AuA와 cultivatingU 사이에 약 3차례의 대화를 나누었으며, 그는 약 3차례의 대화를 나눴습니다.\n' +
      '\n' +
      '인류는 통로에 있는 인사자의 정보가 필요합니다. 정보만 사용하시면 됩니다\n' +
      '\n' +
      '통로에서 흘려요.\n' +
      '\n' +
      '인원은 대화를 시작하고 질문만 한다. 인사문의 질문은 대부분 이전 문항의 후속 또는 연속이다. 컨덕션.\n' +
      '\n' +
      'role-assistant:\n' +
      '\n' +
      '인사: 바세파라는 약에 대해 들었습니다. 어떤 용도로 사용됩니까?\n' +
      '\n' +
      '개인A: Vascepa는 중성지방 수치가 매우 높은 성인을 치료하는 데 사용되는 처방 어유 약물이다.\n' +
      '\n' +
      '인사: 제가 알아야 할 부작용이나 예방 조치가 있나요?\n' +
      '\n' +
      '개인: Vascepa를 사용하는 경우 잦은 혈액 검사가 필요할 수 있으며 의사의 지시를 면밀히 따르는 것이 중요합니다. 알레르기나 기존 조건에 대해 의사와 이야기하는 것이 중요합니다.\n' +
      '\n' +
      '인센티브: 콜레스테롤 수치를 낮추는 데 효과적이나요?\n' +
      '\n' +
      'A: Vascepa는 콜레스테롤이 심한 사람들의 총 콜레스테롤을 낮추기 위해 저지방 식단 및 기타 치료와 함께 사용된다.\n' +
      '\n' +
      'role-user:\n' +
      '\n' +
      '개인A는 다음 각 호의 통로에서 정보에 접근할 수 있다.\n' +
      '\n' +
      '{Document}\n' +
      '\n' +
      'AuA와 cultivatingU 사이에 약 3차례의 대화를 나누었으며, 그는 약 3차례의 대화를 나눴습니다.\n' +
      '\n' +
      '인류는 통로에 있는 인사자의 정보가 필요합니다. 정보만 사용하시면 됩니다\n' +
      '\n' +
      '통로에서 흘려요.\n' +
      '\n' +
      '인원은 대화를 시작하고 질문만 한다. 인사문의 질문은 대부분 이전 문항의 후속 또는 연속이다.\n' +
      '\n' +
      'Conversation:role-assistant:\n' +
      '\n' +
      '단계-2에서의 인텍스트 소수샷 프롬프트는 (사명사와 공통명사를 추가하여 멀티턴 QA 대화를 개정할 청구권)와 같다.\n' +
      '\n' +
      '당신은 도움이 되는 패턴 제거 보조자입니다.\n' +
      '\n' +
      'role-user:\n' +
      '\n' +
      '인사와 인사의 대화는 다음과 같다.\n' +
      '\n' +
      '###PersonU: 멕시코 요리에 있는 아도보 소스에 대해 들었습니다. 그것에 대해 자세히 알려주실 수 있나요?\n' +
      '\n' +
      '개인A: 아도보 소스는 갈은 차일, 허브, 식초 등으로 만든 다크 레드 소스입니다. 멕시코와 사우스웨스턴 요리에 마리네이드와 요리 소스로 사용됩니다.\n' +
      '\n' +
      '인사: 아도보 소스의 주요 재료는 뭔가요?\n' +
      '\n' +
      '개인A: 주요 성분은 보통 칠리 고추, 마늘, 식초입니다. 그러나 레시피에는 차이가 있을 수 있습니다.\n' +
      '\n' +
      '인센티브: 집에 아도보 소스를 어떻게 만들 수 있나요?\n' +
      '\n' +
      '가정에서 아도보 소스를 만드는 한 가지 방법은 칩토클이라는 훈제 자라페로 고추를 사용하는 것입니다. 토마토, 마늘, 식초, 소금, 향신료가 함유된 소스에 칩토클을 찌를 수 있습니다. 많은 식료품점의 히스패닉 식품 섹션에서 통조림 아도보 소스를 찾을 수도 있습니다.\n' +
      '\n' +
      '인사: 아도보 소스에 다른 용도가 있나요?\n' +
      '\n' +
      '개인A: 아도보 소스를 약속으로 사용하거나 다양한 요리의 마리네이드로 사용할 수 있습니다. 육류의 맛을 높이고 조리 및 서빙 소스로 사용할 수 있습니다. 또한 아도보는 이 소스에서 준비한 고기의 스튜 같은 프레젠테이션에도 사용됩니다.\n' +
      '\n' +
      '인사: 아도보 소스는 보존하기 쉽나요?\n' +
      '\n' +
      '개인A: 네, 만들 때 냉동하거나 사용할 수 있어 아도보 소스를 보존할 수 있습니다. 이를 통해 최대 1년 동안 저장하고 원할 때마다 맛을 즐길 수 있습니다.##.\n' +
      '\n' +
      '인사원의 질문을 수정해서 명사 또는 공통 명사를 사용하여 인민의 이전 질문이나 인성A의 이전 응답에서 단어나 문구를 다시 언급한다.\n' +
      '\n' +
      'role-assistant:\n' +
      '\n' +
      '인우: 멕시코 요리에 있는 아도보 소스에 대해 들었습니다. 그것에 대한 더 많은 정보를 제공할 수 있습니까?\n' +
      '\n' +
      '개인A: 아도보 소스는 갈은 차일, 허브, 식초 등으로 만든 다크 레드 소스입니다. 멕시코와 사우스웨스턴 요리에 마리네이드와 요리 소스로 사용됩니다. 인사: 소스의 주요 재료는 무엇인가요?\n' +
      '\n' +
      '개인A: 주요 성분은 보통 칠리 고추, 마늘, 식초입니다. 그러나 레시피에는 차이가 있을 수 있습니다.\n' +
      '\n' +
      '인사: 집에서 소스를 어떻게 만들 수 있나요?\n' +
      '\n' +
      '개인A: 집에서 만드는 한 가지 방법은 칩토클이라는 훈제 팔라페로 고추를 사용하는 것입니다. 토마토, 마늘, 식초, 소금, 향신료가 함유된 소스에서 찌를 수 있습니다. 많은 식료품점의 히스패닉 식품 섹션에서 통조림 아도보 소스를 찾을 수도 있습니다.\n' +
      '\n' +
      '인사: 다른 용도가 있나요?\n' +
      '\n' +
      '개인: 조미료로 사용하거나 다양한 요리의 마리네이드로 사용할 수 있습니다. 육류의 맛을 높이고 조리 및 서빙 소스로 사용할 수 있습니다. 또한 이 소스에서 준비한 고기의 스튜 같은 프레젠테이션에도 사용됩니다.\n' +
      '\n' +
      '인사: 보존이 쉽나요?\n' +
      '\n' +
      '개인A: 네, 냉동하여 보존하거나 만들 때 사용할 수 있습니다. 이를 통해 최대 1년 동안 저장하고 원할 때마다 맛을 즐길 수 있습니다.\n' +
      '\n' +
      'role-user:\n' +
      '\n' +
      '인사와 인사의 대화는 다음과 같다.\n' +
      '\n' +
      '***PersonU: 소변 검사라는 시험에 대해 들었습니다. 어떤 용도로 사용됩니까?\n' +
      '\n' +
      '개인A: 최종 검사는 소변 샘플을 평가하는 테스트입니다. 요로 감염, 신장 질환, 당뇨병과 같은 광범위한 장애를 감지하고 평가하는 데 사용된다. 소변의 외관, 농도 및 함량을 조사합니다.\n' +
      '\n' +
      '인센티브: 방광암 진단에 도움을 줄 수 있나요?\n' +
      '\n' +
      '사람A: 예, 소변 검사는 방광암의 선별 및 진단 도구로 사용될 수 있다. 방광암을 검사하는 한 가지 방법은 소변에서 혈액을 확인하는 것인데, 이를 혈뇨라고 한다. 이것은 특수 현미경으로 소변 세포를 검사하여 소변 검사 중에 수행할 수 있다.\n' +
      '\n' +
      '인우: 소변 검사를 통해 어떤 다른 상태나 질병을 검출할 수 있는가?\n' +
      '\n' +
      '개인A: 요선 검사는 일반적으로 요로 또는 신장 감염 진단, 신장 실패의 원인 평가, 당뇨병 및 고혈압과 같은 만성 질환의 진행을 위한 스크리닝, 특정 질병을 진단하기 위해 다른 검사와 함께 사용할 수 있다. 요로의 이상을 감지하는 데 도움이 되는 다용도 테스트입니다.\n' +
      '\n' +
      '인사: 소변 검사를 어디서 할 수 있나요?\n' +
      '\n' +
      '개인A: 방사선 검사는 의사 사무실, 긴급한 돌봄 시설, 실험실 및 병원을 포함한 다양한 의료 환경에서 수행될 수 있다. 샘플 컵에 소변 샘플을 제공할 수 있으며 샘플을 현장 분석하거나 실험실로 보내 테스트할 수 있습니다.\n' +
      '\n' +
      '인사: 보통 소변 검사를 위해 얼마나 많은 소변이 필요합니까?\n' +
      '\n' +
      '개인A: 사실 30~60ml 범위의 소량의 소변만이 소변 검사를 위해 필요하다. 건강에 대한 귀중한 정보를 제공하는 비침습적이고 비교적 간단한 검사입니다.****.\n' +
      '\n' +
      '인사원의 질문을 수정해서 명사 또는 공통 명사를 사용하여 인민의 이전 질문이나 인성A의 이전 응답에서 단어나 문구를 다시 언급한다.\n' +
      '\n' +
      'role-assistant:\n' +
      '\n' +
      '인사: 소변 검사라는 시험에 대해 들었습니다. 어떤 용도로 사용됩니까?\n' +
      '\n' +
      '개인A: 최종 검사는 소변 샘플을 평가하는 테스트입니다. 요로 감염, 신장 질환, 당뇨병과 같은 광범위한 장애를 감지하고 평가하는 데 사용됩니다. 소변의 외관, 농도 및 함량을 조사합니다.\n' +
      '\n' +
      '인센티브: 방광암 진단에 도움을 줄 수 있나요?\n' +
      '\n' +
      '사람A: 예, 소변 검사는 방광암의 선별 및 진단 도구로 사용될 수 있다. 방광암을 검사하는 한 가지 방법은 소변에서 혈액을 확인하는 것인데, 이를 혈뇨라고 한다. 이것은 특수 현미경으로 소변 세포를 검사하여 소변 검사 중에 수행할 수 있다.\n' +
      '\n' +
      '인우: 이 검사를 통해 어떤 다른 상태나 질병을 검출할 수 있는가?\n' +
      '\n' +
      '개인A: 요선 검사는 일반적으로 요로 또는 신장 감염 진단, 신장 실패의 원인 평가, 당뇨병 및 고혈압과 같은 만성 질환의 진행을 위한 스크리닝, 특정 질병을 진단하기 위해 다른 검사와 함께 사용할 수 있다. 요로의 이상을 감지하는 데 도움이 되는 다용도 테스트입니다.\n' +
      '\n' +
      '인센티브: 이 테스트를 어디서 하러 갈 수 있나요?\n' +
      '\n' +
      '개인A: 방사선 검사는 의사 사무실, 긴급한 돌봄 시설, 실험실 및 병원을 포함한 다양한 의료 환경에서 수행될 수 있다. 샘플 컵에 소변 샘플을 제공할 수 있으며, 샘플을 검사용으로 실험실로 보내진 현장 분석기를 할 수 있다. 인사: 시험에는 보통 소변이 얼마나 필요합니까? 개인A: 사실 30~60ml 범위의 소량의 소변만이 소변 검사를 위해 필요하다. 건강에 대한 귀중한 정보를 제공하는 비침습적이고 비교적 간단한 검사입니다.\n' +
      '\n' +
      '롤-사용자: 인사자와 인사자의 다음 대화 내용을 참조하세요.\n' +
      '\n' +
      '대화와 QA 대화}{multi-turn QA 대화.\n' +
      '\n' +
      '인사원의 질문을 수정해서 명사 또는 공통 명사를 사용하여 인민의 이전 질문이나 인성A의 이전 응답에서 단어나 문구를 다시 언급한다.\n' +
      '\n' +
      'role-assistant:\n' +
      '\n' +
      '경쟁적 QA에서 은퇴를 위한 요건.\n' +
      '\n' +
      'GPT-3.5-트루보-3.5-투르보-#### 퀀리 재생 프로모션에 대한 프로모션이 지정되었다.\n' +
      '\n' +
      'GPT-3.5-투보에 사용하는 인텍스트 소수의 샷 질의 재작성 프롬프트는 다음과 같다.\n' +
      '\n' +
      '당신은 도움이 되는 패턴 제거 보조자입니다.\n' +
      '\n' +
      '롤-사용자: 인사U와 인사A: 인사U:헬로, 어떤 결정에도 동의하지 않으면 어떻게 해야 할지 알고 싶습니다. 개인: 월 소득 조정 금액에 대한 저희의 결정에 동의하지 않습니다? 인사: 아니요. SHIP 연락처를 어디서 찾을 수 있나요? 개인: 온라인상에서 메디케어&유 2020 핸드북 뒷면에 있는 현지 SHIP 연락처를 찾을 수 있습니다. 인우: 어떻게 조정을 계산하나요? 이 모든 대화를 하는 대신, 한 가지 질문을 사용하는 것을 어떻게 구할 수 있습니까? 그 질문에 응답하세요.\n' +
      '\n' +
      '롤-저항: SHIP에 의한 조정 계산은 어떻게 결정됩니까?\n' +
      '\n' +
      '롤 사용자: 인사와 인사의 다음 대화: 인사: 대학 준비 방법을 알아야 합니다. 개인: 먼저 목표와 흥미를 정의하고 대학을 위해 재정적, 학문적으로 계획하는 비용과 방법을 반드시 알아야 한다. 인사: 준비를 위해 가이드로 사용할 수 있는 게 있나요? 이 모든 대화를 하는 대신, 한 가지 질문을 사용하는 것을 어떻게 구할 수 있습니까? 그 질문에 응답하세요.\n' +
      '\n' +
      '구석 보조 : 대학 준비를 돕기 위해 어떤 자원이나 가이드를 사용할 수 있나요?\n' +
      '\n' +
      '롤-사용자: 인사자와 인사자의 다음 대화 내용을 참조하세요.\n' +
      '[대북사+최상의 문제]\n' +
      '\n' +
      '이 모든 대화를 하는 대신, 한 가지 질문을 사용하는 것을 어떻게 구할 수 있습니까? 그 질문에 응답하세요.\n' +
      '\n' +
      'role-assistant:\n' +
      '\n' +
      '대략적인 QA에서 부적절한 결과를 얻습니다.\n' +
      '\n' +
      '표 9에서 미세 조정 방법과 재작성 방법 간의 포괄적인 비교를 보여준다.\n' +
      '\n' +
      '흥미롭게도, 우리는 재필 질의를 입력(Dragon + Rewrite,w/단일 쿼리만)으로 사용하는 것에 비해 추가 대화 이력(Dragon + Rewrite,w/대화 이력)이 평균 점수를 크게 떨어뜨리는 것을 발견했다. 드래곤은 원래 싱글턴 질의에 대해 사전 조작되기 때문에 멀티턴 대화 대신 싱글턴 리필 쿼리를 제공할 때 자연스럽게 더 나은 일반화 능력을 가질 것이기 때문이다. 그리고 리필된 질의는 이미 대화 이력으로부터 충분한 정보를 포함한다.\n' +
      '\n' +
      '또한 "드래곤 + 파인-테이크"가 "드래곤 + 파인-테그 + 리워라이트"와 함께 수행된다는 것을 관측한다. 즉, 멀티턴 미세 조정 방법에 대해 원본 질의를 입력으로 재작성 쿼리로 대체하는 것은 유사한 결과를 산출한다. 대화 이력이 이미 제공되었기 때문에 재작성 쿼리는 모델에 대해 많은 추가 정보를 제공하지 않을 것이며, 전체 대화 입력이 자연스럽지 않기 때문에 부정적인 효과(예: TopiOCQA 데이터셋에 대한 결과)까지 야기할 수 있기 때문이다. 이는 미세 조정 방법이 모델을 멀티턴 컨텍스트를 이해하는 능력과 일치시키는 데 얼마나 효과적인지를 다시 한 번 보여준다.\n' +
      '\n' +
      '적용 C 대화 QA 벤치마크.\n' +
      '\n' +
      '### Data Statistics\n' +
      '\n' +
      'Doc2Dial은 평가를 위해 Doc2Dial의 테스트 세트를 사용한다. 그것은 3939개의 사용자-대리점 턴과 719개의 대화들로 구성된다.\n' +
      '\n' +
      'QuAC는 테스트 세트를 직접 얻을 수 없기 때문에 평가를 위해 QuAC의 검증 세트를 사용한다. 검증 세트는 7354개의 사용자-대리점 턴을 갖는 1000개의 대화들로 구성된다. 이 7354개의 사용자 지원 전환 중 1486개(약 20.2%)의 응답 불가능한 질문이 있다. 답변 가능 문항과 미답변 질문의 결합 평가를 위해 "미안하다. 맥락에 따라 답을 찾을 수 없다"는 내용의 근거 진실 반응을 무대-2 튜닝에서 설정한 것과 동일하게 설정하였다. 공정 비교를 위해 기준 모델(즉, 라마2-SFT/Chat, GPT-3.5-turbo, GPT-4)에서 응답할 수 없는 응답을 동일한 문장으로 대체한다(자세한 내용은 부록 E에서 찾을 수 있다).\n' +
      '\n' +
      'QReCC는 평가를 위해 QReCC의 테스트 세트를 사용한다. 테스트 세트는 QuAC 데이터 세트의 일부 대화 샘플 소스를 포함한다. 다른 벤치마크 데이터 세트와 중첩되는 것을 피하기 위해 QuAC로 구성된 샘플을 제거하여 2805개의 사용자-대리점 턴을 생성한다.\n' +
      '\n' +
      'TopicOCA는 테스트 세트가 아직 이용 가능하지 않기 때문에 TopiOCQA의 검증 세트를 사용한다. 검증 세트는 2514개의 사용자-대리점 턴과 205개의 대화들로 구성된다. 각 질문에는 총 4개의 사람이 쓴 답이 있습니다. 답변할 수 없는 사례가 있습니다. 그러나 응답 불가 사례 평가에는 이 데이터셋이 포함되어 있지 않습니다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c c c c c c c c c c} \\hline \\hline \\multirow{2}{*}{Models} & \\multicolumn{2}{c}{Average} & \\multicolumn{2}{c}{Doc2Dial} & \\multicolumn{2}{c}{QuAC} & \\multicolumn{2}{c}{QReCC} & \\multicolumn{2}{c}{TopiOCQA} & \\multicolumn{2}{c}{INSCIT} \\\\ \\cline{2-13}  & top-1 & top-5 & top-1 & top-5 & top-1 & top-5 & top-1 & top-5 & top-5* & top-20* & top-5* & top-20* \\\\ \\hline Dragon (w/ dialog history) & 46.29 & 73.09 & 43.33 & 75.61 & 56.8 & 82.86 & 46.17 & 81.96 & 57.68 & 78.80 & 27.49 & 46.22 \\\\ Dragon + Rewrite (w/ dialog history) & 47.57 & 74.12 & 44.54 & 76.98 & 57.23 & 83.04 & 46.45 & 82.60 & 60.94 & 81.74 & 28.69 & 46.22 \\\\ Dragon + Rewrite (w/ single query only) & **54.46** & **80.13** & 47.60 & 80.60 & 47.10 & 77.15 & 51.73 & 85.78 & 73.07 & 88.19 & 52.79 & 68.92 \\\\ \\hline Dragon + Fine-tune (w/ dialog history) & 52.72 & 80.67 & 48.94 & 83.01 & 52.64 & 81.95 & 50.73 & 87.17 & 67.86 & 86.28 & 43.43 & 64.94 \\\\ Dragon + Fine-tune (w/ dialog history) & **53.17** & **80.84** & 49.30 & 84.64 & 55.04 & 83.23 & 51.23 & 87.99 & 60.50 & 81.03 & 49.80 & 67.33 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 9: 5개의 데이터셋에 걸쳐 포괄적인 멀티턴 검색 결과를 보여준다.\n' +
      '\n' +
      '답변이 발견되는데, 이는 미답변 사례 평가에 충분하지 않다. 이 데이터셋이 전체 위키피디아를 검색 코퍼스로 사용한다는 점을 감안할 때, 우리는 일반적으로 특정 토픽 또는 영역으로 좁히는 문서보다 대화 QA에 더 초점을 맞추었기 때문에 멀티턴 검색을 위한 토픽 정보를 레버리니다.\n' +
      '\n' +
      '우리는 테스트 세트가 아직 이용 가능하지 않기 때문에 TopiOCQA의 검증 세트를 사용한다. 검증 세트는 사용자-대리점 턴 502을 갖는 86개의 대화들로 구성된다. 각 질문은 평균 1.9개의 인간 필기 답을 가지고 있다. 몇 가지 질문에 대해 응답할 수 없는 반응이 있습니다. 그러나 모든 질문은 항상 답변 가능한 반응이 하나 이상 있기 때문에 응답할 수 없는 사례 평가에 이 데이터 세트를 포함하지 않는다. INSCIT는 또한 전체 위키피디아를 검색 코퍼스로 사용한다. 따라서, 우리는 또한 TopiOCQA에서 언급된 것과 동일한 이유로 멀티턴 검색을 위한 토픽 정보를 레버리지한다.\n' +
      '\n' +
      'CoQA는 테스트 세트를 직접 얻을 수 없기 때문에 CoQA의 검증 세트를 사용한다. 검증 세트는 7983개의 사용자-대리점 턴이 있는 500개의 대화들로 구성된다. 각 질문에는 총 4개의 사람이 쓴 답이 있습니다. 답변할 수 없는 사례가 있습니다. 그러나 TopiOCQA 데이터 세트와 동일한 이유로 응답할 수 없는 사례 평가에 이 데이터 세트를 포함하지 않는다. 답변이 발견되지 않은 13개의 질문만 발견되며, 이는 미답변 사례 평가에 충분하지 않다.\n' +
      '\n' +
      '도큐A는 평가를 위해 도큐A의 테스트 세트를 사용한다. 테스트 세트는 쿡, 여행 및 Movie 영역을 가로질러 5394개의 사용자-대리인 턴을 갖는 1200개의 대화들로 구성된다. 5394개의 사용자-응답 회선 중 1479개(약 27.4%)의 응답 불가능한 질문이 있다. 우리는 예측 불가능한 샘플을 평가에 통합하기 위해 QuAC 데이터 세트에 언급된 것과 동일한 전략을 사용한다.\n' +
      '\n' +
      'ConvFinQA는 테스트 세트를 직접 얻을 수 없기 때문에 CoQA의 검증 세트를 사용한다. 그것의 검증 세트는 1490개의 사용자-대리점 턴이 있는 421개의 대화들로 구성된다.\n' +
      '\n' +
      'Sqa는 평가를 위해 SQA의 테스트 세트를 사용합니다. 테스트 세트는 3100개의 사용자-대리점 턴이 있는 1025개의 대화들로 구성된다.\n' +
      '\n' +
      '우리는 평가를 위해 하이브리드Dial의 테스트 세트를 사용한다. 테스트 세트는 1111개의 사용자-대리점 턴과 243개의 대화들로 구성된다.\n' +
      '\n' +
      '벤치마크의 경우##.\n' +
      '\n' +
      '우리는 ChatQA, Llama2-Chat, GPT-3.5-turbo 및 GPT-4에서 벤치마크에 대해 SSA.2에서 언급된 프롬프트 포맷을 사용하여 모든 모델에 대해 동일한 {Con텍스트}를 유지하는 반면, 바셀린에 대한 { 명령}(즉, Llama2-Chat, GPT-3.5-turbo 및 GPT-4)를 조정하여 하위 최적 결과를 얻지 않도록 한다. 우리는 다른 답변 유형(예: 긴 답변, 짧은 답변, 산술 계산)을 가진 테스트 벤치마크에 대해 다른 지침을 사용한다. 기준점에 대한 모든 모델에 대한 { 명령}은 다음과 같다.\n' +
      '\n' +
      '#### c.2.1 ChatQA\n' +
      '\n' +
      '우리는 { 명령} 단계-2의 데이터와 다른 답변 유형에 기초한 테스트 벤치마크 사이의 데이터 블렌드를 일관적으로 유지한다.\n' +
      '\n' +
      '이 데이터 세트는 일반적으로 질문에 대한 긴 답변이 있기 때문에 도QA, INSCIT, 하이브리드Dial, Doc2Dial, QuAC 및 QReCC에 대해 "질문에 대해 완전하고 완전한 답변을 해달라"고 사용한다.\n' +
      '\n' +
      '이 데이터 세트는 질문에 따라 짧고 긴 답변을 모두 가지고 있기 때문에 SQA 및 TopiOCQA에 대해 "짧은 시간, 또는 완전하고 완전한 답변으로 다음 질문을 사용한다.\n' +
      '\n' +
      '우리는 일반적으로 질문에 대한 답변이 짧기 때문에 CoQA에 대해 "다음 문항이 짧은 질문"을 사용한다. 답은 몇 가지 단어에만 있어야 한다.\n' +
      '\n' +
      '이 데이터 세트는 모델을 컨텍스트에서 수를 추출하거나 산술 계산을 하도록 요구하기 때문에 "맥락이나 +, -, * 또는 / ConvFinQA에 대한 수학 산술에서 나온 숫자로 다음 질문을 사용한다. 우리는 모형을 생성해서 금답과 비교하는 산술식 기준으로 번호를 계산해 볼 것이다.\n' +
      '\n' +
      '#### c.2.2.1 Llama2-Chat\n' +
      '\n' +
      'SSA.2의 것과 비교하여 약간 더 나쁜 결과를 제공하는 원래 라마2-챗 프롬프트 템플릿10을 시도했습니다. 우리는 라마2-챗에 대한 몇 가지 { 명령}를 시도했다. 아래가 가장 잘 작동하는 것을 발견해요.\n' +
      '\n' +
      '부츠 10: [https://gpus.[https://gutus.llamag/llama-2 촉진-템플릿/] (https://gpus.llm-utus.llm-utus.llm-utus.\n' +
      '\n' +
      '이 데이터 세트는 일반적으로 긴 답변이 있지만 한 문장 내에 있기 때문에 도QA, INSCIT, 하이브리드Dial, Doc2Dial, QuAC 및 QReCC에 대해 "한 문장으로 답변을 해달라"는 것을 사용한다. 모델이 매우 긴 답변을 생성하는 것을 방지하기 위해 "풀하고 완전한 답변" 대신 "하나의 문장"과 같은 라마2-챗의 구체적인 지시를 제공하는 것이 중요하다는 것을 알 수 있다.\n' +
      '\n' +
      '이 데이터셋은 질문에 따라 짧고 긴 답변을 모두 가지고 있고 긴 답변은 일반적으로 한 문장 내에 있기 때문에 "짧은 시간, 또는 하나의 문장을 가진 다음 질문을 사용한다." 탑이-OCQA에 대해 사용한다.\n' +
      '\n' +
      '우리는 이 데이터 세트에 대한 답이 항상 컨텍스트로부터의 개체들의 하나 또는 리스트로 구성되어 있기 때문에 SQA에 대한 "하나 또는 목록으로 다음 질문을 사용하는 것"을 사용한다.\n' +
      '\n' +
      '우리는 일반적으로 질문에 대한 답변이 짧기 때문에 CoQA에 대해 "다음 문항이 짧은 질문"을 사용한다. 답은 몇 가지 단어에만 있어야 한다.\n' +
      '\n' +
      '이 데이터 세트는 모델을 컨텍스트에서 수를 추출하거나 산술 계산을 하도록 요구하기 때문에 콘비핀QA에 대해 "맥락으로부터 수 또는 +, -, * 또는/를 사용하는 수학 산술만으로 다음 질문을 사용한다. 우리는 모델에 의해 생성된 연산식을 추출하고 계산기를 사용하여 최종 결과를 얻는다.\n' +
      '\n' +
      '2.2.3.2 GPT-3.5-투르보 & GPT-4.5-투르보 & GPT-4.5-투르보 & GPT-4.###### c.\n' +
      '\n' +
      '우리는 GPT-3.5-투르보 및 GPT-4에 대해 몇 가지 { 명령}을 시도했으며 아래 작품들은 최고(GPT-3.5-투르보 및 GPT-4 모두에 적용)를 찾았다.\n' +
      '\n' +
      '이 데이터 세트는 일반적으로 긴 답변이 있지만 한 문장 내에 있기 때문에 도QA, INSCIT, 하이브리드Dial, Doc2Dial, QuAC 및 QReCC에 대해 "한 문장으로 답변을 해달라"는 것을 사용한다. 라마2-챗과 유사하게 오픈AI 모델도 "풀하고 완전한 답변"이라는 지시에 따라 상당히 긴 답변을 생성하는 경향이 있다. 따라서 모델이 매우 긴 답변을 생성하는 것을 방지하기 위해 더 구체적인(즉, "하나의 문장") 지시를 한다.\n' +
      '\n' +
      '우리는 "JUST의 몇 가지 단어 또는 한 문장에 다음 질문을 사용하는데, 토티-OCQA는 이 데이터셋이 질문에 따라 짧고 긴 대답을 모두 가지고 있고 긴 답변은 일반적으로 한 문장 내에 있기 때문이다.\n' +
      '\n' +
      '우리는 "기업들의 하나 또는 목록으로 다음과 같은 질문을 사용하는 것"을 사용하고 있으며, SQA에 대한 자세한 설명은 최대한 짧아야 한다. 우리는 OpenAI 모델이 구체적으로 지시하지 않는 한 SQA 데이터 세트에 대해 자세한 설명을 자주 한다는 것을 발견했다.\n' +
      '\n' +
      '우리는 일반적으로 질문에 대한 답변이 짧기 때문에 CoQA에 대해 "다음 문항이 짧은 질문"을 사용한다. 답은 몇 가지 단어에만 있어야 한다.\n' +
      '\n' +
      '이 데이터 세트는 모델을 컨텍스트에서 수를 추출하거나 산술 계산을 하도록 요구하기 때문에 콘비핀QA에 대해 "맥락으로부터 수 또는 +, -, * 또는 /를 사용하여 수학 산술만으로 다음 질문을 제공한다. 우리는 모델에 의해 생성된 연산식을 추출하고 계산기를 사용하여 최종 결과를 얻는다.\n' +
      '\n' +
      '부록 D 인간 평가.\n' +
      '\n' +
      '우리는 10개의 테스트 벤치마크 데이터 세트를 통해 인간 평가를 수행한다. 우리는 각 데이터 세트에 대해 무작위로 60개의 샘플을 선택하고 각 샘플은 3개의 주석으로 표지되어 총 1800개의 주석을 생성한다.\n' +
      '\n' +
      '주석자에게 모델의 출력에서 사실 관계를 확인하고 질문에 대한 보다 정확한 응답을 제공하는 모델을 결정해 달라고 요청한다. 우리는 인간 평가를 수행하기 위해 아마존 기계 투르크 플랫폼을 사용합니다. 우리의 인간 평가 지침과 주석자에게 나타난 인터페이스의 세부 사항은 그림 3에 나와 있다.\n' +
      '\n' +
      '응답 가능 사례 평가\n' +
      '\n' +
      '답변할 수 없는 경우, 질문을 올바른 것으로 대답할 수 없음을 나타내는 모델을 고려한다. 답변 가능한 사례에 대해 우리는 질문을 나타내지 않는 모델이 정확하지 않은 것으로 간주한다(즉, 답을 제공하는 모델). ChatQA가 무대-2 튜닝에서 응답할 수 없는 질문에 대한 응답으로 이 문장을 사용하기 때문에 질문을 찾을 때 항상 "미안해. 맥락을 기반으로 답을 찾을 수 없다"는 것을 알게 된다. 라마2-챗, GPT-3.5-투보 및 GPT-4의 경우, 응답할 수 없는 질문에 대한 산출물은 보통 몇 가지 특정 패턴을 따른다. 아래에서는 도QA 및 QuAC 데이터 세트에서 생성된 모든 샘플에서 파생된 휴리스틱 매칭 패턴을 나열하여 모델이 질문이 응답할 수 없음을 시사하는지 여부를 결정한다. 생성된 산출물에는 아래에 열거된 패턴이 포함되어 있는 것을 발견하면, 우리는 문제가 불가하다는 표시로 해석하고, F1 평가를 위해 "미안하다"라고 대답을 대체할 수 없다.\n' +
      '\n' +
      '정보도 없고, 명시적이지 않으며, 정보도 없고, 아무런 언급도 없고, 없습니다.\n' +
      '\n' +
      '부록 F 사례 조사\n' +
      '\n' +
      'ChatQA-13B, ChatQA-70B, GPT-3.5-turbo 및 GPT-4에 대한 더 많은 예는 표 10에서 찾을 수 있다.\n' +
      '\n' +
      '그림 3: 인간 평가 지시와 주석을 위한 인터페이스.\n' +
      '\n' +
      '태클: 벵골 여우. "발레페스 벵갈렌시스"는 길쭉한 무탕, 길고 뾰족한 귀, 머리 및 몸길이의 약 50~60%의 바쁜 키가 있는 비교적 작은 여우이다. 등쪽 부탁은 매우 다양하지만 대부분 회색과 손바닥은 사실상 갈색이나 썩은 다리입니다. 그것은 "발레프 베일"보다 더 극소하게 구축된다. 높이는 저명한 블랙 팁으로 바쁩니다. 귀백은 검은 마진이 있는 짙은 갈색입니다. 눈 앞에 작은 검은색 헤어 패치가 있거나 멀리 깨어있는 작은 블랙 헤어 패치가 있는 탈색은 육안으로 입술이 검은색이다.\n' +
      '\n' +
      '태클: 레드 여우. 빨간색 붉은색은 아프간, 코르크스락, 벵갈보다 더 특별한 형태로 간주되며 크기 방향 및 육식성에 적응하기 때문에 두개골은 다른 종보다 훨씬 적은 수의 신성 특성을 나타낸다.\n' +
      '\n' +
      '태클: 벵골 여우. 귀는 지도나 어두운 것과 같은 색을 가지고 있지만, "V. 모음"에서와 같이 어두운 패치를 갖지 않는다. 코트 색의 광범위한 변화는 개체군과 개체군 내에서 계절에 따라 존재하지만 일반적으로 회색에서 팔갈색으로 다양하다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l l l l} \\hline \\hline\n' +
      '**Context** & & **Conversation** & **Assistant Responses** \\\\ \\hline The 3000 meters steeplechase or 3000-meter & User: Hello, can you tell me about the 3000 & \\\\ steeplechase is the most common distance for the stereplechase in track and field. It is an obstacle & metres steeplechase? & \\\\ race over the distance of the 3000 metres, which & Assistant: The 3000 metres steeplechase is the most common distance for the steeplechase in track and field that goes over the distance of & ChatQA-13B: He ran in Berlin, Adelaide, and Stockholm. \\\\ \\hline\n' +
      '1968 & 주코 쿠하(FIN)\n' +
      '앤키엘이 1969&블라디미르 인디언사(URS)와 킬레이스가 맡고 있다.\n' +
      '에이앤앤드베를린 브라이언(AUS)과 브라이언스(AUS)의 브라이언(1970&Kerry O)의 브라이언(AUS)과 베를린\n' +
      '1971 & 케리 오의 브라이언(AUS) & 아델라라이드(AUS)\n' +
      '앤헬싱키(SWE) & 헨싱키(Helsinki)는 1972&1972 & 앤더어스 가르트드(1972)\n' +
      '앤헬싱키(KEN) & 헨싱키(Helsinki)는 1973&벤지보(K73)\n' +
      '앤헬싱키(SWE) & 헨싱키(Helsinki:\\\\) & 앤더서스 가르트드(1974&Dartord Gartord)\n' +
      '1975&앤드더어스 가르트드(SWE) & 스톡홀름\n' +
      '1976 & 앤더어스 가르트드(SWE) & 몬트리올(SWE)\n' +
      '1977 & Michael Kast (FRG) & Stockholm \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\begin{tabular}{l l} \\hline \\hline\n' +
      '**Context** & **Conversation** & **Assistant Responses** \\\\ \\hline The 3000 meters steeplechase or 3000-meter & User: Hello, can you tell me about the 3000 \\\\ stereplechase is the most common distance for the stereplechase in track and field. It is an obstacle & metres steeplechase? \\\\ race over the distance of the 3000 metres, which & Assistant: The 3000 metres steeplechase is the most common distance for the steeplechase in track and field that goes over the distance of & ChatQA-13B: He ran in Berlin, Adelaide, and Stockholm. \\\\ \\hline ChatQA-70B: Kerry O’Brien ran in Adelaide and Berlin, \\\\\n' +
      '2000 & ChatQA-70B: Kerry O’Brien ran in Berlin, Adelaide, and Champion. \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\begin{tabular}{l l} \\hline \\hline\n' +
      '**Year** & **Adilete** \\\\ \\hline\n' +
      '1968 & 주코 쿠하(FIN)\n' +
      '앤키엘이 1969&블라디미르 인디언사(URS)와 킬레이스가 맡고 있다.\n' +
      '에이앤앤드베를린 브라이언(AUS)과 브라이언스(AUS)의 브라이언(1970&Kerry O)의 브라이언(AUS)과 베를린\n' +
      '1971 & 케리 오의 브라이언(AUS) & 아델라라이드(AUS)\n' +
      '앤헬싱키(SWE) & 헨싱키(Helsinki)는 1972&1972 & 앤더어스 가르트드(1972)\n' +
      '앤헬싱키(KEN) & 헨싱키(Helsinki)는 1973&벤지보(K73)\n' +
      '앤헬싱키(SWE) & 헨싱키(Helsinki:\\\\) & 앤더서스 가르트드(1974&Dartord Gartord)\n' +
      '1975&앤드더어스 가르트드(SWE) & 스톡홀름\n' +
      '1976 & 앤더어스 가르트드(SWE) & 몬트리올(SWE)\n' +
      '\n' +
      '대용 QA Data 수집에 관한 지침## 앱이론스 G 지침\n' +
      '\n' +
      '이 섹션에서는 대화 QA 데이터 수집을 위한 지침을 보여준다. 주석자에게 주어진 문서를 기반으로 대화형 QA 샘플을 구성하도록 사용자와 에이전트 역할을 모두 요청하여 주석을 보다 효율적으로 만든다. 지침은 1) 대화 QA 샘플이 어떻게 생겼는지, 2) 우리가 필요로 하는 어떤 종류의 대화 QA 샘플, 3) 주석을 해야 하는 것으로 구성되어 있다.\n' +
      '\n' +
      'QA 샘플은 대화형 QA 샘플처럼 보입니다.\n' +
      '\n' +
      '하나의 대화형 QA 샘플은 우리가 제공하는 문서를 기반으로 합니다. 사용자 및 에이전트 행동은 다음과 같습니다.\n' +
      '\n' +
      '* User 거동: 1) 주어진 문서를 기반으로 에이전트에 대한 질문, 2) 에이전트가 무언가를 명확히 하고 싶을 때 에이전트의 응답 질문.\n' +
      '* 문제의 행동: 1) 문서를 기반으로 사용자의 질문에 대한 질문, 2) 사용자의 질문이 명확하지 않은 경우 사용자에게 질문하거나 너무 일반/길이를 질문한다.\n' +
      '\n' +
      '우리가 필요로 하는 멀티턴 QA 샘플에는 어떤 종류의 멀티턴 QA 샘플이 포함됩니다.\n' +
      '\n' +
      '아래의 사용자 질문 및 에이전트의 응답에 대한 요구 사항을 나열합니다.\n' +
      '\n' +
      '#### User\'s Questions\n' +
      '\n' +
      '*User의 질문은 그의 이전 질문(또는 이전의 여러 차례)을 지칭할 수 있다.\n' +
      '* User의 질문은 에이전트의 이전(또는 여러 차례 이전) 답도 참조할 수 있다.\n' +
      '*는 앞서 언급한 기업을 대체하기 위해 명사 또는 공통 명사를 사용하려고 한다.\n' +
      '*는 사용자의 질문을 다양하게 만들기 위해 노력합니다. 같은 유형의 질문에 대해 서로 다른 대화 주석으로 표현하기 위해 다른 방법을 사용하려고 한다.\n' +
      '필요한 사용자 질문 유형\n' +
      '* 에이전트에게 답변하세요(예를 들어, 다른 건...\n' +
      '*는 주제를 스위치하고 대화에서 새로운 실을 시작한다.\n' +
      '*도 동시에 두 가지 질문을 합니다.\n' +
      '\n' +
      '#### Agent\'s Response\n' +
      '\n' +
      '*는 1-2문장 내에서 에이전트의 답을 만드도록 한다. 답변이 길어야 한다면 간결하게 만들려고 한다.\n' +
      '*는 문서로부터 관련 맥락 전체를 직접 답으로 복사하지 않도록 한다. 대신 선택된 맥락을 파프레이밍하여 답을 구성하려고 한다.\n' +
      '*은 에이전트가 어떤 것을 명확히 하기 위해 사용자에게 질문을 하는 적은 비율의 사례를 내놓도록 한다. 구체적으로, 사용자의 질문이 너무 광범위하거나 명확하지 않은 경우, 에이전트는 사용자가 더 많이 배려하는 특정 측면을 보기 위해 질문을 설명함으로써 범위를 좁힐 필요가 있다.\n' +
      '\n' +
      '우리가 주석을 해야 하는 이유는요.\n' +
      '\n' +
      '아래 각 대화에 대해 주석을 잡아야 할 내용을 나열합니다.\n' +
      '\n' +
      '* 각 문서의 경우 사용자의 질문과 해당 에이전트의 응답을 주석해야 합니다. 대화당 평균 사용자-대리점 전환 횟수는 5개 내외가 되어야 한다.\n' +
      '* 각 사용자의 질문에 대해 문서 내에서 모든 관련 컨텍스트를 주석을 달아야 합니다.\n' +
      '\n';
  </script>
  <style>
    #content {
      max-width: 800px;
      margin: auto;
    }
  </style>
  <script>
    let script = document.createElement('script');
    script.src = "https://cdn.jsdelivr.net/npm/mathpix-markdown-it@1.0.40/es5/bundle.js";
    document.head.append(script);

    script.onload = function() {
      const isLoaded = window.loadMathJax();
      if (isLoaded) {
        console.log('Styles loaded!')
      }

      const el = window.document.getElementById('content-text');
      if (el) {
        const options = {
          htmlTags: true
        };
        const html = window.render(text, options);
        el.outerHTML = html;
      }
    };
  </script>
</head>
<body>
  <div id="content"><div id="content-text"></div></div>
</body>
</html>