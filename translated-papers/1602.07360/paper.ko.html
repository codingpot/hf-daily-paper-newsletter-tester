<!DOCTYPE html>
<html lang="en" data-lt-installed="true"><head>
  <meta charset="UTF-8">
  <title>Title</title>
  <script>
    const text = '' +
      '50배 더 적은 매개변수 및 \\(<\\)<<\\).5MB 모델 크기 \\(<\\)<<\\).5MB 모델 크기인 알렉스넷 수준의 정확성: 50배 더 적은 매개변수 및 \\(<\\).5MB 모델 크기인 알렉스넷 수준의 정확성이다.\n' +
      '\n' +
      '레스트 N. Iandola\\({}^{1}\\), 송한성({}^{2}\\), 매튜 W. Hhalid Ashraf\\({}^{1}}\\), Khalid Ashraf\\({}^{1}}\\), Khalid Ashraf\\({}^{1}}\\)\n' +
      '\n' +
      '윌리엄 J. Dally\\({}^{2}\\), 커트 게이저\\({}^{1}\\)\n' +
      '\n' +
      '<{}^{*}\\> & UC 버클리({}^{2}\\)\n' +
      '\n' +
      '케슬리는{forresti, moskewcz, kashraf, keutzer}@eecs.berkeecs.berkeecs.berkeymi, moskewcz, kashraf, keutzer}@eecs.berutzer}@eecs.\n' +
      '\n' +
      '{songhan, dally}@stanford.edu\n' +
      '\n' +
      '[http://deepscale.ai](http://deepscale.ai)\n' +
      '\n' +
      '###### Abstract\n' +
      '\n' +
      '심층 컨볼루션 신경망(CNN)에 대한 최근 연구는 주로 정확도 향상에 초점을 맞추었다. 주어진 정확도 수준을 위해, 일반적으로 그 정확도 수준을 달성하는 다수의 CNN 아키텍처를 식별할 수 있다. 동일한 정확도로 더 작은 CNN 아키텍처는 분산 훈련 동안 (1) 작은 CNN이 서버 전반에 걸쳐 덜 통신해야 하는 최소 세 가지 이점을 제공한다. (2) 소형 CNN은 클라우드에서 자율주행 자동차로 새로운 모델을 수출하기 위해 더 적은 대역폭이 필요하다. (3) 소형 CNN은 제한된 메모리를 가진 FPGAs 및 기타 하드웨어에 배치하는 것이 더 가능하다. 이러한 모든 이점을 제공하기 위해 SqueezeNet이라는 작은 CNN 아키텍처를 제안한다. 스퀴즈넷은 50배 더 적은 매개변수로 이미지넷에서 알렉스넷 수준의 정확도를 달성한다. 또한 모델 압축 기술을 사용하여 SqueezeNet을 알렉스넷보다 작은 0.5MB(510\\times\\) 미만으로 압축할 수 있다.\n' +
      '\n' +
      'SqueezeNet 아키텍처는 여기에서 다운로드할 수 있다: [https://github.com/딥Scale/SqueezeNet] (https://github.com/딥Scale/SqueezeNet)\n' +
      '\n' +
      '1번 소개 및 가이드라인, 1번 소개 및 유도요.\n' +
      '\n' +
      '최근 심층 컨볼루션 신경망(CNN)에 대한 연구의 대부분은 컴퓨터 비전 데이터셋에 대한 정확도를 높이는 데 초점을 맞추었다. 주어진 정확도 수준에 대해, 일반적으로 그 정확도 수준을 달성하는 다수의 CNN 아키텍처가 존재한다. 동일한 정확도를 감안할 때 파라미터가 적은 CNN 아키텍처는 몇 가지 이점을 가지고 있다.\n' +
      '\n' +
      '**** 서버 간 보다 효율적인 분산 학습** 커뮤니케이션은 분산 CNN 훈련의 확장성에 대한 제한 요소이다. 분산 데이터-병렬 학습을 위해 통신 오버헤드는 모델의 파라미터 수(Iandola et al, 2016)에 직접 비례한다. 요컨대, 작은 모델은 의사소통이 덜 필요하기 때문에 더 빠르게 훈련됩니다.\n' +
      '신규 모델을 고객에게 수출할 때* *** 오버헤드가 적습니다.** 자율주행을 위해 테슬라와 같은 기업들은 주기적으로 서버에서 고객의 자동차로 새로운 모델을 복사한다. 이 관행은 종종 _over-the-air_ 업데이트라고 한다. 소비자 레포트는 테슬라의 _오토필로트_준자율주행 기능의 안전성이 최근 과공 업데이트(소비자 레포츠, 2016)로 확대 개선됐다는 것을 발견했다. 그러나 오늘날 일반적인 CNN/DNN 모델의 공기외 업데이트는 큰 데이터 전달을 요구할 수 있다. 알렉산넷을 사용하면 서버에서 자동차까지 240MB의 통신이 필요합니다. 더 작은 모델은 더 적은 의사소통을 필요로 하므로 빈번한 업데이트가 더 실현 가능하다.\n' +
      '***Feasible FPGA 및 임베디드 배치** FPG는 종종 온칩 메모리의 10MB1 미만과 오프칩 메모리나 스토리지가 없다. 추론을 위해 메모리 대역폭(Qiu et al, 2016), 비디오 프레임들이 FPGA를 통해 실시간으로 스트리밍되는 대신 충분히 작은 모델을 FPGA에 직접 저장할 수 있다. 또한, 응용-특정 통합 서킷(ASICs)에 CNN을 배치할 때 충분히 작은 모델을 온칩에 직접 저장할 수 있으며, 더 작은 모델은 ASIC가 더 작은 다이에 맞도록 할 수 있다.\n' +
      '\n' +
      '보시다시피, 더 작은 CNN 아키텍처의 몇 가지 장점이 있습니다. 이를 염두에 두고, 우리는 잘 알려진 모델에 비해 매개변수가 적지만 등가 정확도인 CNN 아키텍처를 식별하는 문제에 직접 초점을 맞추고 있다. 우리는 _SqueezeNet_이라고 부르는 이러한 구조를 발견했다. 또한, 새로운 CNN 아키텍처를 위한 디자인 공간을 검색하기 위해 보다 규율된 접근법에 대한 시도를 제시한다.\n' +
      '\n' +
      '나머지 논문들은 다음과 같이 정리되어 있다. 제2절에서는 관련 작업을 검토한다. 그런 다음 섹션 3과 섹션 4에서 SqueezeNet 아키텍처를 설명하고 평가한다. 그 후 CNN 건축 디자인 선택이 모델 크기와 정확도에 어떠한 영향을 미치는지 이해하는 데 관심을 돌린다. SqueezeNet과 같은 아키텍처의 디자인 공간을 탐색하여 이러한 이해를 얻습니다. 5절에서 우리는 개별 계층 및 모듈의 조직 및 차원으로 정의하는 _CNN 미세건축_에 대한 공간 탐색을 설계한다. 6절에서 우리는 CNN에서 층들의 고수준의 조직으로 정의되는 _CNN 매크로 아키텍처_에 대한 공간 탐색을 설계한다. 마지막으로 7절에서 결론을 내리는데, 짧게는 3절과 4절은 CNN 연구자와 SqueezeNet을 새로운 애플리케이션에 적용하려는 실무자들에게도 유용하다. 나머지 섹션은 자체 CNN 아키텍처를 설계하려는 첨단 연구자를 대상으로 한다.\n' +
      '\n' +
      '2개는 회사 관련.\n' +
      '\n' +
      '### Model Compression\n' +
      '\n' +
      '우리의 작업의 과도한 목표는 정확도를 보존하면서 파라미터가 거의 없는 모델을 식별하는 것이다. 이 문제를 해결하기 위해, 감각적인 접근법은 기존의 CNN 모델을 취하여 손실된 방식으로 압축하는 것이다. 실제로 _model 압축_의 주제를 중심으로 연구 공동체가 등장하였고, 여러 가지 접근법이 보고되었다. 덴톤 _et al._에 의한 상당히 간단한 접근법은 전처리된 CNN 모델(덴톤 등 2014)에 단수 값 분해(SVD)를 적용하는 것이다. 한_et al_et al._ 개발된 네트워크 프루닝은 전처리된 모델로 시작된 다음 특정 임계값 미만의 파라미터를 제로 대체하여 희소 행렬을 형성하고 최종적으로 희박한 CNN(한 et al. 2015)에 대한 훈련의 몇 가지 반복을 수행한다. 최근 한_et al._는 네트워크 프루닝과 양자화(8비트 이하) 및 허프만 인코딩을 결합하여 딥 억제(한 et al., 2015)라는 접근법을 생성하고, 압축 모델에 직접 동작하는 EIE(한 et al. 2016)라는 하드웨어 가속기를 추가로 설계하여 실질적인 속도 및 에너지 절감을 달성하였다.\n' +
      '\n' +
      '### CNN Microarchitecture\n' +
      '\n' +
      '컨볼루션을 인공 신경망에서 최소 25년 동안 사용했으며 LeCun _et al.__는 1980년대 후반(LeCun et al., 1989) 디지털 인식 응용을 위해 CNN을 대중화하는 데 도움이 되었다. 신경망에서 컨볼루션 필터는 전형적으로 3D로서 키, 폭, 채널을 핵심 차원으로 한다. 이미지에 적용할 때 CNN 필터는 일반적으로 첫 번째 층(즉, RGB)에 3개의 채널을 가지며, 각 후속 층(L_{i}\\)에서 필터는 \\(L_{i-1}\\)와 동일한 수의 채널을 갖는다. 레쿤 _et al_(LeCun et al., 1989)의 초기 작업은 5x5 채널s2 필터를 사용하고 있으며 최근 VGG(심니안 & Zisserman, 2014) 아키텍처는 3x3 필터를 광범위하게 사용한다. 네트워크 인넷(Lin et al., 2013), 건축가 고그레이넷 계열(Szegedy et al., 2014; Ioffe & Szegedy, 2015; Szegedy et al., 2016)과 같은 모델은 일부 층에서 1x1 필터를 사용한다.\n' +
      '\n' +
      '발주 2: 앞으로는 HxWx채널을 단순히 HxW로 축약할 것이다.\n' +
      '\n' +
      '매우 깊은 CNN을 설계하는 경향으로 각 레이어에 대해 수동으로 필터 치수를 선택하는 것은 번거로울 것이다. 이를 해결하기 위해 특정 고정 조직을 갖는 다중 컨볼루션 레이어로 구성된 다양한 상위 레벨 구축 블록들 또는 _모듈_이 제안되었다. 예를 들어, 고그LeNet 논문은 보통 1x1 및 3x3, 때로는 5x5(Szegedy et al, 2014), 때로는 1x3 및 3x1(Szegedy et al, 2015)을 포함하여 다수의 서로 다른 필터 치수로 구성된 _Inception 모듈_을 제안한다. 그런 다음 많은 그러한 모듈이 아마도 추가 _ad-hoc_층과 결합하여 완전한 네트워크를 형성한다. 우리는 _CNN 미세건축_이라는 용어를 사용하여 개별 모듈의 특정 조직 및 차원을 나타낸다.\n' +
      '\n' +
      '### CNN Macroarchitecture\n' +
      '\n' +
      'CNN 미세 아키텍처는 개별 계층 및 모듈을 지칭하는 반면, 우리는 _CNN 매크로 아키텍처_를 최종 대 엔드 CNN 아키텍처로의 다중 모듈의 시스템 수준 조직으로 정의한다.\n' +
      '\n' +
      ' 아마도 최근 문헌에서 가장 널리 연구된 CNN 거시건축 주제는 네트워크에서 _ 심층_(즉, 층수)의 영향일 것이다. 시모얀과 지스머먼은 12~19개의 레이어가 있는 CNN의 VGG(심니안, 지셔만, 2014) 계열을 제안했으며 더 깊은 네트워크가 이미지넷-1k 데이터세트(Deng et al, 2009)에서 더 높은 이미지넷 정확도(He et al., 2015a)를 제공하는 최대 30개 레이어로 더 깊은 CNN을 제안했다고 보고했다.\n' +
      '\n' +
      '여러 층 또는 모듈에 걸친 연결 선택은 CNN 거시건축 연구의 새로운 영역이다. 잔류네트웍스(ResNet)(He et al., 2015b)와 고속도로네트웍스(Srivastava et al., 2015)는 각각 다중 레이어 위에 건너뛰는 연결의 사용을 제안하며, 예를 들어 계층 3에서 계층 6에서 활성화로 액티베이션을 추가 연결한다. ResNet의 저자는 우회 연결이 있거나 없는 34층 CNN의 A/B 비교를 제공하고 바이패스 연결을 추가하면 탑-5 이미지넷 정확도에 2%포인트 개선을 제공한다.\n' +
      '\n' +
      '신경망 디자인 공간.\n' +
      '\n' +
      '신경망(깊고 합성곱 NN 포함)은 디자인 공간이 크며 마이크로 아키텍처, 매크로 아키텍처, 솔버 및 기타 하이퍼파라미터에 대한 다양한 옵션이 있다. 이러한 요인이 NN의 정확성(즉, 디자인 공간의 _shape__)에 어떤 영향을 미치는지에 대해 커뮤니티가 직관을 얻고자 하는 것은 당연해 보인다. NN의 디자인 공간 탐색(DSE) 작업에 대한 많은 작업은 더 높은 정확도를 전달하는 NN 아키텍처를 찾기 위한 자동화된 접근법을 개발하는 데 중점을 두었다. 이러한 자동화된 DSE 접근법에는 베이지안 최적화(Snoek et al., 2012), 시뮬레이션된 가열냉각(Ludermir et al, 2006), 무작위 검색(Bergstra and Bengio, 2012), 유전자 알고리즘(Stanley and Miikkulainen, 2002)이 포함된다. 그들의 신용에 대해, 이 논문들 각각은 제안된 DSE 접근법이 대표적인 기준선에 비해 더 높은 정확도를 달성하는 NN 아키텍처를 생성하는 경우를 제공한다. 그러나 이 논문은 NN 디자인 공간의 형태에 대해 직관을 제공하려고 시도하지 않는다. 이후 본 논문에서는 CNN 건축 결정이 모델 크기와 정확도에 어떻게 영향을 미치는지 조사하기 위해 원칙적인 A/B 비교를 할 수 있는 방식으로 CNN을 반박한다.\n' +
      '\n' +
      '다음 섹션에서는 먼저 모델 압축이 있거나 없는 SqueezeNet 아키텍처를 제안 및 평가한다. 그런 다음 SqueezeNet 유사 CNN 아키텍처에 대한 미세건축 및 거시건축에서 디자인 선택의 영향을 탐구한다.\n' +
      '\n' +
      '파라미터가 거의 없는 정확도를 보존합니다.\n' +
      '\n' +
      '이 섹션에서는 매개변수가 거의 없는 CNN 아키텍처를 위한 설계 전략을 요약하여 시작한다. 그런 다음 CNN 아키텍처를 구축하기 위해 새로운 건물 블록인 _Fire 모듈_을 소개합니다. 마지막으로, 우리는 주로 화재 모듈로 구성된 _SqueezeNet_를 구성하기 위해 설계 전략을 사용한다.\n' +
      '\n' +
      '건축 디자인 전략\n' +
      '\n' +
      '이 논문에서 우리의 과도한 목적은 경쟁적 정확도를 유지하면서 매개변수가 적은 CNN 아키텍처를 식별하는 것이다. 이를 달성하기 위해 CNN 아키텍처를 설계할 때 세 가지 주요 전략을 사용한다.\n' +
      '\n' +
      '1x1 필터가 있는_전략 1._** 교체 3x3 필터는 일정 수의 컨볼루션 필터의 예산을 통해 1x1 필터가 3x3 필터보다 9X가 적기 때문에 이 필터 1x1의 대부분을 만들기 위해 선택하겠습니다.\n' +
      '\n' +
      '_전략 2._**는 입력 채널의 수를 3x3 필터로 감소시키며*** 컨벌더 레이어는 완전히 3x3 필터로 구성된다. 이 계층의 파라미터의 총량은 (입력 채널의 수) * (필터 수) * (3*3)이다. 따라서 CNN에서 소수의 총 매개변수를 유지하기 위해서는 3x3 필터 수(위 전략 1 참조)를 감소시킬 뿐만 아니라 _입력 채널_의 수를 3x3 필터로 감소시키는 것이 중요하다. 우리는 다음 섹션에서 설명하는 _squeeze 층_을 사용하여 입력 채널의 수를 3x3 필터로 감소시킨다.\n' +
      '\n' +
      '컨볼루션 레이어가 큰 활성화 맵(***)이 되도록 네트워크에서 후기_전략 3.** 다운샘플링, 각 컨볼루션 레이어는 최소 1x1이고 종종 1x1보다 훨씬 큰 공간 해상도로 출력 활성화 맵을 생성하며, 이러한 활성화 맵의 높이와 폭은 입력 데이터(e.g. 256x256 이미지)의 크기(e. 256x256 이미지)와 CNN 아키텍처에서 다운샘플링되는 레이어의 선택(2)에 의해 제어된다. 가장 일반적으로 다운샘플링은 일부 컨볼루션 또는 풀링 계층(예: Szegedy et al, 2014, 심니안 & Zisserman, 2014, Krizhevsky et al. 2012)에서 (stride \\(>1\\))을 설정하여 CNN 아키텍처로 조작된다. 네트워크 내의 초기 3 레이어가 큰 지층을 갖는 경우 대부분의 레이어는 작은 활성화 맵을 가질 것이다. 반대로, 네트워크의 대부분의 계층이 1의 보폭을 가지며, 1보다 큰 지층은 네트워크의 끝자락을 향해 집중되어 있다면, 네트워크의 많은 계층은 큰 활성화 맵을 가질 것이다. 우리의 직관은 큰 활성화 맵(지연된 다운샘플링으로 인한)이 다른 모든 것이 동등하게 유지되는 더 높은 분류 정확도로 이어질 수 있다는 것이다. 네, K. 그는 H. 선이 4개의 다른 CNN 아키텍처에 지연 다운샘플링을 적용했고, 각각의 경우 다운샘플링이 지연되면 분류 정확성이 높아졌다(허앤선, 2015).\n' +
      '\n' +
      '발주 3: 우리의 용어에서 "매우" 계층은 입력 데이터에 가깝다.\n' +
      '\n' +
      '부츠 4: 우리의 용어에서 네트워크의 "엔드"는 분류기이다.\n' +
      '\n' +
      '전략 1과 2는 정확도를 보존하려고 시도하면서 CNN에서 매개변수의 양을 유도적으로 감소시킨다는 것이다. 전략 3은 파라미터의 제한된 예산에 대한 정확도를 최대화하는 것이다. 다음으로 전략 1, 2, 3을 성공적으로 채용할 수 있는 CNN 아키텍처의 건물 블록인 화재 모듈을 설명한다.\n' +
      '\n' +
      '헬드 모듈\n' +
      '\n' +
      '우리는 화재 모듈을 다음과 같이 정의한다. 화재는 1x1 및 3x3 컨볼루션 필터를 혼합한 _squze_ 컨볼루션 레이어(1x1 필터만 있는)로 구성되며, 화재 모듈에서 1x1 필터의 자유화 사용은 3.1 섹션에서 전략 1의 적용이며, \\(s_{1x1}\\), \\(e_{1x1}\\), \\(e_{3x3}\\)에 3개의 튜닝 가능한 치수(e_{3x3}\\)를 노출한다. 소방모듈에서 \\(s_{1x1}\\)는 스퀴즈층(all 1x1), \\(e_{1x1}\\)는 팽창층의 1x1 필터의 수이고, \\(e_{3x3}\\)는 확장층의 3x3 필터의 수이다. 우리가 화재 모듈을 사용할 때 \\(s_{1x1}\\)를 (e_{1x1}+e_{3x3}\\)보다 적게 설정하므로 스퀴즈 층은 3.1절에서 전략 2에 따라 입력 채널의 수를 3x3 필터로 제한하는 데 도움이 된다.\n' +
      '\n' +
      '네트 아키텍처.\n' +
      '\n' +
      '이제 SqueezeNet CNN 아키텍처를 설명합니다. 우리는 그림 2에서 SqueezeNet이 독립형 컨볼루션 레이어(conv1)로 시작되고, 이어서 8개의 화재 모듈(소방2-9)이 최종 컨벌루션 레이어(conv10)로 종료됨을 보여준다. 우리는 화재 모듈당 필터의 수를 네트워크 시작부터 종료까지 점진적으로 증가시킨다. SqueezeNet은 레이어 컨트랙트 1, 화재 4, 화재 8 및 설득 10 후 2개의 스트라이드로 맥스풀링을 수행하며, 이러한 비교적 늦은 풀링 장소는 3.1절에서 전략 3당이며, <표 1>에 전체 SqueezeNet 아키텍처를 제시한다.\n' +
      '\n' +
      '그림 1: 마이크로 아키텍처 뷰: ** 화재 모듈**의 컨볼루션 필터 기구. 이 예에서 \\(s_{1x1}=3\\), \\(e_{1x1}=4\\), \\(e_{3x3}=4\\)이다. 컨볼루션 필터를 설명하지만 액티베이션은 설명하지 않습니다.\n' +
      '\n' +
      '세퀴즈넷 상세내용 3.3.1.1의#####\n' +
      '\n' +
      '유중성을 위해 <표 1>과 <그림 2>의 SqueezeNet에 대한 세부사항과 디자인 선택의 수를 생략하였다. 우리는 다음과 같은 설계 선택을 제공한다. 이러한 선택의 배후에 있는 직관은 아래 인용된 논문에서 찾을 수 있다.\n' +
      '\n' +
      '*. 1x1 및 3x3 필터로부터의 출력 액티베이션이 키와 너비가 동일하다는 것을 So, 입력 데이터에 0패딩의 1픽셀 경계를 확장 모듈 3x3 필터에 추가한다.\n' +
      '* ReLU(Nair & Hinton, 2010)는 스퀴즈 및 확장 계층으로부터의 활성화들에 적용된다.\n' +
      '*드롭아웃(Srivastava et al, 2014)은 화재9 모듈 이후에 50%의 비율로 적용되고 있다.\n' +
      '* 노트 SqueezeNet에서 완전히 연결된 층이 없다는 것을 알 수 있으며, 이 디자인 선택은 NiN(Lin et al., 2013) 아키텍처의 영감을 받았다.\n' +
      '* SqueezeNet 훈련 시 0.04의 학습률로 시작하여 (Mishkin et al, 2016)에서 설명한 대로 훈련 전반에 걸쳐 학습률을 선형적으로 감소시킨다. 훈련 프로토콜(예: 배치 크기, 학습률, 매개변수 초기화)에 대한 세부 사항은 여기에 위치한 카페인 호환 구성 파일[https://github.com/DeepScale/SqueezeNet] (https://github.com/딥Scale/SqueezeNet)을 참조하십시오.\n' +
      '* Caffe 프레임워크는 다수의 필터 해상도(예: 1x1 및 3x3)를 포함하는 컨볼루션 레이어(예: 2014.Jia et al., 2014). 이를 위해 1x1 필터가 있는 층과 3x3 필터가 있는 층이라는 두 개의 개별 컨볼루션 레이어로 확장 레이어를 구현한다. 그런 다음 채널 차원에서 이러한 층의 출력을 함께 연결합니다. 이것은 1x1 및 3x3 필터를 모두 포함하는 하나의 층을 구현하는 것과 수치적으로 동일하다.\n' +
      '\n' +
      '우리는 Caffe CNN 프레임워크에 의해 정의된 형식으로 SqueezeNet 구성 파일을 출시하였다. 그러나 카페 외에도 MXNet(Chen et al., 2015a), 치네어(톡의 et al., 2015), 케라(콜레트, 2016), 토치(콜로베르트 et al., 2011) 등 여러 CNN 틀이 등장했다. 이들 각각은 CNN 아키텍처를 나타내기 위한 고유한 고유 포맷을 가지고 있다. 즉, 이들 도서관의 대부분은 cuDNN(Chetlur et al., 2014), MKL-DNN(Das et al., 2016)과 같은 동일한 기본 계산 백라인을 사용한다. 연구계가 가지고 있습니다.\n' +
      '\n' +
      '그림 2: SqueezeNet 아키텍처에 대한 거시건축적 관점을 보여준다. 좌표: 스퀴즈넷(섹션 3.3); 중: 단순 바이패스(섹션 6)가 있는 SqueezeNet, 즉 복합 바이패스(SquzeNet)가 있는 SquzeNet(섹션 6)\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:6]\n' +
      '\n' +
      '33% 스파시티6 및 8비트 양자화를 사용하여 SqueezeNet을 사용합니다. 이는 알렉스넷과 동등한 정확도로 0.66MB 모델(32비트 알렉스넷보다 작은 363\\)을 생성한다. 또한, SqueezeNet에 6비트 양자화 및 33% 스쿼티로 딥 압축을 적용하여 동등한 정확도로 0.47MB 모델(32비트 알렉스넷보다 작은510\\(\\times\\)을 생성한다. 자사 작은 모델은 압축에 실제로 적합합니다.*****\n' +
      '\n' +
      '부츠 6: 노트, 희소한 매트릭스 지수를 저장하는 저장 오버헤드로 인해 33%의 스파시티가 모델 크기의 \\(3\\) 감소보다 다소 적게 이어진다.\n' +
      '\n' +
      '또한, 이러한 결과는 딥 억제(한 et al., 2015a)가 많은 매개변수(예: 알렉스넷 및 VGG)로 CNN 아키텍처에 잘 작용할 뿐만 아니라 이미 컴팩트하고 완전히 컨볼루션 SqueezeNet 아키텍처를 압축할 수 있음을 보여준다. 딥 압축 SqueezeNet은 기준 정확도를 보존하면서 \\(10\\)에 의해 압축된다. 요약하면, CNN 아키텍처 혁신(SqueezeNet)과 최첨단 압축 기술(딥압축)을 결합하여 기준선과 비교하여 정확도가 감소하지 않는 모델 크기의 \\(510\\t 시점이다\\) 감소를 달성했다.\n' +
      '\n' +
      '마지막으로 딥 억제(한 et al., 2015b)는 CNN 파라미터를 정밀도의 6- 또는 8-토끼로 정량화하기 위한 계획의 일부로 _codebook_를 사용한다는 점에 주목한다. 따라서 대부분의 상품 프로세서에서 딥 억제에서 개발된 방식을 사용하여 6비트 양자화를 사용하여 8비트 양자화 또는 \\(\\frac{32}{8}=4x\\)로 \\(\\frac{32}{6}=5.3x\\)의 속도를 달성하는 것이 _not_ 사소한 것이다. 그러나 한 _et al_. 코드북-양자화된 CNN을 보다 효율적으로 계산할 수 있는 맞춤형 하드웨어 - _효율적인 해결 엔진(EIE)_ - 개발되었습니다(한 et al 2016a). 또한 SqueezeNet을 출시한 지 몇 달 만에 P. Gysel은 SqueezeNet을 8비트(Gysel, 2016)로 선형 정량화하기 위한 _Ristretto_라는 전략을 개발했다. 구체적으로, Ristretto는 8비트로 계산되며, 8비트 데이터 타입에 파라미터와 액티베이션을 저장한다. SqueezeNet 추론에서 8비트 계산을 위한 Ristretto 전략을 사용하여 Gysel은 32비트 데이터 유형 대신 8비트 사용 시 정확도의 1%포인트 미만의 감소를 관찰했다.\n' +
      '\n' +
      '5 CNN 구성 디자인 공간.\n' +
      '\n' +
      '지금까지 소규모 모델에 대한 건축 설계 전략을 제안하고, 이 원칙을 따라 SqueezeNet을 만들었으며, SqueezeNet이 동등한 정확도로 알렉스넷보다 50배 작은 것을 발견했다. 그러나 SqueezeNet 및 기타 모델은 CNN 아키텍처의 광범위하고 크게 설명되지 않은 디자인 공간에 존재한다. 이제 5절과 6절에서는 디자인 공간의 여러 측면을 탐색한다. 우리는 이 건축 탐사를 _마이크로 아키텍처 탐사_(전체 모듈 층 치수 및 구성)와 _macroarchural 탐사_(모듈 및 다른 층의 고수준의 종단 간 조직)의 두 가지 주요 주제로 나눈다.\n' +
      '\n' +
      '이 섹션에서는 3.1절에서 제안한 설계 전략과 관련하여 미세 건축 설계 공간의 형태에 대한 직관을 제공하는 것을 목표로 실험을 설계하고 실행하며, 여기에서 우리의 목표는 모든 실험에서 정확도를 최대화하기 위해 _not_이지만 오히려 CNN 건축 선택이 모델 크기와 정확도에 미치는 영향을 이해하고자 한다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{|c|c|c|c|c|c|c|} \\hline CNN architecture & Compression Approach & Data & Original \\(\\rightarrow\\) & Reduction in Model Size & Top-1 & Top-5 \\\\  & & Type & Compressed Model & Model Size & ImageNet & ImageNet \\\\ \\hline AlexNet & None (baseline) & 32 bit & 240MB & 1x & 57.2k & 80.3\\% \\\\ \\hline AlexNet & SVD (Denton et al., 2014) & 32 bit & 240MB \\(\\rightarrow\\) 48MB & 5x & 56.0\\% & 79.4\\% \\\\ \\hline AlexNet & Network Pruning (Han et al., 2015b) & 32 bit & 240MB \\(\\rightarrow\\) 27MB & 9x & 57.2\\% & 80.3\\% \\\\ \\hline AlexNet & Deep & 5-8 bit & 240MB \\(\\rightarrow\\) 6.3/MB & 35x & 57.2\\% & 80.3\\% \\\\  & Compression (Han et al., 2015a) & & & & & \\\\ \\hline SqueezeNet (ours) & None & 32 bit & 4.8MB & **50x** & 57.5\\% & 80.3\\% \\\\ \\hline SqueezeNet (ours) & Deep Compression & 8 bit & 4.8MB \\(\\rightarrow\\) 0.66MB & **363x** & 57.5\\% & 80.3\\% \\\\ \\hline SqueezeNet (ours) & Deep Compression & 6 bit & 4.8MB \\(\\rightarrow\\) 0.47MB & **510k** & 57.5\\% & 80.3\\% \\\\ \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 2: SqueezeNet을 모델 압축 접근법으로 비교하는 것이다. i_m모델 크기_에 의해, 우리는 모든 매개변수를 학습된 모델에 저장하는 데 필요한 바이트의 수를 의미한다.\n' +
      '\n' +
      'CNN은\n' +
      '\n' +
      'SqueezeNet에서 각 화재 모듈은 3.2절에서 정의되는 3차원 하이퍼파라미터, \\(s_{1x1}\\), \\(e_{1x1}\\), \\(e_{3x3}\\)를 갖는다. 스퀴즈넷에는 총 24차원 하이퍼파라미터가 있는 8개의 화재 모듈이 있습니다. SqueezeNet 유사 아키텍처의 디자인 공간의 광범위한 스윕을 수행하기 위해 CNN에서 모든 화재 모듈의 치수를 제어하는 더 높은 레벨 _metaparamet_의 세트를 정의한다. 우리는 CNN의 첫 번째 화재 모듈에서 \\(베이스_{e}\\)를 _expand_ 필터의 수로 정의한다. 모든 \\(freq\\) 화재 모듈 후에, 우리는 \\(incr_{e}\\)에 의해 확장 필터의 수를 증가시킨다. 즉, 화재 모듈 \\(i\\)의 경우 확장 필터의 수는 \\(e_{i}=베이스_{e}+(incr_{e}*\\leleft\\frac{i}{freq}\\right\\rfloor)\\이다. (pcd_{3x3}\\)는 \\(pcd_{i,{i_{i,3x3}\\)로, \\(e_{i,1x3}. 마지막으로, 모든 화재 모듈에 의해 공유되는 _squze 비율(SR)_squze 비율([0,1]\\) 범위(s_{i,1x1}=SR*e_{i}\\): \\(s_{i,1x1}\\)(또는 동등하게 \\(s_{i,1x1}=SR*(e_{i,1x1}=SR*(e_{i,1x1})=SR*(e_{i,1x1}. SqueezeNet(표 1)은 앞서 언급한 메타 파라미터 세트와 함께 생성된 예시 아키텍처이다. 구체적으로, SqueezeNet은 \\(베이스_{e}=128\\), \\(incr_{e}=128\\), \\(pcd_{3x3}=0.5\\), \\(freq=2\\) 및 \\(SR=0.125\\)의 메타모수를 갖는다.\n' +
      '\n' +
      '### Squeeze Ratio\n' +
      '\n' +
      '3.1절에서 3x3 필터에서 볼 수 있는 입력 채널의 수를 줄이기 위해 _squeeze 층_을 사용하여 매개변수의 수를 줄이는 것을 제안했다. 우리는 _squeeze 비율(SR)_을 _squeeze_ 층의 필터 수와 _expand_ 층의 필터 수 사이의 비율로 정의했다. 우리는 이제 스퀴즈 비율이 모델 크기와 정확도에 미치는 영향을 조사하기 위한 실험을 설계한다.\n' +
      '\n' +
      '이 실험에서 우리는 SqueezeNet(그림 2)을 출발점으로 사용한다. SqueezeNet에서와 같이, 이러한 실험은 \\(베이스_{e}=128\\), \\(incr_{e}=128\\), \\(pcd_{3x3}=0.5\\), \\(freq=2\\)를 사용한다. 각 모델이 [0.125, 1.0] 범위에서 서로 다른 스퀴즈비(SR)7을 갖는 여러 모델을 훈련한다. 그림 3(a)에서 그래프 상의 각 지점이 처음부터 훈련된 독립적인 모델인 이 실험의 결과를 보여준다. SqueezeNet은 이 그림 8의 SR=0.125점이며, 이 그림에서 SR을 0.125 이상으로 증가시키면 4.8MB 모델이 있는 80.3%(즉 알렉사넷 수준)에서 19MB 모델로 86.0%로 이미지Net 최고-5 정확도를 더욱 증가시킬 수 있음을 알게 된다. SR=0.75(19MB 모델)로 86.0%의 정확성 평판 및 SR=1.0 설정은 정확도를 향상시키지 않으면서 모델 크기를 더욱 증가시킨다.\n' +
      '\n' +
      '부츠 7: 노트, 주어진 모델에 대해 모든 화재 층은 동일한 스퀴즈 비율을 공유한다.\n' +
      '\n' +
      '스퀴즈비(SR)가 낮기 때문에 우리가 _SqueezeNet_이라고 명명한 트윗 8: 노트입니다. 즉, SqueezeNet 내의 스퀴즈층들은 팽창층으로서 필터의 수 0.125x를 갖는다.\n' +
      '\n' +
      '1x1 및 3x3 필터 트레이딩.\n' +
      '\n' +
      '3.1절에서 우리는 일부 3x3 필터를 1x1 필터로 대체하여 CNN의 매개변수 수를 줄이는 것을 제안했다. 개방적인 질문은 CNN 필터에서 공간 해상도가 얼마나 중요한가?_어떻게 중요한가?\n' +
      '\n' +
      '그림 3: 마이크로 아키텍처 디자인 공간 탐색.\n' +
      '\n' +
      'VGG(심니안&지스머만, 2014) 아키텍처는 대부분의 레이어 필터에서 3x3 공간 해상도를 가지고 있으며, 고그LeNet(Szegedy et al., 2014), 네트워크 인넷(NiN)(Lin et al., 2013)은 일부 레이어에서 1x1 필터를 가지고 있다. 고그LeNet과 NiN에서 저자는 추가 분석 없이 단순히 1x1 및 3x3 필터의 특정 양을 제안하며, 1x1 및 3x3 필터의 비율이 모델 크기와 정확도에 어떻게 영향을 미치는지 밝히고자 한다.\n' +
      '\n' +
      '뿌리 9: 명확하기 위해 각 필터는 1x1x채널 또는 3x3x채널이며, 이는 우리가 1x1 및 3x3으로 축약한다.\n' +
      '\n' +
      '우리는 이 실험에서\\(베이스_{e}=incr_{e}=128\\), \\(freq=2\\), \\(SR=0.500\\) 및\\(pct_{3x3}\\)를 1%에서 99%로 다양한다. 즉, 각 화재 모듈의 확장층은 1x1과 3x3 사이에서 분할된 미리 정의된 수의 필터를 가지고 있으며, 여기서는 이들 필터의 손잡이를 "최소한 1x1"에서 "대부분 3x3"으로 돌린다. 이 모형들은 이전 실험과 마찬가지로 그림 2와 같은 층들의 조직에 따라 8개의 화재 모듈을 가지고 있다. <그림 3>에서 본 실험의 결과를 보여준다. 그림 3(a) 및 그림 3(b)의 13MB 모델은 \\(SR=0.500\\) 및 \\(pct_{3x3}=50\\%\\)의 동일한 아키텍처이다. 그림 3(b)에서 50% 3x3 필터를 사용하여 상위 5개 정확도 플레이트를 85.6%로 85.6%로 보고, 3x3 필터의 비율을 더 증가시키면 모델 크기가 더 크지만 이미지넷에 대한 정확도는 향상되지 않는다.\n' +
      '\n' +
      '6 CNN 맥로픽처 디자인 스페이스.\n' +
      '\n' +
      '지금까지 우리는 미건축 수준에서 설계 공간, 즉 CNN의 개별 모듈의 내용을 탐색했다. 이제 우리는 화재 모듈 간의 고위급 연결에 관한 거시건축 수준에서 설계 결정을 탐색한다. ResNet(He et al., 2015)에 의해 영감을 받은 우리는 세 가지 다른 아키텍처를 탐색했다.\n' +
      '\n' +
      '* 바닐라 스쿼즈넷 (이전 섹션당)\n' +
      '일부 화재 모듈들 사이의 단순 바이패스 연결을 갖는* SqueezeNet입니다. (시바스타바 등, 2015, He et al., 2015)에 의해 영감을 받았다.\n' +
      '나머지 화재 모듈들 사이의 복잡한 우회 연결을 갖는* SqueezeNet.\n' +
      '\n' +
      '우리는 그림 2의 SqueezeNet의 이 세 가지 변형을 보여준다.\n' +
      '\n' +
      '우리의 _단순 바이패스_ 아키텍처는 화재 모듈 3, 5, 7, 9 주변의 바이패스 연결을 추가하여 이들 모듈이 입력과 출력 사이의 잔차 기능을 학습하도록 요구한다. ResNet에서와 같이, 화재3 주변의 바이패스 연결을 구현하기 위해, + 오퍼레이터가 요소적으로 추가되는 (화재의 출력 2+화재의 출력)와 동일한 파이어4로 입력을 설정했다. 이는 이들 화재 모듈의 파라미터들에 적용되는 규칙화를 변화시키고, ResNet당처럼 전체 모델을 훈련시키는 최종 정확도 및/또는 능력을 향상시킬 수 있다.\n' +
      '\n' +
      '한 가지 한계는 간단한 경우, 입력 채널의 수와 출력 채널의 수가 같을 수 있고, 그 결과, "채널 수의" 요구 사항을 충족할 수 없는 것처럼, 우리는 그림 2의 우측에 예시된 바와 같이 1x1 컨볼루션 레이어를 포함하는 복잡한 우회기를 "정밀 바이패스_ 연결"으로 정의하고, 간단한 우회은 필요한 출력 채널의 수와 동일한 필터 수를 갖는 1x1 컨볼루션 레이어를 포함하는 우회으로 정의한다. 복잡한 우회 연결은 모델에 추가 파라미터를 추가하는 반면 단순 우회 연결은 그렇지 않다.\n' +
      '\n' +
      '정규화를 바꾸는 것 외에도 바이패스 연결을 추가하면 스퀴즈 층에 의해 도입된 대표 병목 완화에 도움이 된다는 것이 직관적이다. SqueezeNet에서 스퀴즈비(SR)는 0.125로, 모든 스퀴즈층이 첨부된 팽창층보다 8배 적은 출력채널을 가지고 있음을 의미한다. 이러한 심각한 차원 감소로 인해 제한된 양의 정보가 스퀴즈 레이어를 통과할 수 있다. 그러나 SqueezeNet에 우회 연결을 추가하여, 우리는 정보가 _around_ 압착 레이어를 흐를 수 있는 방법을 열어준다.\n' +
      '\n' +
      '우리는 그림 2의 세 가지 거시건축과 SqueezeNet을 훈련하고 표 3의 정확도와 모델 크기를 비교했으며 거시건축 탐색 전반에 걸쳐 표 1에 설명된 바와 같이 SqueezeNet과 일치하도록 미세건축을 고정했다. 복잡하고 간단한 우회 연결은 둘 다 바닐라 스퀴즈넷 아키텍처에 대한 정확성 향상을 산출했다. 흥미롭게도 단순 우회은 복잡한 우회보다 더 높은 정확도 향상을 가능하게 했다. 단순 우회 연결을 추가하면 모델 크기를 증가시키지 않으면서 상위-1 정확도에서 2.9%포인트, 상위-5 정확도에서 2.2%포인트 증가했다.\n' +
      '\n' +
      '## 7 Conclusions\n' +
      '\n' +
      '본 논문에서는 컨볼루션 신경망의 설계 공간 탐색에 대한 보다 규율된 접근 방식을 향한 단계를 제안하였다. 이 목표를 통해 우리는 알렉스넷보다 더 적은 매개변수(50\\)를 갖고 이미지넷에 알렉스넷 수준의 정확도를 유지하는 CNN 아키텍처인 SqueezeNet을 제시했다. 또한 SqueezeNet을 압축 없이 알렉스넷보다 작은 0.5MB 이하 또는 \\(510\\)로 압축했다. 2016년 기술보고서로 본 논문을 발표한 이후 송한과 그의 협력자들은 스쿼즈넷과 모델 압축을 추가로 실험하였다. 1.2%포인트인 SquzeNet 파라미터 세트를 더 정확하게 생성하고 표 2의 결과와 비교하여 4.3%포인트인 SquzeNet 매개변수의 압축되지 않은 세트를 더 정확하게 생성하기 위해 정규화기로 훈련하는 동안 모델 압축을 사용한다._Dense-Sparse-D(한 et al., 2016).\n' +
      '\n' +
      '본 논문의 시작 부근에서는 작은 모델이 FPGAs에 대한 온칩 구현에 더 적합하다는 것을 언급했다. SqueezeNet 모형을 발표한 이후, Gschwend는 SqueezeNet의 변종을 개발하여 FPGA(Gschwend, 2016)에 구현하였다. 우리가 예상한 바와 같이, Gschwend는 SqueezeNet 유사 모델의 파라미터를 FPGA 내에서 완전히 저장하고 모델 매개변수를 로드하기 위해 칩 오프 메모리 접근의 필요성을 제거할 수 있었다.\n' +
      '\n' +
      '본 논문의 맥락에서, 우리는 타겟 데이터 세트로서 이미지넷에 초점을 맞추었다. 그러나 미세곡물 인식(장 et al., 2013; 돈아에 등, 2013), 이미지 내 로고 식별(아이난돌라 et al., 2015), 이미지(망 et al., 2015)에 대한 문장을 생성하는 등 다양한 애플리케이션에 이미지넷 학습된 CNN 표현을 적용하는 것이 일반적인 관행으로 되었다. 이미지넷으로 훈련된 CNN은 영상(Iandola et al, 2014; Girshick et al, 2015; Ashraf et al, 2016), 동영상(Chen et al., 2015), 도로 형상(Badrinarayan et al., 2015)을 세분화하는 등 자율 주행과 관련된 다수의 애플리케이션에도 적용되었다. 우리는 SqueezeNet이 다양한 응용 분야에 대한 좋은 후보 CNN 아키텍처가 될 것이라고 생각합니다, 특히 작은 모델 크기가 중요하다고 생각합니다.\n' +
      '\n' +
      '스퀴즈넷은 CNN 아키텍처의 디자인 공간을 광범위하게 탐색하면서 발견한 여러 새로운 CNN 중 하나이다. SqueezeNet이 독자에게 CNN 아키텍처의 디자인 공간에서 광범위한 가능성을 고려하고 탐색하고 보다 체계적인 방식으로 그 탐구를 수행하기를 바랍니다.\n' +
      '\n' +
      '## References\n' +
      '\n' +
      '* 아슈라프 등 (2016) 칼리드 아슈라프, 비첸 우, 포레스트 N. 아이오올라 마테와 W. 골격계, 커트 게이저. 고수용성 도로 객체-검출을 위한 네트워크 작성. _j 고수익성 도로 객체-검출을 위한 네트워크 작성. arXiv:1606.01561_ 2016.\n' +
      '*바트리나란 등은 (2015) 비제이 바트리나라야난, 알렉스 켄달, 로베르토 시폴라 등이다. 세그넷: 이미지 분할을 위한 A 딥 컨벌루션 인코더-디코더 아키텍처 __SegNet: A 딥 컨벌루션 인코더-디코더 아키텍처. 아렉시브:1511.00561_ 2015.\n' +
      '* 벨(2016) 에드디 벨입니다. 루머에서 스퀴젠셋의 구현. [내셔널://github.com/ejlb/squeezenet-사슬러]]. 2016년 (https://github.com/ejlb/squeezenet-사슬er)\n' +
      '* 베르그스트리와 벤지오(2012) J 베르그스트라 및 Y. 벤지오. 신경망 가중치 및 아키텍처에 대한 최적화 방법론은 __ 뉴럴 네트워크 가중치 및 아키텍처에 대한 최적화 방법론이 있다. JMLR_ 2012.\n' +
      '*코헨 등은 (2015) 톈치 첸, 무리, 유티안 리, 민린, 나이옌 왕, 민지왕, 톈준 샤오, 빙추, 치유안 장, 정장 등이 있다. Mxnet: 이종 분산 시스템을 위한 유연하고 효율적인 기계 학습 라이브러리 __Mxnet: 이종 분산 시스템을 위한 유연하고 효율적인 기계 학습 라이브러리를 사용한다. arXiv:1512.01274_, 2015a.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{|c|c|c|c|} \\hline Architecture & Top-1 Accuracy & Top-5 Accuracy & Model Size \\\\ \\hline Vanilla SqueezeNet & 57.5\\% & 80.3\\% & 4.8MB \\\\ \\hline SqueezeNet + Simple Bypass & **60.4\\%** & **82.5\\%** & 4.8MB \\\\ \\hline SqueezeNet + Complex Bypass & 58.8\\% & 82.0\\% & 7.7MB \\\\ \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 3: SqueezeNet 정확도와 모델 크기는 서로 다른 거시 아키텍처 구성 요소 구성을 사용하는 것\n' +
      '* 첸 등은 (2015) 샤오지히 첸, 카스타브 쿤두, 유룬 주, 앤드루 게 베르네위, 후민 마, 산자 피들러, 라젤 우피나선 등이 있다. 정확한 객체 클래스 검출을 위한 3d 객체 제안서. 2015b에서 _NIPS_.\n' +
      '* 체트루 등 (2014) 샤란 체트루르, 클리핀 울리, 필리페 반데르치, 조나탄 코헨, 존 트란, 브라이언 카탄자로, 에반 셸햄러 등이다. 딥러닝을 위한 효율적인 프리미티브 __cuDNN: 딥러닝을 위한 효율적인 프리미티브이다. arXiv:1410.0759_ 2014.\n' +
      '*콜렛 (2016) 프랑수이스 솔렛. 키라: 나노 및 텐서 흐름을 위한 딥 러닝 라이브러리:https://keras. [https://keras.io]]] 텐서플로우. 2016년 (https://keras.io).\n' +
      '*콜로베르트 등 (2011) 로난 콜로베르트, 코레이 카부쿠오글루, 코르네 프라벳 등이 있다. Torch7: 머신 러닝을 위한 매트랩 같은 환경입니다. 2011년 _NIPS 빅학습 워크샵_.\n' +
      '*수입(2016) 소비자 수입입니다. GO://www. [http://www.org/tesla/tesla-새로운 오토필롯-부탄-부종-개선] Better: 새로운 오토필롯이 개선되어야 한다. 2016년(http://www. 살펴보고자umerre 수출은.org/tesla/tesla-새로운 오토필로트-베터-부틸-부탄-개선)이다.\n' +
      '* 다스 등은 (2016) 디피칸카르 다스, 사미칸트 아바카, 디에바쓰아 무디게르, 카시마케옌 바덴시아 아탄, 시리바스 세리다란, 다람카르, 바하트 카울, 페데프 다브비 등이 있다. 동기 확률적 구배 하강기를 사용하여 딥러닝을 분배했다. __ 동기 확률적 구배 하강기를 사용하여 딥러닝을 분배했다. arXiv:1602.06709_ 2016.\n' +
      '* 덩 et al. (2009) J Deng, W. 동, R. 소셔, L. J. 리, K. 리, L. Fei-Fei. 이미지넷: 대규모 계층적 이미지 데이터베이스입니다. 2009년 _CVPR_에서.\n' +
      '* 펜톤 et al. (2014) E.L 덴톤, W. 자레마바, 제이 브루나, Y. 리쿤과 R. 페르거스. 효율적인 평가를 위해 컨볼루션 네트워크 내에서 선형 구조를 탐색한다. 2014년 _NIPS_에서.\n' +
      '* 돈아에 등은 (2013) 제프 도야에, 양칭 지아, 오리올 비네스, 주디 호프만, 닝 장, 에릭 터젠, 트레보르 다렐 등이다. 일반 시각적 인식을 위한 심층 컨볼루션 활성화 특징 __디카프: 일반적인 시각적 인식을 위한 심층 컨볼루션 활성화 특징. arXiv:1310.1531_ 2013.\n' +
      '2016년(2016) DT42 (2016) 사케네트 케라 구현[https://github.com/DT42/squeezenet_demo]]. ket://github.com/DT42/squeezenet_demo]]. 2016년 (https://github.com/DT42/squeezenet_demo)\n' +
      '* Fang et al. (2015) Hao Fang, Saurabh Gupta, 포레스트 이랜드콜라, 루피쉬 시바스타바, 리 드펑, 푸엇라케, 지아니펑 가오, 샤오동 허, 마가레트 미첼, 존 C. 로렌스 지트니크 및 거프리 저웨그이다. 포획부터 시각 개념, 등까지. 2015년 _CVPR_에서.\n' +
      '* 기릭 등 (2015) 로스 B 기릭, 포레스트 N. 아이돌라, 트레보르 다렐, 지텐드라 말릭. 형성 가능한 부분 모델은 컨볼루션 신경망이다. 2015년 _CVPR_에서.\n' +
      '* Gschwend (2016) 데이비드 Gschwend. Zynqnet: An fpga가 급속화된 임베디드 컨볼루션 신경망입니다. 마스터의 논문인 스위스 연방기술원 주리히(ETH-Zurich)는 2016년이다.\n' +
      '* Gysel (2016) 필리필 Gysel. Ristretto: Hardware 지향 합성곱 신경망의 근사치. __Hardware 중심 근사치. arXiv:1605.06402_ 2016.\n' +
      '* 한 등은 (2015a) S. 한, 하마오, W. 너무. 딥 압축: 프루닝, 훈련된 양자화 및 커프만 코딩으로 DNN을 압축하는 _ 딥 압축: 프루닝, 훈련된 양자화 및 커프만 코딩으로 고정하세요. 아렉시브:1510.00149v3_, 2015a.\n' +
      '2015b(2015b) S. 한, J. 풀, J. 트란, W. 너무. 효율적인 신경망을 위해 가중치와 연결을 모두 학습합니다. 2015b에서 _NIPS_.\n' +
      '*한 등은 송한, 식유 류, 후지 마오, 징 푸, 아다반 페드람, 마크 아 호로비츠, 윌리엄 J 다이버리 등이 있다. 압축된 심층 신경망 상의 Eie: 효율적인 추론 엔진은 압축된 심층 신경망 상의 __Eie: 효율적인 추론 엔진이다. 컴퓨터 건축(ISCA)_ 2016a에 대한 국제 심포지엄.\n' +
      '*한 등은 송한, 제프풀, 샤란 나랑, 후지 마오, 시지안 탕, 에리히 엘센, 브라이언 카탄자로, 존 트란, 윌리엄 J. Dally입니다. Dd: 조밀한 비교 밀도 훈련 흐름을 가진 심층 신경망의 등록화: 깊은 신경망을 촘촘하게 고정화할 수 있다. arXiv:1607.04381_ 2016b.\n' +
      '* 하리아(2016) 구아히리아. mxnet[사스트기투브.com/haria/haria/SqueezeNet/commit/0cf57539375fd5429275af36fc94c774503427c3]]]-mxnet. 2016년 (https://github.com/haria/SqueezeNet/commit/0cff57539375fd5429275af36fc94c944503427c3)\n' +
      '\n' +
      '* He 등은 K. (2015a) 그는 X. 장, S. 런과 J. 태양. 직장으로 깊숙한 곳, 즉 상상력 분류에 대한 인간 수준의 성능을 통과시킨다. E_ICCV_, 2015a.\n' +
      '* He & Sun(2015) 키밍 하이와 지안 선입니다. 컨볼루션 신경망은 제약된 시간 비용으로 제한된다. 2015년 _CVPR_에서.\n' +
      '* He et al.(2015b) 키밍 하이, 샤앙유 장, 샤오킹 르, 지안 선. 이미지 인식을 위한 딥 잔차학습 __, 영상 인식을 위한 딥 잔차학습 _. _. _. arXiv:1512.03385_, 2015b.\n' +
      '* 이단돌라 등 (2014) 포레스트 N. 아이오올라 마테와 W. 골격과즈, 세르게이 카라예프, 로스 비기쉬크, 트레보 다렐, 커트 게이저 등이 있다. 덴세넷: 효율적인 컨볼넷 디스크립터 피라미드 구현, 효율적인 컨벌넷 디스크립터 피라미드. __입니다. arXiv:1404.1869_ 2014.\n' +
      '* 이단돌라 et al. (2015) 포레스트 N. 이닥돌라, 안팅 선, 피터 가오, 커트 게이저. 심층 신경망 망치로 __ 딥 로고: 홉팅 로고 인식을 인식합니다. 아르시브:1510.02131_ 2015.\n' +
      '* 이단돌라 et al. (2016) 포레스트 N. 이단돌라, 칼리드 아슈라프, 매튜 W. 골격계, 커트 게이저. 화재카페: 컴파일 군집에 대한 심층 신경망 훈련의 비선형 가속도. 2016년 _CVPR_에서.\n' +
      '* 이오프앤세그레디(2015) 세르게이 이오프, 크리스티안 스제그리디 등이 있다. Batch 정규화: 내부 공변량 이동을 감소시켜 심층 네트워크 훈련을 가속화하는 _ 배치 정규화: 내부 공변량 이동을 감소시켜 심층 네트워크 교육을 제공한다. JMLR_ 2015.\n' +
      '*자아 등은 (2014) 양칭자아, 에반셸하이어, 제프 도야에, 세르게이 카야예프, 조나단 롱, 로스 기릭, 세르히오 과다라라마, 트레보 다렐 등이 있다. 빠른 특징 임베딩을 위한 __Caffe: Convolutional 아키텍처. arXiv:1408.5093_ 2014.\n' +
      '* 크리에헤프스키 등은 알(2012) 알렉스 켈즈허프스키, 아이라이아 세이츠케버, 거프리 에르턴 등이 있다. 딥컨볼루션 신경네트웍스를 사용한 이미지넷 분류입니다. 2012년 _NIPS_에서.\n' +
      '* LeCun et al. (1989) Y. LeCun, B.Boser, J. S. 덴커, D. 헨더슨, R.E. 하워드 W. 허바드, L.D. 잭텔. 필기 지퍼 코드 인식에 적용된 역전파( __)는 필기 지퍼 코드 인식에 적용되었다. 신경 컴퓨팅_1989.\n' +
      '* Lin 등은 (2013) 민린, 키앙 첸, 슈이청 옌이다. 네트워크 네트워크 네트워크 네트워크 네트워크 네트워크 네트워크 네트워크( __Network)의 네트워크( __Network). __. arXiv:1312.4400_ 2013.\n' +
      '* 루데르미르 등은 T.(2006) T. 루더미르, A. 야마자키 및 C. 자네틴. 신경망 가중치 및 아키텍처에 대한 최적화 방법론은 __ 뉴럴 네트워크 가중치 및 아키텍처에 대한 최적화 방법론이 있다. IEEE 트랜스는 신경네트웍스_, 2006.\n' +
      '* 미슈킨 등 (2016) 디미트로 미쉬킨, 니콜레이 세르히예스키, 지리 마타스 등이 있다. 상상에 대한 cnn 발전에 대한 체계적인 평가 __ cnn 발전은 상상력에 대한 시스템적 평가이다. 2016년arXiv:1606.02228_\n' +
      '* Nair & Hinton(2010) 비노드 네어와 지오프리 에르턴. 확장된 선형 단위는 제한된 볼츠만 기계를 개선합니다. 2010년 _ICML_에서.\n' +
      '* Qiu 등은 (2016) 지안토오 Qiu, Jie Wang, 송야오, Kaiyuan Guo, Boxun Li, Boxun Li, 에르진 주, 진청 유, 톈치 당, 닝이 Xu, 센송, 유왕, 후즈홍 양이다. 컨볼루션 뉴럴 네트워크를 위해 임베디드 fpga 플랫폼으로 더 깊이 간다. 2016년 FPGA_에 대한 _ACM 국제 심포지엄에서.\n' +
      '* 시노난 & 지셔난(2014) 카렌 시노난과 앤드루 지스메만이 있다. 대규모 이미지 인식을 위한 매우 깊은 컨볼루션 네트워크는 __ 대규모 이미지 인식을 위한 매우 깊은 컨볼루션 네트워크이다. arXiv:1409.1556_ 2014.\n' +
      '* Snoek et al. (2012) J. Snoek, H. Larochelle 및 R.P. Adams. 기계 학습 알고리즘의 실용적인 베이지안 최적화를 합니다. 2012년 _NIPS_에서.\n' +
      '* 시바스타바 등 (2014) 니티시 시바스타바, 거프리 호튼, 알렉스 크리에헤프스키, 아이라이아 세이츠케버, 러틀란 살라쿠트디노프 등이다. 드롭아웃: 신경망이 과적합되는 것을 방지하는 간단한 방법: __ 신경망이 과적합되는 것을 방지하는 간단한 방법이다. JMLR_ 2014.\n' +
      '* 시바스타바 등 (2015) R. K. 시바스타바, K. 그레프, J. 슈미트후버. 고도로 네트워크. 2015년 _ICML 딥 러닝 워크숍_.\n' +
      '*스탠리&미키쿨레옌(2002) K.O. 스탠리와 R. 미이크쿨렌. 토폴로지를 증가시켜 신경망을 전달하는 __는 토폴로지를 증가시킨다. 신경컴퓨팅_ 2002.\n' +
      '* Szegedy et al. (2014) 크리스천 세제금, Wei Liu, Weqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, 두릿루 에르한, 빈센트 반우케 및 앤드류 라비노비치. 경련으로 더 깊이 올라가. __은 경련으로 더 깊이 간다. arXiv:1409.4842_ 2014.\n' +
      '\n' +
      '* Szegedy et al. (2015) 크리스티안 Szegedy, 빈센트 반우케, 세르게이 이오프, 조온톤 섀센, 지그니뷰 우자나. 컴퓨터 비전을 위해 인셉션 아키텍처를 생각하는 __ 컴퓨터 비전을 위해 인셉션 아키텍처를 생각하십시오. 아르시브:1512.00567_ 2015.\n' +
      '* Szegedy et al. (2016) 크리스티안 Szegedy, 세르게이 이오프, 빈센트 반우케. 인셉션-v4, 인셉션-resnet, 인셉션-resnet 및 잔차 연결이 학습에 미치는 영향. __잔차 연결이 학습에 미치는 영향. 2016년arXiv:1602.07261_입니다.\n' +
      '2015) S.(2015) S. 토쿠이, K. 오노, S. 시도, J. 클레이튼. Chainer: 딥러닝을 위한 차세대 오픈 소스 프레임워크입니다. 2015년 머신러닝시스템(학습Syss)__NIPS 워크숍에서.\n' +
      '* 와그마어(2016) 사가 마구마어. 소방 모델은 톨루아. 2016년 2016년 (https://github.com/요소 연구/dpnn/blob/master/소방 모델) (https://github.com/요소 연구/dpnn/blob/master/소방 모델).\n' +
      '* 장 등은 (2013) 닝 장, 라이언 파렐, 포레스트 이단돌라, 트레보 다렐 등을 들 수 있다. 미세-곡물 인식 및 속성 예측을 위한 변형 가능한 부분 디스크립터이다. 2013년 _ICCV_에서.\n' +
      '\n';
  </script>
  <style>
    #content {
      max-width: 800px;
      margin: auto;
    }
  </style>
  <script>
    let script = document.createElement('script');
    script.src = "https://cdn.jsdelivr.net/npm/mathpix-markdown-it@1.0.40/es5/bundle.js";
    document.head.append(script);

    script.onload = function() {
      const isLoaded = window.loadMathJax();
      if (isLoaded) {
        console.log('Styles loaded!')
      }

      const el = window.document.getElementById('content-text');
      if (el) {
        const options = {
          htmlTags: true
        };
        const html = window.render(text, options);
        el.outerHTML = html;
      }
    };
  </script>
</head>
<body>
  <div id="content"><div id="content-text"></div></div>
</body>
</html>